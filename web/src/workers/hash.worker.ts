/// <reference lib="webworker" />

// ä¿®æ­£ WASM è·¯å¾„ï¼Œä½¿ç”¨ç›¸å¯¹è·¯å¾„ä»¥ç¡®ä¿ Worker èƒ½å¤Ÿæ­£ç¡®è§£æ
import init, {initThreadPool, StreamingHasher} from "../wasm/blake3/blake3_wasm";

// --- Constants (Matching Backend) ---
const QUICK_HASH_THRESHOLD = 100 * 1024 * 1024; // 100 MB
const QUICK_HASH_CHUNK_SIZE = 1 * 1024 * 1024; // 1 MB

const THREADS = Math.max(1, navigator.hardwareConcurrency - 1);
const CHUNK_SIZE = THREADS > 4 ? 8 * 1024 * 1024 : 4 * 1024 * 1024;


// --- Type Definitions ---
// è¾“å…¥æ¶ˆæ¯ç±»å‹
export interface WorkerMessage {
  type: "ABORT" | "GENERATE_HASH";
  data?: File[];
}

// å•ä¸ªç»“æœè¿”å›ç±»å‹ (å‰ç«¯éœ€è¦æ ¹æ®è¿™ä¸ªæ¥å®šä¹‰æ¥æ”¶é€»è¾‘)
export interface SingleHashPayload {
  index: number;
  hash: string;
  error?: string;
  file?: File; // å¯é€‰ï¼šå¦‚æœä½ éœ€è¦æŠŠæ–‡ä»¶å¯¹è±¡ä¼ å›ä¸»çº¿ç¨‹ï¼ˆæ³¨æ„è¿™ä¸ä¼šæ‹·è´æ–‡ä»¶å†…å®¹ï¼Œåªæ˜¯å¼•ç”¨ï¼‰
}

// è¿›åº¦è¿”å›ç±»å‹
export interface ProgressPayload {
  processed: number;
  total: number;
}

// --- Initialization Control ---
let initializationPromise: Promise<void> | null = null;

async function initialize(): Promise<void> {
  if (initializationPromise) {
    return initializationPromise;
  }

  initializationPromise = (async () => {
    try {
      await init();

      const isIsolated = self.crossOriginIsolated;

      if (isIsolated && navigator.hardwareConcurrency > 1 && initThreadPool) {
        
        await initThreadPool(THREADS);
      } else {
        console.warn("Worker is not cross-origin isolated or multi-threading not supported. Falling back to single-threaded mode.");
      }

      self.postMessage({ type: "WASM_READY" });
    } catch (error: unknown) {
      const errMsg = (error as Error).message ?? "Unknown worker error";
      console.error("Error initializing genHash WebAssembly module:", error);
      self.postMessage({ type: "ERROR", payload: { error: errMsg } });
      throw new Error(errMsg);
    }
  })();

  return initializationPromise;
}

/**
 * ç­–ç•¥ A: å¿«é€Ÿå“ˆå¸Œ (é’ˆå¯¹å¤§æ–‡ä»¶)
 * Strategy: hash(file_size_64bit_le + first_chunk + last_chunk)
 */
async function calculateQuickHash(file: File, signal: AbortSignal): Promise<string> {
  const hasher = new StreamingHasher();

  // 1. Write file size as 8-byte little-endian
  const sizeBuf = new ArrayBuffer(8);
  const sizeView = new BigUint64Array(sizeBuf);
  sizeView[0] = BigInt(file.size);
  // æ³¨æ„ï¼šhasher.update éœ€è¦ Uint8Array è§†å›¾
  hasher.update(new Uint8Array(sizeBuf));

  // 2. Read first chunk
  const firstChunk = await file.slice(0, QUICK_HASH_CHUNK_SIZE).arrayBuffer();
  if (signal.aborted) throw new Error("Aborted");
  hasher.update(new Uint8Array(firstChunk));

  // 3. Read last chunk (if file is large enough)
  if (file.size > QUICK_HASH_CHUNK_SIZE) {
    let lastChunkStart = file.size - QUICK_HASH_CHUNK_SIZE;
    if (lastChunkStart < QUICK_HASH_CHUNK_SIZE) {
      lastChunkStart = QUICK_HASH_CHUNK_SIZE;
    }
    const lastChunk = await file.slice(lastChunkStart, file.size).arrayBuffer();
    if (signal.aborted) throw new Error("Aborted");
    hasher.update(new Uint8Array(lastChunk));
  }

  // finalize æ¶ˆè€— hasher å¹¶è¿”å› hex string
  return hasher.finalize();
}

/**
 * ç­–ç•¥ B: å…¨é‡å“ˆå¸Œ (é’ˆå¯¹å°æ–‡ä»¶)
 * ä½¿ç”¨ CHUNK_SIZE åˆ†å—è¯»å–ï¼Œæé«˜ BLAKE3 æ•ˆç‡
 */
async function calculateFullHash(file: File, signal: AbortSignal): Promise<string> {
  const hasher = new StreamingHasher();
  let offset = 0;

  while (offset < file.size) {
    if (signal.aborted) throw new Error("Aborted");

    const end = Math.min(offset + CHUNK_SIZE, file.size);
    const chunk = await file.slice(offset, end).arrayBuffer();
    hasher.update(new Uint8Array(chunk));
    offset = end;
  }

  return hasher.finalize();
}

// --- Abort Control ---
let abortController = new AbortController();

// --- Main Logic ---
self.onmessage = async (e: MessageEvent<WorkerMessage>) => {
  const { type, data } = e.data;

  switch (type) {
    case "ABORT":
      abortController.abort();
      // é‡ç½® Controller ä»¥ä¾¿ä¸‹æ¬¡ä½¿ç”¨
      abortController = new AbortController();
      break;

    case "GENERATE_HASH": {
      // æ¯æ¬¡æ–°ä»»åŠ¡å¼€å§‹å‰ï¼Œç¡®ä¿ä¹‹å‰çš„è¢« Abort (æˆ–è€…é‡ç½®ä¿¡å·)
      abortController.abort();
      abortController = new AbortController();
      const signal = abortController.signal;

      let numberOfFilesProcessed = 0;

      try {
        await initialize();

        if (!data || data.length === 0) {
          // å¤„ç†ç©ºæ•°ç»„æƒ…å†µï¼Œç›´æ¥è¿”å›å®Œæˆ
          self.postMessage({ type: "HASH_COMPLETE" });
          return;
        }

        const assets = data;
        const total = assets.length;

        // --- æ ¸å¿ƒå¾ªç¯ï¼šæµå¼å¤„ç† ---
        for (let i = 0; i < total; i++) {
          // æ£€æŸ¥ä¸­æ­¢ä¿¡å·
          if (signal.aborted) break;

          const asset = assets[i];
          const globalIndex = i; // è¿™é‡Œå‡è®¾ä¼ å…¥çš„æ•°ç»„ index å°±æ˜¯å…¨å±€ indexï¼Œæˆ–è€…ä½ å¯ä»¥ä» data é‡Œä¼  id è¿›æ¥

          try {
            let hash: string;

            // æ ¹æ®å¤§å°é€‰æ‹©ç­–ç•¥
            if (asset.size > QUICK_HASH_THRESHOLD) {
              hash = await calculateQuickHash(asset, signal);
            } else {
              hash = await calculateFullHash(asset, signal);
            }

            // ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šç®—å®Œä¸€ä¸ªï¼Œç«‹é©¬åå‡ºæ¥
            // è¿™æ ·ä¸»çº¿ç¨‹å¯ä»¥ç«‹åˆ»æŠŠè¿™ä¸ªæ–‡ä»¶æ‰”è¿›ä¸Šä¼ é˜Ÿåˆ—
            const payload: SingleHashPayload = {
              index: globalIndex,
              hash: hash,
              // file: asset // å¦‚æœéœ€è¦å›ä¼ æ–‡ä»¶å¯¹è±¡ç”¨äºä¸Šä¼ ï¼Œå¯ä»¥åœ¨è¿™é‡Œå¸¦ä¸Š
            };

            self.postMessage({
              type: "HASH_SINGLE_COMPLETE",
              payload: payload
            });

          } catch (err: unknown) {
            // å¦‚æœæ˜¯ Abortedï¼Œé€šå¸¸ä¸éœ€è¦æŠ¥é”™ï¼Œç›´æ¥é€€å‡ºå¾ªç¯å³å¯
            if ((err as Error).message === "Aborted") {
              break;
            }

            const errorMessage = `Error generating hash for ${asset.name}`;
            console.error(errorMessage, err);

            // å•ä¸ªå¤±è´¥ä¸åº”æ‰“æ–­æ•´ä½“æµç¨‹ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯å³å¯
            self.postMessage({
              type: "HASH_SINGLE_COMPLETE",
              payload: {
                index: globalIndex,
                hash: "", // ç©º hash ä»£è¡¨å¤±è´¥
                error: (err as Error).message
              }
            });
          } finally {
            // åªæœ‰åœ¨æ²¡è¢«ä¸­æ–­çš„æƒ…å†µä¸‹æ‰æ›´æ–°è¿›åº¦
            if (!signal.aborted) {
              self.postMessage({
                type: "PROGRESS",
                payload: {
                  processed: ++numberOfFilesProcessed,
                  total: total,
                },
              });
            }
          }
        }

        // å¾ªç¯ç»“æŸï¼Œå‘é€æ€»å®Œæˆä¿¡å· (ä¸å¸¦æ•°æ®)
        if (!signal.aborted) {
          self.postMessage({ type: "HASH_COMPLETE" });
        }

      } catch (err: unknown) {
        const errorMessage = err instanceof Error ? err.message : "Unknown worker error";
        console.error("Error in GENERATE_HASH task:", err);
        self.postMessage({ type: "ERROR", payload: { error: errorMessage } });
      }
      break;
    }

    default:
      // @ts-ignore
      console.warn(`Unknown message type: ${type}`);
      break;
  }
};
