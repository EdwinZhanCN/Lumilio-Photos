<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 15.0.4"/>
    <title>lumen_clip.backends API documentation</title>

    <style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#ffffcc}.pdoc-code{background:#f8f8f8;}.pdoc-code .c{color:#3D7B7B; font-style:italic}.pdoc-code .err{border:1px solid #FF0000}.pdoc-code .k{color:#008000; font-weight:bold}.pdoc-code .o{color:#666666}.pdoc-code .ch{color:#3D7B7B; font-style:italic}.pdoc-code .cm{color:#3D7B7B; font-style:italic}.pdoc-code .cp{color:#9C6500}.pdoc-code .cpf{color:#3D7B7B; font-style:italic}.pdoc-code .c1{color:#3D7B7B; font-style:italic}.pdoc-code .cs{color:#3D7B7B; font-style:italic}.pdoc-code .gd{color:#A00000}.pdoc-code .ge{font-style:italic}.pdoc-code .gr{color:#E40000}.pdoc-code .gh{color:#000080; font-weight:bold}.pdoc-code .gi{color:#008400}.pdoc-code .go{color:#717171}.pdoc-code .gp{color:#000080; font-weight:bold}.pdoc-code .gs{font-weight:bold}.pdoc-code .gu{color:#800080; font-weight:bold}.pdoc-code .gt{color:#0044DD}.pdoc-code .kc{color:#008000; font-weight:bold}.pdoc-code .kd{color:#008000; font-weight:bold}.pdoc-code .kn{color:#008000; font-weight:bold}.pdoc-code .kp{color:#008000}.pdoc-code .kr{color:#008000; font-weight:bold}.pdoc-code .kt{color:#B00040}.pdoc-code .m{color:#666666}.pdoc-code .s{color:#BA2121}.pdoc-code .na{color:#687822}.pdoc-code .nb{color:#008000}.pdoc-code .nc{color:#0000FF; font-weight:bold}.pdoc-code .no{color:#880000}.pdoc-code .nd{color:#AA22FF}.pdoc-code .ni{color:#717171; font-weight:bold}.pdoc-code .ne{color:#CB3F38; font-weight:bold}.pdoc-code .nf{color:#0000FF}.pdoc-code .nl{color:#767600}.pdoc-code .nn{color:#0000FF; font-weight:bold}.pdoc-code .nt{color:#008000; font-weight:bold}.pdoc-code .nv{color:#19177C}.pdoc-code .ow{color:#AA22FF; font-weight:bold}.pdoc-code .w{color:#bbbbbb}.pdoc-code .mb{color:#666666}.pdoc-code .mf{color:#666666}.pdoc-code .mh{color:#666666}.pdoc-code .mi{color:#666666}.pdoc-code .mo{color:#666666}.pdoc-code .sa{color:#BA2121}.pdoc-code .sb{color:#BA2121}.pdoc-code .sc{color:#BA2121}.pdoc-code .dl{color:#BA2121}.pdoc-code .sd{color:#BA2121; font-style:italic}.pdoc-code .s2{color:#BA2121}.pdoc-code .se{color:#AA5D1F; font-weight:bold}.pdoc-code .sh{color:#BA2121}.pdoc-code .si{color:#A45A77; font-weight:bold}.pdoc-code .sx{color:#008000}.pdoc-code .sr{color:#A45A77}.pdoc-code .s1{color:#BA2121}.pdoc-code .ss{color:#19177C}.pdoc-code .bp{color:#008000}.pdoc-code .fm{color:#0000FF}.pdoc-code .vc{color:#19177C}.pdoc-code .vg{color:#19177C}.pdoc-code .vi{color:#19177C}.pdoc-code .vm{color:#19177C}.pdoc-code .il{color:#666666}</style>
    <style>/*! theme.css */:root{--pdoc-background:#fff;}.pdoc{--text:#212529;--muted:#6c757d;--link:#3660a5;--link-hover:#1659c5;--code:#f8f8f8;--active:#fff598;--accent:#eee;--accent2:#c1c1c1;--nav-hover:rgba(255, 255, 255, 0.5);--name:#0066BB;--def:#008800;--annotation:#007020;}</style>
    <style>/*! layout.css */html, body{width:100%;height:100%;}html, main{scroll-behavior:smooth;}body{background-color:var(--pdoc-background);}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;z-index:999;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}header + main{margin-top:-3rem;}.git-button{display:none !important;}nav input[type="search"]{max-width:77%;}nav input[type="search"]:first-child{margin-top:-6px;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}header + main{margin-top:-4rem;}#navtoggle{display:none;}}#togglestate{position:absolute;height:0;opacity:0;}nav.pdoc{--pad:clamp(0.5rem, 2vw, 1.75rem);--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent; z-index:1}nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc .logo{max-width:calc(100% - var(--pad));max-height:35vh;display:block;margin:0 auto 1rem;transform:translate(calc(-.5 * var(--pad)), 0);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc > div > ul{margin-left:calc(0px - var(--pad));}nav.pdoc li a{padding:.2rem 0 .2rem calc(var(--pad) + var(--indent));}nav.pdoc > div > ul > li > a{padding-left:var(--pad);}nav.pdoc li{transition:all 100ms;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}nav.pdoc footer:before{content:"";display:block;width:calc(100% - var(--pad));border-top:solid var(--accent2) 1px;margin-top:1.5rem;padding-top:.5rem;}nav.pdoc footer{font-size:small;}</style>
    <style>/*! content.css */.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{cursor:pointer;display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .alert{padding:1rem 1rem 1rem calc(1.5rem + 24px);border:1px solid transparent;border-radius:.25rem;background-repeat:no-repeat;background-position:.75rem center;margin-bottom:1rem;}.pdoc .alert > em{display:none;}.pdoc .alert > *:last-child{margin-bottom:0;}.pdoc .alert.note{color:#084298;background-color:#cfe2ff;border-color:#b6d4fe;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23084298%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8%2016A8%208%200%201%200%208%200a8%208%200%200%200%200%2016zm.93-9.412-1%204.705c-.07.34.029.533.304.533.194%200%20.487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703%200-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381%202.29-.287zM8%205.5a1%201%200%201%201%200-2%201%201%200%200%201%200%202z%22/%3E%3C/svg%3E");}.pdoc .alert.tip{color:#0a3622;background-color:#d1e7dd;border-color:#a3cfbb;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%230a3622%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2%206a6%206%200%201%201%2010.174%204.31c-.203.196-.359.4-.453.619l-.762%201.769A.5.5%200%200%201%2010.5%2013a.5.5%200%200%201%200%201%20.5.5%200%200%201%200%201l-.224.447a1%201%200%200%201-.894.553H6.618a1%201%200%200%201-.894-.553L5.5%2015a.5.5%200%200%201%200-1%20.5.5%200%200%201%200-1%20.5.5%200%200%201-.46-.302l-.761-1.77a2%202%200%200%200-.453-.618A5.98%205.98%200%200%201%202%206m6-5a5%205%200%200%200-3.479%208.592c.263.254.514.564.676.941L5.83%2012h4.342l.632-1.467c.162-.377.413-.687.676-.941A5%205%200%200%200%208%201%22/%3E%3C/svg%3E");}.pdoc .alert.important{color:#055160;background-color:#cff4fc;border-color:#9eeaf9;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23055160%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2%200a2%202%200%200%200-2%202v12a2%202%200%200%200%202%202h12a2%202%200%200%200%202-2V2a2%202%200%200%200-2-2zm6%204c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%204.995A.905.905%200%200%201%208%204m.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2%22/%3E%3C/svg%3E");}.pdoc .alert.warning{color:#664d03;background-color:#fff3cd;border-color:#ffecb5;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23664d03%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8.982%201.566a1.13%201.13%200%200%200-1.96%200L.165%2013.233c-.457.778.091%201.767.98%201.767h13.713c.889%200%201.438-.99.98-1.767L8.982%201.566zM8%205c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%205.995A.905.905%200%200%201%208%205zm.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2z%22/%3E%3C/svg%3E");}.pdoc .alert.caution{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M11.46.146A.5.5%200%200%200%2011.107%200H4.893a.5.5%200%200%200-.353.146L.146%204.54A.5.5%200%200%200%200%204.893v6.214a.5.5%200%200%200%20.146.353l4.394%204.394a.5.5%200%200%200%20.353.146h6.214a.5.5%200%200%200%20.353-.146l4.394-4.394a.5.5%200%200%200%20.146-.353V4.893a.5.5%200%200%200-.146-.353zM8%204c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%204.995A.905.905%200%200%201%208%204m.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2%22/%3E%3C/svg%3E");}.pdoc .alert.danger{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5.52.359A.5.5%200%200%201%206%200h4a.5.5%200%200%201%20.474.658L8.694%206H12.5a.5.5%200%200%201%20.395.807l-7%209a.5.5%200%200%201-.873-.454L6.823%209.5H3.5a.5.5%200%200%201-.48-.641l2.5-8.5z%22/%3E%3C/svg%3E");}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc > section:not(.module-info) h1{font-size:1.5rem;font-weight:500;}.pdoc > section:not(.module-info) h2{font-size:1.4rem;font-weight:500;}.pdoc > section:not(.module-info) h3{font-size:1.3rem;font-weight:500;}.pdoc > section:not(.module-info) h4{font-size:1.2rem;}.pdoc > section:not(.module-info) h5{font-size:1.1rem;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-top:0;margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;background-color:var(--code);}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--accent);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc > section:not(.module-info){margin-bottom:1.5rem;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.view-source-toggle-state,.view-source-toggle-state ~ .pdoc-code{display:none;}.view-source-toggle-state:checked ~ .pdoc-code{display:block;}.view-source-button{display:inline-block;float:right;font-size:.75rem;line-height:1.5rem;color:var(--muted);padding:0 .4rem 0 1.3rem;cursor:pointer;text-indent:-2px;}.view-source-button > span{visibility:hidden;}.module-info .view-source-button{float:none;display:flex;justify-content:flex-end;margin:-1.2rem .4rem -.2rem 0;}.view-source-button::before{position:absolute;content:"View Source";display:list-item;list-style-type:disclosure-closed;}.view-source-toggle-state:checked ~ .attr .view-source-button::before,.view-source-toggle-state:checked ~ .view-source-button::before{list-style-type:disclosure-open;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc section:not(.module-info) .docstring{margin-left:clamp(0rem, 5vw - 2rem, 1rem);}.pdoc .docstring .pdoc-code{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target,.pdoc .pdoc-code > pre > span:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc .pdoc-code > pre > span:target{display:block;}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc *{scroll-margin:2rem;}.pdoc .pdoc-code .linenos{user-select:none;}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc section, .pdoc .classattr{position:relative;}.pdoc .headerlink{--width:clamp(1rem, 3vw, 2rem);position:absolute;top:0;left:calc(0rem - var(--width));transition:all 100ms ease-in-out;opacity:0;}.pdoc .headerlink::before{content:"#";display:block;text-align:center;width:var(--width);height:2.3rem;line-height:2.3rem;font-size:1.5rem;}.pdoc .attr:hover ~ .headerlink,.pdoc *:target > .headerlink,.pdoc .headerlink:hover{opacity:1;}.pdoc .attr{display:block;margin:.5rem 0 .5rem;padding:.4rem .4rem .4rem 1rem;background-color:var(--accent);overflow-x:auto;}.pdoc .classattr{margin-left:2rem;}.pdoc .decorator-deprecated{color:#842029;}.pdoc .decorator-deprecated ~ span{filter:grayscale(1) opacity(0.8);}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{background-color:transparent;}.pdoc .param, .pdoc .return-annotation{white-space:pre;}.pdoc .signature.multiline .param{display:block;}.pdoc .signature.condensed .param{display:inline-block;}.pdoc .annotation{color:var(--annotation);}.pdoc .view-value-toggle-state,.pdoc .view-value-toggle-state ~ .default_value{display:none;}.pdoc .view-value-toggle-state:checked ~ .default_value{display:inherit;}.pdoc .view-value-button{font-size:.5rem;vertical-align:middle;border-style:dashed;margin-top:-0.1rem;}.pdoc .view-value-button:hover{background:white;}.pdoc .view-value-button::before{content:"show";text-align:center;width:2.2em;display:inline-block;}.pdoc .view-value-toggle-state:checked ~ .view-value-button::before{content:"hide";}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:35px;vertical-align:middle;width:70px;transition:all 200ms;}.pdoc table{display:block;width:max-content;max-width:100%;overflow:auto;margin-bottom:1rem;}.pdoc table th{font-weight:600;}.pdoc table th, .pdoc table td{padding:6px 13px;border:1px solid var(--accent2);}</style>
    <style>/*! custom.css */</style></head>
<body>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>            <a class="pdoc-button module-list-button" href="../lumen_clip.html">
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-box-arrow-in-left" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M10 3.5a.5.5 0 0 0-.5-.5h-8a.5.5 0 0 0-.5.5v9a.5.5 0 0 0 .5.5h8a.5.5 0 0 0 .5-.5v-2a.5.5 0 0 1 1 0v2A1.5 1.5 0 0 1 9.5 14h-8A1.5 1.5 0 0 1 0 12.5v-9A1.5 1.5 0 0 1 1.5 2h8A1.5 1.5 0 0 1 11 3.5v2a.5.5 0 0 1-1 0v-2z"/>
  <path fill-rule="evenodd" d="M4.146 8.354a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H14.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3z"/>
</svg>                &nbsp;lumen_clip</a>


            <input type="search" placeholder="Search..." role="searchbox" aria-label="search"
                   pattern=".+" required>



            <h2>API Documentation</h2>
                <ul class="memberlist">
            <li>
                    <a class="class" href="#BaseClipBackend">BaseClipBackend</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#BaseClipBackend.__init__">BaseClipBackend</a>
                        </li>
                        <li>
                                <a class="variable" href="#BaseClipBackend.resources">resources</a>
                        </li>
                        <li>
                                <a class="function" href="#BaseClipBackend.initialize">initialize</a>
                        </li>
                        <li>
                                <a class="function" href="#BaseClipBackend.close">close</a>
                        </li>
                        <li>
                                <a class="variable" href="#BaseClipBackend.is_initialized">is_initialized</a>
                        </li>
                        <li>
                                <a class="function" href="#BaseClipBackend.text_to_vector">text_to_vector</a>
                        </li>
                        <li>
                                <a class="function" href="#BaseClipBackend.image_to_vector">image_to_vector</a>
                        </li>
                        <li>
                                <a class="function" href="#BaseClipBackend.image_batch_to_vectors">image_batch_to_vectors</a>
                        </li>
                        <li>
                                <a class="function" href="#BaseClipBackend.text_batch_to_vectors">text_batch_to_vectors</a>
                        </li>
                        <li>
                                <a class="function" href="#BaseClipBackend.get_info">get_info</a>
                        </li>
                        <li>
                                <a class="function" href="#BaseClipBackend.unit_normalize">unit_normalize</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#BackendInfo">BackendInfo</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#BackendInfo.__init__">BackendInfo</a>
                        </li>
                        <li>
                                <a class="variable" href="#BackendInfo.runtime">runtime</a>
                        </li>
                        <li>
                                <a class="variable" href="#BackendInfo.device">device</a>
                        </li>
                        <li>
                                <a class="variable" href="#BackendInfo.model_id">model_id</a>
                        </li>
                        <li>
                                <a class="variable" href="#BackendInfo.model_name">model_name</a>
                        </li>
                        <li>
                                <a class="variable" href="#BackendInfo.pretrained">pretrained</a>
                        </li>
                        <li>
                                <a class="variable" href="#BackendInfo.version">version</a>
                        </li>
                        <li>
                                <a class="variable" href="#BackendInfo.image_embedding_dim">image_embedding_dim</a>
                        </li>
                        <li>
                                <a class="variable" href="#BackendInfo.text_embedding_dim">text_embedding_dim</a>
                        </li>
                        <li>
                                <a class="variable" href="#BackendInfo.precisions">precisions</a>
                        </li>
                        <li>
                                <a class="variable" href="#BackendInfo.max_batch_size">max_batch_size</a>
                        </li>
                        <li>
                                <a class="variable" href="#BackendInfo.supports_image_batch">supports_image_batch</a>
                        </li>
                        <li>
                                <a class="variable" href="#BackendInfo.extra">extra</a>
                        </li>
                        <li>
                                <a class="function" href="#BackendInfo.as_dict">as_dict</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#RuntimeKind">RuntimeKind</a>
                            <ul class="memberlist">
                        <li>
                                <a class="variable" href="#RuntimeKind.TORCH">TORCH</a>
                        </li>
                        <li>
                                <a class="variable" href="#RuntimeKind.ONNXRT">ONNXRT</a>
                        </li>
                        <li>
                                <a class="variable" href="#RuntimeKind.RKNN">RKNN</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#TorchBackend">TorchBackend</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#TorchBackend.__init__">TorchBackend</a>
                        </li>
                        <li>
                                <a class="function" href="#TorchBackend.initialize">initialize</a>
                        </li>
                        <li>
                                <a class="function" href="#TorchBackend.close">close</a>
                        </li>
                        <li>
                                <a class="function" href="#TorchBackend.text_to_vector">text_to_vector</a>
                        </li>
                        <li>
                                <a class="function" href="#TorchBackend.image_to_vector">image_to_vector</a>
                        </li>
                        <li>
                                <a class="function" href="#TorchBackend.image_batch_to_vectors">image_batch_to_vectors</a>
                        </li>
                        <li>
                                <a class="function" href="#TorchBackend.text_batch_to_vectors">text_batch_to_vectors</a>
                        </li>
                        <li>
                                <a class="function" href="#TorchBackend.get_info">get_info</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#ONNXRTBackend">ONNXRTBackend</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#ONNXRTBackend.__init__">ONNXRTBackend</a>
                        </li>
                        <li>
                                <a class="function" href="#ONNXRTBackend.initialize">initialize</a>
                        </li>
                        <li>
                                <a class="function" href="#ONNXRTBackend.text_to_vector">text_to_vector</a>
                        </li>
                        <li>
                                <a class="function" href="#ONNXRTBackend.image_to_vector">image_to_vector</a>
                        </li>
                        <li>
                                <a class="function" href="#ONNXRTBackend.image_batch_to_vectors">image_batch_to_vectors</a>
                        </li>
                        <li>
                                <a class="function" href="#ONNXRTBackend.text_batch_to_vectors">text_batch_to_vectors</a>
                        </li>
                        <li>
                                <a class="function" href="#ONNXRTBackend.get_info">get_info</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#RKNNBackend">RKNNBackend</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#RKNNBackend.__init__">RKNNBackend</a>
                        </li>
                        <li>
                                <a class="function" href="#RKNNBackend.initialize">initialize</a>
                        </li>
                        <li>
                                <a class="function" href="#RKNNBackend.text_to_vector">text_to_vector</a>
                        </li>
                        <li>
                                <a class="function" href="#RKNNBackend.image_to_vector">image_to_vector</a>
                        </li>
                        <li>
                                <a class="function" href="#RKNNBackend.get_info">get_info</a>
                        </li>
                </ul>

            </li>
    </ul>



        <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev" target="_blank">
            built with <span class="visually-hidden">pdoc</span><img
                alt="pdoc logo"
                src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20role%3D%22img%22%20aria-label%3D%22pdoc%20logo%22%20width%3D%22300%22%20height%3D%22150%22%20viewBox%3D%22-1%200%2060%2030%22%3E%3Ctitle%3Epdoc%3C/title%3E%3Cpath%20d%3D%22M29.621%2021.293c-.011-.273-.214-.475-.511-.481a.5.5%200%200%200-.489.503l-.044%201.393c-.097.551-.695%201.215-1.566%201.704-.577.428-1.306.486-2.193.182-1.426-.617-2.467-1.654-3.304-2.487l-.173-.172a3.43%203.43%200%200%200-.365-.306.49.49%200%200%200-.286-.196c-1.718-1.06-4.931-1.47-7.353.191l-.219.15c-1.707%201.187-3.413%202.131-4.328%201.03-.02-.027-.49-.685-.141-1.763.233-.721.546-2.408.772-4.076.042-.09.067-.187.046-.288.166-1.347.277-2.625.241-3.351%201.378-1.008%202.271-2.586%202.271-4.362%200-.976-.272-1.935-.788-2.774-.057-.094-.122-.18-.184-.268.033-.167.052-.339.052-.516%200-1.477-1.202-2.679-2.679-2.679-.791%200-1.496.352-1.987.9a6.3%206.3%200%200%200-1.001.029c-.492-.564-1.207-.929-2.012-.929-1.477%200-2.679%201.202-2.679%202.679A2.65%202.65%200%200%200%20.97%206.554c-.383.747-.595%201.572-.595%202.41%200%202.311%201.507%204.29%203.635%205.107-.037.699-.147%202.27-.423%203.294l-.137.461c-.622%202.042-2.515%208.257%201.727%2010.643%201.614.908%203.06%201.248%204.317%201.248%202.665%200%204.492-1.524%205.322-2.401%201.476-1.559%202.886-1.854%206.491.82%201.877%201.393%203.514%201.753%204.861%201.068%202.223-1.713%202.811-3.867%203.399-6.374.077-.846.056-1.469.054-1.537zm-4.835%204.313c-.054.305-.156.586-.242.629-.034-.007-.131-.022-.307-.157-.145-.111-.314-.478-.456-.908.221.121.432.25.675.355.115.039.219.051.33.081zm-2.251-1.238c-.05.33-.158.648-.252.694-.022.001-.125-.018-.307-.157-.217-.166-.488-.906-.639-1.573.358.344.754.693%201.198%201.036zm-3.887-2.337c-.006-.116-.018-.231-.041-.342.635.145%201.189.368%201.599.625.097.231.166.481.174.642-.03.049-.055.101-.067.158-.046.013-.128.026-.298.004-.278-.037-.901-.57-1.367-1.087zm-1.127-.497c.116.306.176.625.12.71-.019.014-.117.045-.345.016-.206-.027-.604-.332-.986-.695.41-.051.816-.056%201.211-.031zm-4.535%201.535c.209.22.379.47.358.598-.006.041-.088.138-.351.234-.144.055-.539-.063-.979-.259a11.66%2011.66%200%200%200%20.972-.573zm.983-.664c.359-.237.738-.418%201.126-.554.25.237.479.548.457.694-.006.042-.087.138-.351.235-.174.064-.694-.105-1.232-.375zm-3.381%201.794c-.022.145-.061.29-.149.401-.133.166-.358.248-.69.251h-.002c-.133%200-.306-.26-.45-.621.417.091.854.07%201.291-.031zm-2.066-8.077a4.78%204.78%200%200%201-.775-.584c.172-.115.505-.254.88-.378l-.105.962zm-.331%202.302a10.32%2010.32%200%200%201-.828-.502c.202-.143.576-.328.984-.49l-.156.992zm-.45%202.157l-.701-.403c.214-.115.536-.249.891-.376a11.57%2011.57%200%200%201-.19.779zm-.181%201.716c.064.398.194.702.298.893-.194-.051-.435-.162-.736-.398.061-.119.224-.3.438-.495zM8.87%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zm-.735-.389a1.15%201.15%200%200%200-.314.783%201.16%201.16%200%200%200%201.162%201.162c.457%200%20.842-.27%201.032-.653.026.117.042.238.042.362a1.68%201.68%200%200%201-1.679%201.679%201.68%201.68%200%200%201-1.679-1.679c0-.843.626-1.535%201.436-1.654zM5.059%205.406A1.68%201.68%200%200%201%203.38%207.085a1.68%201.68%200%200%201-1.679-1.679c0-.037.009-.072.011-.109.21.3.541.508.935.508a1.16%201.16%200%200%200%201.162-1.162%201.14%201.14%200%200%200-.474-.912c.015%200%20.03-.005.045-.005.926.001%201.679.754%201.679%201.68zM3.198%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zM1.375%208.964c0-.52.103-1.035.288-1.52.466.394%201.06.64%201.717.64%201.144%200%202.116-.725%202.499-1.738.383%201.012%201.355%201.738%202.499%201.738.867%200%201.631-.421%202.121-1.062.307.605.478%201.267.478%201.942%200%202.486-2.153%204.51-4.801%204.51s-4.801-2.023-4.801-4.51zm24.342%2019.349c-.985.498-2.267.168-3.813-.979-3.073-2.281-5.453-3.199-7.813-.705-1.315%201.391-4.163%203.365-8.423.97-3.174-1.786-2.239-6.266-1.261-9.479l.146-.492c.276-1.02.395-2.457.444-3.268a6.11%206.11%200%200%200%201.18.115%206.01%206.01%200%200%200%202.536-.562l-.006.175c-.802.215-1.848.612-2.021%201.25-.079.295.021.601.274.837.219.203.415.364.598.501-.667.304-1.243.698-1.311%201.179-.02.144-.022.507.393.787.213.144.395.26.564.365-1.285.521-1.361.96-1.381%201.126-.018.142-.011.496.427.746l.854.489c-.473.389-.971.914-.999%201.429-.018.278.095.532.316.713.675.556%201.231.721%201.653.721.059%200%20.104-.014.158-.02.207.707.641%201.64%201.513%201.64h.013c.8-.008%201.236-.345%201.462-.626.173-.216.268-.457.325-.692.424.195.93.374%201.372.374.151%200%20.294-.021.423-.068.732-.27.944-.704.993-1.021.009-.061.003-.119.002-.179.266.086.538.147.789.147.15%200%20.294-.021.423-.069.542-.2.797-.489.914-.754.237.147.478.258.704.288.106.014.205.021.296.021.356%200%20.595-.101.767-.229.438.435%201.094.992%201.656%201.067.106.014.205.021.296.021a1.56%201.56%200%200%200%20.323-.035c.17.575.453%201.289.866%201.605.358.273.665.362.914.362a.99.99%200%200%200%20.421-.093%201.03%201.03%200%200%200%20.245-.164c.168.428.39.846.68%201.068.358.273.665.362.913.362a.99.99%200%200%200%20.421-.093c.317-.148.512-.448.639-.762.251.157.495.257.726.257.127%200%20.25-.024.37-.071.427-.17.706-.617.841-1.314.022-.015.047-.022.068-.038.067-.051.133-.104.196-.159-.443%201.486-1.107%202.761-2.086%203.257zM8.66%209.925a.5.5%200%201%200-1%200c0%20.653-.818%201.205-1.787%201.205s-1.787-.552-1.787-1.205a.5.5%200%201%200-1%200c0%201.216%201.25%202.205%202.787%202.205s2.787-.989%202.787-2.205zm4.4%2015.965l-.208.097c-2.661%201.258-4.708%201.436-6.086.527-1.542-1.017-1.88-3.19-1.844-4.198a.4.4%200%200%200-.385-.414c-.242-.029-.406.164-.414.385-.046%201.249.367%203.686%202.202%204.896.708.467%201.547.7%202.51.7%201.248%200%202.706-.392%204.362-1.174l.185-.086a.4.4%200%200%200%20.205-.527c-.089-.204-.326-.291-.527-.206zM9.547%202.292c.093.077.205.114.317.114a.5.5%200%200%200%20.318-.886L8.817.397a.5.5%200%200%200-.703.068.5.5%200%200%200%20.069.703l1.364%201.124zm-7.661-.065c.086%200%20.173-.022.253-.068l1.523-.893a.5.5%200%200%200-.506-.863l-1.523.892a.5.5%200%200%200-.179.685c.094.158.261.247.432.247z%22%20transform%3D%22matrix%28-1%200%200%201%2058%200%29%22%20fill%3D%22%233bb300%22/%3E%3Cpath%20d%3D%22M.3%2021.86V10.18q0-.46.02-.68.04-.22.18-.5.28-.54%201.34-.54%201.06%200%201.42.28.38.26.44.78.76-1.04%202.38-1.04%201.64%200%203.1%201.54%201.46%201.54%201.46%203.58%200%202.04-1.46%203.58-1.44%201.54-3.08%201.54-1.64%200-2.38-.92v4.04q0%20.46-.04.68-.02.22-.18.5-.14.3-.5.42-.36.12-.98.12-.62%200-1-.12-.36-.12-.52-.4-.14-.28-.18-.5-.02-.22-.02-.68zm3.96-9.42q-.46.54-.46%201.18%200%20.64.46%201.18.48.52%201.2.52.74%200%201.24-.52.52-.52.52-1.18%200-.66-.48-1.18-.48-.54-1.26-.54-.76%200-1.22.54zm14.741-8.36q.16-.3.54-.42.38-.12%201-.12.64%200%201.02.12.38.12.52.42.16.3.18.54.04.22.04.68v11.94q0%20.46-.04.7-.02.22-.18.5-.3.54-1.7.54-1.38%200-1.54-.98-.84.96-2.34.96-1.8%200-3.28-1.56-1.48-1.58-1.48-3.66%200-2.1%201.48-3.68%201.5-1.58%203.28-1.58%201.48%200%202.3%201v-4.2q0-.46.02-.68.04-.24.18-.52zm-3.24%2010.86q.52.54%201.26.54.74%200%201.22-.54.5-.54.5-1.18%200-.66-.48-1.22-.46-.56-1.26-.56-.8%200-1.28.56-.48.54-.48%201.2%200%20.66.52%201.2zm7.833-1.2q0-2.4%201.68-3.96%201.68-1.56%203.84-1.56%202.16%200%203.82%201.56%201.66%201.54%201.66%203.94%200%201.66-.86%202.96-.86%201.28-2.1%201.9-1.22.6-2.54.6-1.32%200-2.56-.64-1.24-.66-2.1-1.92-.84-1.28-.84-2.88zm4.18%201.44q.64.48%201.3.48.66%200%201.32-.5.66-.5.66-1.48%200-.98-.62-1.46-.62-.48-1.34-.48-.72%200-1.34.5-.62.5-.62%201.48%200%20.96.64%201.46zm11.412-1.44q0%20.84.56%201.32.56.46%201.18.46.64%200%201.18-.36.56-.38.9-.38.6%200%201.46%201.06.46.58.46%201.04%200%20.76-1.1%201.42-1.14.8-2.8.8-1.86%200-3.58-1.34-.82-.64-1.34-1.7-.52-1.08-.52-2.36%200-1.3.52-2.34.52-1.06%201.34-1.7%201.66-1.32%203.54-1.32.76%200%201.48.22.72.2%201.06.4l.32.2q.36.24.56.38.52.4.52.92%200%20.5-.42%201.14-.72%201.1-1.38%201.1-.38%200-1.08-.44-.36-.34-1.04-.34-.66%200-1.24.48-.58.48-.58%201.34z%22%20fill%3D%22green%22/%3E%3C/svg%3E"/>
        </a>
</div>
    </nav>
    <main class="pdoc">
            <section class="module-info">
                    <h1 class="modulename">
<a href="./../lumen_clip.html">lumen_clip</a><wbr>.backends    </h1>

                        <div class="docstring"><p>Backends package for CLIP-like model runtimes.</p>

<p>Exports:</p>

<ul>
<li>BaseClipBackend: abstract interface for runtime-agnostic backends</li>
<li>BackendInfo: metadata container describing runtime, device, and model info</li>
<li>RuntimeKind: enumeration of supported runtime families</li>
<li>TorchBackend: PyTorch/OpenCLIP implementation of BaseClipBackend</li>
<li>ONNXRTBackend: ONNX Runtime implementation scaffold of BaseClipBackend</li>
<li>RKNNBackend: RKNN backend shim (Linux-only optional; provided via separate module)</li>
</ul>
</div>

                        <input id="mod-backends-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">

                        <label class="view-source-button" for="mod-backends-view-source"><span>View Source</span></label>

                        <div class="pdoc-code codehilite"><pre><span></span><span id="L-1"><a href="#L-1"><span class="linenos"> 1</span></a><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-2"><a href="#L-2"><span class="linenos"> 2</span></a><span class="sd">Backends package for CLIP-like model runtimes.</span>
</span><span id="L-3"><a href="#L-3"><span class="linenos"> 3</span></a>
</span><span id="L-4"><a href="#L-4"><span class="linenos"> 4</span></a><span class="sd">Exports:</span>
</span><span id="L-5"><a href="#L-5"><span class="linenos"> 5</span></a><span class="sd">- BaseClipBackend: abstract interface for runtime-agnostic backends</span>
</span><span id="L-6"><a href="#L-6"><span class="linenos"> 6</span></a><span class="sd">- BackendInfo: metadata container describing runtime, device, and model info</span>
</span><span id="L-7"><a href="#L-7"><span class="linenos"> 7</span></a><span class="sd">- RuntimeKind: enumeration of supported runtime families</span>
</span><span id="L-8"><a href="#L-8"><span class="linenos"> 8</span></a><span class="sd">- TorchBackend: PyTorch/OpenCLIP implementation of BaseClipBackend</span>
</span><span id="L-9"><a href="#L-9"><span class="linenos"> 9</span></a><span class="sd">- ONNXRTBackend: ONNX Runtime implementation scaffold of BaseClipBackend</span>
</span><span id="L-10"><a href="#L-10"><span class="linenos">10</span></a><span class="sd">- RKNNBackend: RKNN backend shim (Linux-only optional; provided via separate module)</span>
</span><span id="L-11"><a href="#L-11"><span class="linenos">11</span></a><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-12"><a href="#L-12"><span class="linenos">12</span></a>
</span><span id="L-13"><a href="#L-13"><span class="linenos">13</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseClipBackend</span><span class="p">,</span> <span class="n">BackendInfo</span><span class="p">,</span> <span class="n">RuntimeKind</span>
</span><span id="L-14"><a href="#L-14"><span class="linenos">14</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">.torch_backend</span><span class="w"> </span><span class="kn">import</span> <span class="n">TorchBackend</span>
</span><span id="L-15"><a href="#L-15"><span class="linenos">15</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">.onnxrt_backend</span><span class="w"> </span><span class="kn">import</span> <span class="n">ONNXRTBackend</span>
</span><span id="L-16"><a href="#L-16"><span class="linenos">16</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">.rknn_backend</span><span class="w"> </span><span class="kn">import</span> <span class="n">RKNNBackend</span>
</span><span id="L-17"><a href="#L-17"><span class="linenos">17</span></a>
</span><span id="L-18"><a href="#L-18"><span class="linenos">18</span></a><span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="L-19"><a href="#L-19"><span class="linenos">19</span></a>    <span class="s2">&quot;BaseClipBackend&quot;</span><span class="p">,</span>
</span><span id="L-20"><a href="#L-20"><span class="linenos">20</span></a>    <span class="s2">&quot;BackendInfo&quot;</span><span class="p">,</span>
</span><span id="L-21"><a href="#L-21"><span class="linenos">21</span></a>    <span class="s2">&quot;RuntimeKind&quot;</span><span class="p">,</span>
</span><span id="L-22"><a href="#L-22"><span class="linenos">22</span></a>    <span class="s2">&quot;TorchBackend&quot;</span><span class="p">,</span>
</span><span id="L-23"><a href="#L-23"><span class="linenos">23</span></a>    <span class="s2">&quot;ONNXRTBackend&quot;</span><span class="p">,</span>
</span><span id="L-24"><a href="#L-24"><span class="linenos">24</span></a>    <span class="s2">&quot;RKNNBackend&quot;</span><span class="p">,</span>
</span><span id="L-25"><a href="#L-25"><span class="linenos">25</span></a><span class="p">]</span>
</span></pre></div>


            </section>
                <section id="BaseClipBackend">
                            <input id="BaseClipBackend-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">BaseClipBackend</span><wbr>(<span class="base">abc.ABC</span>):

                <label class="view-source-button" for="BaseClipBackend-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BaseClipBackend"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BaseClipBackend-98"><a href="#BaseClipBackend-98"><span class="linenos"> 98</span></a><span class="k">class</span><span class="w"> </span><span class="nc">BaseClipBackend</span><span class="p">(</span><span class="n">abc</span><span class="o">.</span><span class="n">ABC</span><span class="p">):</span>
</span><span id="BaseClipBackend-99"><a href="#BaseClipBackend-99"><span class="linenos"> 99</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BaseClipBackend-100"><a href="#BaseClipBackend-100"><span class="linenos">100</span></a><span class="sd">    Abstract base for CLIP-like backends.</span>
</span><span id="BaseClipBackend-101"><a href="#BaseClipBackend-101"><span class="linenos">101</span></a>
</span><span id="BaseClipBackend-102"><a href="#BaseClipBackend-102"><span class="linenos">102</span></a><span class="sd">    Implementations MUST:</span>
</span><span id="BaseClipBackend-103"><a href="#BaseClipBackend-103"><span class="linenos">103</span></a><span class="sd">    - Perform model loading in initialize()</span>
</span><span id="BaseClipBackend-104"><a href="#BaseClipBackend-104"><span class="linenos">104</span></a><span class="sd">    - Produce unit-normalized float32 vectors for text/image encoding</span>
</span><span id="BaseClipBackend-105"><a href="#BaseClipBackend-105"><span class="linenos">105</span></a><span class="sd">    - Provide accurate BackendInfo via get_info()</span>
</span><span id="BaseClipBackend-106"><a href="#BaseClipBackend-106"><span class="linenos">106</span></a>
</span><span id="BaseClipBackend-107"><a href="#BaseClipBackend-107"><span class="linenos">107</span></a><span class="sd">    Implementations MAY:</span>
</span><span id="BaseClipBackend-108"><a href="#BaseClipBackend-108"><span class="linenos">108</span></a><span class="sd">    - Override image_batch_to_vectors for true batched execution</span>
</span><span id="BaseClipBackend-109"><a href="#BaseClipBackend-109"><span class="linenos">109</span></a><span class="sd">    - Expose runtime-specific knobs via `extra` in BackendInfo</span>
</span><span id="BaseClipBackend-110"><a href="#BaseClipBackend-110"><span class="linenos">110</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="BaseClipBackend-111"><a href="#BaseClipBackend-111"><span class="linenos">111</span></a>
</span><span id="BaseClipBackend-112"><a href="#BaseClipBackend-112"><span class="linenos">112</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="BaseClipBackend-113"><a href="#BaseClipBackend-113"><span class="linenos">113</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="BaseClipBackend-114"><a href="#BaseClipBackend-114"><span class="linenos">114</span></a>        <span class="n">resources</span><span class="p">:</span> <span class="s2">&quot;ModelResources&quot;</span><span class="p">,</span>
</span><span id="BaseClipBackend-115"><a href="#BaseClipBackend-115"><span class="linenos">115</span></a>        <span class="n">device_preference</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="BaseClipBackend-116"><a href="#BaseClipBackend-116"><span class="linenos">116</span></a>        <span class="n">max_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="BaseClipBackend-117"><a href="#BaseClipBackend-117"><span class="linenos">117</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="BaseClipBackend-118"><a href="#BaseClipBackend-118"><span class="linenos">118</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BaseClipBackend-119"><a href="#BaseClipBackend-119"><span class="linenos">119</span></a><span class="sd">        Construct a backend with model resources.</span>
</span><span id="BaseClipBackend-120"><a href="#BaseClipBackend-120"><span class="linenos">120</span></a>
</span><span id="BaseClipBackend-121"><a href="#BaseClipBackend-121"><span class="linenos">121</span></a><span class="sd">        Args:</span>
</span><span id="BaseClipBackend-122"><a href="#BaseClipBackend-122"><span class="linenos">122</span></a><span class="sd">            resources: ModelResources object containing all model files and configs</span>
</span><span id="BaseClipBackend-123"><a href="#BaseClipBackend-123"><span class="linenos">123</span></a><span class="sd">            device_preference: Hint for device selection (e.g., &quot;cuda&quot;, &quot;mps&quot;, &quot;cpu&quot;).</span>
</span><span id="BaseClipBackend-124"><a href="#BaseClipBackend-124"><span class="linenos">124</span></a><span class="sd">            max_batch_size: Hint for batching; implementation may clamp lower/higher.</span>
</span><span id="BaseClipBackend-125"><a href="#BaseClipBackend-125"><span class="linenos">125</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaseClipBackend-126"><a href="#BaseClipBackend-126"><span class="linenos">126</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="BaseClipBackend-127"><a href="#BaseClipBackend-127"><span class="linenos">127</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">resources</span> <span class="o">=</span> <span class="n">resources</span>
</span><span id="BaseClipBackend-128"><a href="#BaseClipBackend-128"><span class="linenos">128</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_device_pref</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="n">device_preference</span>
</span><span id="BaseClipBackend-129"><a href="#BaseClipBackend-129"><span class="linenos">129</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_max_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="n">max_batch_size</span>
</span><span id="BaseClipBackend-130"><a href="#BaseClipBackend-130"><span class="linenos">130</span></a>
</span><span id="BaseClipBackend-131"><a href="#BaseClipBackend-131"><span class="linenos">131</span></a>    <span class="c1"># ---------- Lifecycle ----------</span>
</span><span id="BaseClipBackend-132"><a href="#BaseClipBackend-132"><span class="linenos">132</span></a>
</span><span id="BaseClipBackend-133"><a href="#BaseClipBackend-133"><span class="linenos">133</span></a>    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="BaseClipBackend-134"><a href="#BaseClipBackend-134"><span class="linenos">134</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="BaseClipBackend-135"><a href="#BaseClipBackend-135"><span class="linenos">135</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Load weights and prepare runtime resources. Must be idempotent.&quot;&quot;&quot;</span>
</span><span id="BaseClipBackend-136"><a href="#BaseClipBackend-136"><span class="linenos">136</span></a>        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="BaseClipBackend-137"><a href="#BaseClipBackend-137"><span class="linenos">137</span></a>
</span><span id="BaseClipBackend-138"><a href="#BaseClipBackend-138"><span class="linenos">138</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="BaseClipBackend-139"><a href="#BaseClipBackend-139"><span class="linenos">139</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Release runtime resources. Optional override.&quot;&quot;&quot;</span>
</span><span id="BaseClipBackend-140"><a href="#BaseClipBackend-140"><span class="linenos">140</span></a>        <span class="c1"># Default no-op</span>
</span><span id="BaseClipBackend-141"><a href="#BaseClipBackend-141"><span class="linenos">141</span></a>        <span class="k">return</span>
</span><span id="BaseClipBackend-142"><a href="#BaseClipBackend-142"><span class="linenos">142</span></a>
</span><span id="BaseClipBackend-143"><a href="#BaseClipBackend-143"><span class="linenos">143</span></a>    <span class="nd">@property</span>
</span><span id="BaseClipBackend-144"><a href="#BaseClipBackend-144"><span class="linenos">144</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">is_initialized</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
</span><span id="BaseClipBackend-145"><a href="#BaseClipBackend-145"><span class="linenos">145</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Whether initialize() has successfully completed.&quot;&quot;&quot;</span>
</span><span id="BaseClipBackend-146"><a href="#BaseClipBackend-146"><span class="linenos">146</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span>
</span><span id="BaseClipBackend-147"><a href="#BaseClipBackend-147"><span class="linenos">147</span></a>
</span><span id="BaseClipBackend-148"><a href="#BaseClipBackend-148"><span class="linenos">148</span></a>    <span class="c1"># ---------- Encoding API (unit-normalized float32) ----------</span>
</span><span id="BaseClipBackend-149"><a href="#BaseClipBackend-149"><span class="linenos">149</span></a>
</span><span id="BaseClipBackend-150"><a href="#BaseClipBackend-150"><span class="linenos">150</span></a>    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="BaseClipBackend-151"><a href="#BaseClipBackend-151"><span class="linenos">151</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">text_to_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="BaseClipBackend-152"><a href="#BaseClipBackend-152"><span class="linenos">152</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BaseClipBackend-153"><a href="#BaseClipBackend-153"><span class="linenos">153</span></a><span class="sd">        Encode a text string to a unit-normalized embedding vector.</span>
</span><span id="BaseClipBackend-154"><a href="#BaseClipBackend-154"><span class="linenos">154</span></a>
</span><span id="BaseClipBackend-155"><a href="#BaseClipBackend-155"><span class="linenos">155</span></a><span class="sd">        Returns:</span>
</span><span id="BaseClipBackend-156"><a href="#BaseClipBackend-156"><span class="linenos">156</span></a><span class="sd">            np.ndarray with shape (D,) and dtype float32, L2-normalized to 1.0</span>
</span><span id="BaseClipBackend-157"><a href="#BaseClipBackend-157"><span class="linenos">157</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaseClipBackend-158"><a href="#BaseClipBackend-158"><span class="linenos">158</span></a>        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="BaseClipBackend-159"><a href="#BaseClipBackend-159"><span class="linenos">159</span></a>
</span><span id="BaseClipBackend-160"><a href="#BaseClipBackend-160"><span class="linenos">160</span></a>    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="BaseClipBackend-161"><a href="#BaseClipBackend-161"><span class="linenos">161</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">image_to_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_bytes</span><span class="p">:</span> <span class="nb">bytes</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="BaseClipBackend-162"><a href="#BaseClipBackend-162"><span class="linenos">162</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BaseClipBackend-163"><a href="#BaseClipBackend-163"><span class="linenos">163</span></a><span class="sd">        Encode image bytes to a unit-normalized embedding vector.</span>
</span><span id="BaseClipBackend-164"><a href="#BaseClipBackend-164"><span class="linenos">164</span></a>
</span><span id="BaseClipBackend-165"><a href="#BaseClipBackend-165"><span class="linenos">165</span></a><span class="sd">        Returns:</span>
</span><span id="BaseClipBackend-166"><a href="#BaseClipBackend-166"><span class="linenos">166</span></a><span class="sd">            np.ndarray with shape (D,) and dtype float32, L2-normalized to 1.0</span>
</span><span id="BaseClipBackend-167"><a href="#BaseClipBackend-167"><span class="linenos">167</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaseClipBackend-168"><a href="#BaseClipBackend-168"><span class="linenos">168</span></a>        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="BaseClipBackend-169"><a href="#BaseClipBackend-169"><span class="linenos">169</span></a>
</span><span id="BaseClipBackend-170"><a href="#BaseClipBackend-170"><span class="linenos">170</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">image_batch_to_vectors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">bytes</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="BaseClipBackend-171"><a href="#BaseClipBackend-171"><span class="linenos">171</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BaseClipBackend-172"><a href="#BaseClipBackend-172"><span class="linenos">172</span></a><span class="sd">        Encode a list of image bytes into a batch of unit-normalized vectors.</span>
</span><span id="BaseClipBackend-173"><a href="#BaseClipBackend-173"><span class="linenos">173</span></a>
</span><span id="BaseClipBackend-174"><a href="#BaseClipBackend-174"><span class="linenos">174</span></a><span class="sd">        Defaults to a sequential fallback using image_to_vector(). Backends that</span>
</span><span id="BaseClipBackend-175"><a href="#BaseClipBackend-175"><span class="linenos">175</span></a><span class="sd">        support true batched execution should override for better throughput.</span>
</span><span id="BaseClipBackend-176"><a href="#BaseClipBackend-176"><span class="linenos">176</span></a>
</span><span id="BaseClipBackend-177"><a href="#BaseClipBackend-177"><span class="linenos">177</span></a><span class="sd">        Returns:</span>
</span><span id="BaseClipBackend-178"><a href="#BaseClipBackend-178"><span class="linenos">178</span></a><span class="sd">            np.ndarray with shape (N, D) and dtype float32, each row L2-normalized.</span>
</span><span id="BaseClipBackend-179"><a href="#BaseClipBackend-179"><span class="linenos">179</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaseClipBackend-180"><a href="#BaseClipBackend-180"><span class="linenos">180</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">images</span><span class="p">:</span>
</span><span id="BaseClipBackend-181"><a href="#BaseClipBackend-181"><span class="linenos">181</span></a>            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="BaseClipBackend-182"><a href="#BaseClipBackend-182"><span class="linenos">182</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="BaseClipBackend-183"><a href="#BaseClipBackend-183"><span class="linenos">183</span></a>            <span class="n">vecs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="BaseClipBackend-184"><a href="#BaseClipBackend-184"><span class="linenos">184</span></a>            <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">images</span><span class="p">:</span>
</span><span id="BaseClipBackend-185"><a href="#BaseClipBackend-185"><span class="linenos">185</span></a>                <span class="k">try</span><span class="p">:</span>
</span><span id="BaseClipBackend-186"><a href="#BaseClipBackend-186"><span class="linenos">186</span></a>                    <span class="n">vec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_to_vector</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</span><span id="BaseClipBackend-187"><a href="#BaseClipBackend-187"><span class="linenos">187</span></a>                    <span class="n">vecs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vec</span><span class="p">)</span>
</span><span id="BaseClipBackend-188"><a href="#BaseClipBackend-188"><span class="linenos">188</span></a>                <span class="k">except</span> <span class="p">(</span><span class="n">BackendError</span><span class="p">,</span> <span class="ne">RuntimeError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="BaseClipBackend-189"><a href="#BaseClipBackend-189"><span class="linenos">189</span></a>                    <span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
</span><span id="BaseClipBackend-190"><a href="#BaseClipBackend-190"><span class="linenos">190</span></a>
</span><span id="BaseClipBackend-191"><a href="#BaseClipBackend-191"><span class="linenos">191</span></a>                    <span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
</span><span id="BaseClipBackend-192"><a href="#BaseClipBackend-192"><span class="linenos">192</span></a>                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to encode one image in batch: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="BaseClipBackend-193"><a href="#BaseClipBackend-193"><span class="linenos">193</span></a>                    <span class="k">continue</span>
</span><span id="BaseClipBackend-194"><a href="#BaseClipBackend-194"><span class="linenos">194</span></a>
</span><span id="BaseClipBackend-195"><a href="#BaseClipBackend-195"><span class="linenos">195</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="n">vecs</span><span class="p">:</span>
</span><span id="BaseClipBackend-196"><a href="#BaseClipBackend-196"><span class="linenos">196</span></a>                <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span><span class="s2">&quot;All images in batch failed to encode&quot;</span><span class="p">)</span>
</span><span id="BaseClipBackend-197"><a href="#BaseClipBackend-197"><span class="linenos">197</span></a>
</span><span id="BaseClipBackend-198"><a href="#BaseClipBackend-198"><span class="linenos">198</span></a>            <span class="c1"># Validate consistent dims</span>
</span><span id="BaseClipBackend-199"><a href="#BaseClipBackend-199"><span class="linenos">199</span></a>            <span class="n">dim</span> <span class="o">=</span> <span class="n">vecs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="BaseClipBackend-200"><a href="#BaseClipBackend-200"><span class="linenos">200</span></a>            <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">vecs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="BaseClipBackend-201"><a href="#BaseClipBackend-201"><span class="linenos">201</span></a>            <span class="k">if</span> <span class="n">out</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">2</span> <span class="ow">or</span> <span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">dim</span><span class="p">:</span>
</span><span id="BaseClipBackend-202"><a href="#BaseClipBackend-202"><span class="linenos">202</span></a>                <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span>
</span><span id="BaseClipBackend-203"><a href="#BaseClipBackend-203"><span class="linenos">203</span></a>                    <span class="s2">&quot;image_batch_to_vectors: inconsistent vector dimensions.&quot;</span>
</span><span id="BaseClipBackend-204"><a href="#BaseClipBackend-204"><span class="linenos">204</span></a>                <span class="p">)</span>
</span><span id="BaseClipBackend-205"><a href="#BaseClipBackend-205"><span class="linenos">205</span></a>            <span class="k">return</span> <span class="n">out</span>
</span><span id="BaseClipBackend-206"><a href="#BaseClipBackend-206"><span class="linenos">206</span></a>
</span><span id="BaseClipBackend-207"><a href="#BaseClipBackend-207"><span class="linenos">207</span></a>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="BaseClipBackend-208"><a href="#BaseClipBackend-208"><span class="linenos">208</span></a>            <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Batch image encoding failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span><span id="BaseClipBackend-209"><a href="#BaseClipBackend-209"><span class="linenos">209</span></a>
</span><span id="BaseClipBackend-210"><a href="#BaseClipBackend-210"><span class="linenos">210</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">text_batch_to_vectors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">texts</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="BaseClipBackend-211"><a href="#BaseClipBackend-211"><span class="linenos">211</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BaseClipBackend-212"><a href="#BaseClipBackend-212"><span class="linenos">212</span></a><span class="sd">        Encode a list of text strings into a batch of unit-normalized vectors.</span>
</span><span id="BaseClipBackend-213"><a href="#BaseClipBackend-213"><span class="linenos">213</span></a>
</span><span id="BaseClipBackend-214"><a href="#BaseClipBackend-214"><span class="linenos">214</span></a><span class="sd">        Defaults to a sequential fallback using text_to_vector(). Backends that</span>
</span><span id="BaseClipBackend-215"><a href="#BaseClipBackend-215"><span class="linenos">215</span></a><span class="sd">        support true batched execution should override for better throughput.</span>
</span><span id="BaseClipBackend-216"><a href="#BaseClipBackend-216"><span class="linenos">216</span></a>
</span><span id="BaseClipBackend-217"><a href="#BaseClipBackend-217"><span class="linenos">217</span></a><span class="sd">        Returns:</span>
</span><span id="BaseClipBackend-218"><a href="#BaseClipBackend-218"><span class="linenos">218</span></a><span class="sd">            np.ndarray with shape (N, D) and dtype float32, each row L2-normalized.</span>
</span><span id="BaseClipBackend-219"><a href="#BaseClipBackend-219"><span class="linenos">219</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaseClipBackend-220"><a href="#BaseClipBackend-220"><span class="linenos">220</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">texts</span><span class="p">:</span>
</span><span id="BaseClipBackend-221"><a href="#BaseClipBackend-221"><span class="linenos">221</span></a>            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="BaseClipBackend-222"><a href="#BaseClipBackend-222"><span class="linenos">222</span></a>
</span><span id="BaseClipBackend-223"><a href="#BaseClipBackend-223"><span class="linenos">223</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="BaseClipBackend-224"><a href="#BaseClipBackend-224"><span class="linenos">224</span></a>            <span class="n">vecs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="BaseClipBackend-225"><a href="#BaseClipBackend-225"><span class="linenos">225</span></a>            <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">:</span>
</span><span id="BaseClipBackend-226"><a href="#BaseClipBackend-226"><span class="linenos">226</span></a>                <span class="k">try</span><span class="p">:</span>
</span><span id="BaseClipBackend-227"><a href="#BaseClipBackend-227"><span class="linenos">227</span></a>                    <span class="n">vec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_to_vector</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</span><span id="BaseClipBackend-228"><a href="#BaseClipBackend-228"><span class="linenos">228</span></a>                    <span class="n">vecs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vec</span><span class="p">)</span>
</span><span id="BaseClipBackend-229"><a href="#BaseClipBackend-229"><span class="linenos">229</span></a>                <span class="k">except</span> <span class="p">(</span><span class="n">BackendError</span><span class="p">,</span> <span class="ne">RuntimeError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="BaseClipBackend-230"><a href="#BaseClipBackend-230"><span class="linenos">230</span></a>                    <span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
</span><span id="BaseClipBackend-231"><a href="#BaseClipBackend-231"><span class="linenos">231</span></a>
</span><span id="BaseClipBackend-232"><a href="#BaseClipBackend-232"><span class="linenos">232</span></a>                    <span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
</span><span id="BaseClipBackend-233"><a href="#BaseClipBackend-233"><span class="linenos">233</span></a>                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to encode one text in batch: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="BaseClipBackend-234"><a href="#BaseClipBackend-234"><span class="linenos">234</span></a>                    <span class="k">continue</span>
</span><span id="BaseClipBackend-235"><a href="#BaseClipBackend-235"><span class="linenos">235</span></a>
</span><span id="BaseClipBackend-236"><a href="#BaseClipBackend-236"><span class="linenos">236</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="n">vecs</span><span class="p">:</span>
</span><span id="BaseClipBackend-237"><a href="#BaseClipBackend-237"><span class="linenos">237</span></a>                <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span><span class="s2">&quot;All texts in batch failed to encode&quot;</span><span class="p">)</span>
</span><span id="BaseClipBackend-238"><a href="#BaseClipBackend-238"><span class="linenos">238</span></a>
</span><span id="BaseClipBackend-239"><a href="#BaseClipBackend-239"><span class="linenos">239</span></a>            <span class="c1"># Validate consistent dims</span>
</span><span id="BaseClipBackend-240"><a href="#BaseClipBackend-240"><span class="linenos">240</span></a>            <span class="n">dim</span> <span class="o">=</span> <span class="n">vecs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="BaseClipBackend-241"><a href="#BaseClipBackend-241"><span class="linenos">241</span></a>            <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">vecs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="BaseClipBackend-242"><a href="#BaseClipBackend-242"><span class="linenos">242</span></a>            <span class="k">if</span> <span class="n">out</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">2</span> <span class="ow">or</span> <span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">dim</span><span class="p">:</span>
</span><span id="BaseClipBackend-243"><a href="#BaseClipBackend-243"><span class="linenos">243</span></a>                <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span>
</span><span id="BaseClipBackend-244"><a href="#BaseClipBackend-244"><span class="linenos">244</span></a>                    <span class="s2">&quot;text_batch_to_vectors: inconsistent vector dimensions.&quot;</span>
</span><span id="BaseClipBackend-245"><a href="#BaseClipBackend-245"><span class="linenos">245</span></a>                <span class="p">)</span>
</span><span id="BaseClipBackend-246"><a href="#BaseClipBackend-246"><span class="linenos">246</span></a>            <span class="k">return</span> <span class="n">out</span>
</span><span id="BaseClipBackend-247"><a href="#BaseClipBackend-247"><span class="linenos">247</span></a>
</span><span id="BaseClipBackend-248"><a href="#BaseClipBackend-248"><span class="linenos">248</span></a>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="BaseClipBackend-249"><a href="#BaseClipBackend-249"><span class="linenos">249</span></a>            <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Batch text encoding failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span><span id="BaseClipBackend-250"><a href="#BaseClipBackend-250"><span class="linenos">250</span></a>
</span><span id="BaseClipBackend-251"><a href="#BaseClipBackend-251"><span class="linenos">251</span></a>    <span class="c1"># ---------- Metadata ----------</span>
</span><span id="BaseClipBackend-252"><a href="#BaseClipBackend-252"><span class="linenos">252</span></a>
</span><span id="BaseClipBackend-253"><a href="#BaseClipBackend-253"><span class="linenos">253</span></a>    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="BaseClipBackend-254"><a href="#BaseClipBackend-254"><span class="linenos">254</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_info</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BackendInfo</span><span class="p">:</span>
</span><span id="BaseClipBackend-255"><a href="#BaseClipBackend-255"><span class="linenos">255</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BaseClipBackend-256"><a href="#BaseClipBackend-256"><span class="linenos">256</span></a><span class="sd">        Return a BackendInfo describing runtime, device, model identifiers,</span>
</span><span id="BaseClipBackend-257"><a href="#BaseClipBackend-257"><span class="linenos">257</span></a><span class="sd">        embedding dimensions, precision supports, batchability, etc.</span>
</span><span id="BaseClipBackend-258"><a href="#BaseClipBackend-258"><span class="linenos">258</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaseClipBackend-259"><a href="#BaseClipBackend-259"><span class="linenos">259</span></a>        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="BaseClipBackend-260"><a href="#BaseClipBackend-260"><span class="linenos">260</span></a>
</span><span id="BaseClipBackend-261"><a href="#BaseClipBackend-261"><span class="linenos">261</span></a>    <span class="c1"># ---------- Utilities (reusable across backends/managers) ----------</span>
</span><span id="BaseClipBackend-262"><a href="#BaseClipBackend-262"><span class="linenos">262</span></a>
</span><span id="BaseClipBackend-263"><a href="#BaseClipBackend-263"><span class="linenos">263</span></a>    <span class="nd">@staticmethod</span>
</span><span id="BaseClipBackend-264"><a href="#BaseClipBackend-264"><span class="linenos">264</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">unit_normalize</span><span class="p">(</span>
</span><span id="BaseClipBackend-265"><a href="#BaseClipBackend-265"><span class="linenos">265</span></a>        <span class="n">vec</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">],</span> <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span>
</span><span id="BaseClipBackend-266"><a href="#BaseClipBackend-266"><span class="linenos">266</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="BaseClipBackend-267"><a href="#BaseClipBackend-267"><span class="linenos">267</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BaseClipBackend-268"><a href="#BaseClipBackend-268"><span class="linenos">268</span></a><span class="sd">        L2-normalize vectors along the given axis.</span>
</span><span id="BaseClipBackend-269"><a href="#BaseClipBackend-269"><span class="linenos">269</span></a>
</span><span id="BaseClipBackend-270"><a href="#BaseClipBackend-270"><span class="linenos">270</span></a><span class="sd">        Args:</span>
</span><span id="BaseClipBackend-271"><a href="#BaseClipBackend-271"><span class="linenos">271</span></a><span class="sd">            vec: Input array</span>
</span><span id="BaseClipBackend-272"><a href="#BaseClipBackend-272"><span class="linenos">272</span></a><span class="sd">            axis: Axis to normalize over</span>
</span><span id="BaseClipBackend-273"><a href="#BaseClipBackend-273"><span class="linenos">273</span></a><span class="sd">            eps: Numerical stability epsilon</span>
</span><span id="BaseClipBackend-274"><a href="#BaseClipBackend-274"><span class="linenos">274</span></a>
</span><span id="BaseClipBackend-275"><a href="#BaseClipBackend-275"><span class="linenos">275</span></a><span class="sd">        Returns:</span>
</span><span id="BaseClipBackend-276"><a href="#BaseClipBackend-276"><span class="linenos">276</span></a><span class="sd">            Unit-normalized array (float32)</span>
</span><span id="BaseClipBackend-277"><a href="#BaseClipBackend-277"><span class="linenos">277</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaseClipBackend-278"><a href="#BaseClipBackend-278"><span class="linenos">278</span></a>        <span class="n">v</span> <span class="o">=</span> <span class="n">vec</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="BaseClipBackend-279"><a href="#BaseClipBackend-279"><span class="linenos">279</span></a>        <span class="n">norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="BaseClipBackend-280"><a href="#BaseClipBackend-280"><span class="linenos">280</span></a>        <span class="n">norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">norm</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span>
</span><span id="BaseClipBackend-281"><a href="#BaseClipBackend-281"><span class="linenos">281</span></a>        <span class="k">return</span> <span class="n">v</span> <span class="o">/</span> <span class="n">norm</span>
</span></pre></div>


            <div class="docstring"><p>Abstract base for CLIP-like backends.</p>

<p>Implementations MUST:</p>

<ul>
<li>Perform model loading in initialize()</li>
<li>Produce unit-normalized float32 vectors for text/image encoding</li>
<li>Provide accurate BackendInfo via get_info()</li>
</ul>

<p>Implementations MAY:</p>

<ul>
<li>Override image_batch_to_vectors for true batched execution</li>
<li>Expose runtime-specific knobs via <code>extra</code> in BackendInfo</li>
</ul>
</div>


                            <div id="BaseClipBackend.__init__" class="classattr">
                                        <input id="BaseClipBackend.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">BaseClipBackend</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">resources</span><span class="p">:</span> <span class="n"><a href="resources.html#ModelResources">lumen_clip.resources.ModelResources</a></span>,</span><span class="param">	<span class="n">device_preference</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">max_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="BaseClipBackend.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BaseClipBackend.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BaseClipBackend.__init__-112"><a href="#BaseClipBackend.__init__-112"><span class="linenos">112</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="BaseClipBackend.__init__-113"><a href="#BaseClipBackend.__init__-113"><span class="linenos">113</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="BaseClipBackend.__init__-114"><a href="#BaseClipBackend.__init__-114"><span class="linenos">114</span></a>        <span class="n">resources</span><span class="p">:</span> <span class="s2">&quot;ModelResources&quot;</span><span class="p">,</span>
</span><span id="BaseClipBackend.__init__-115"><a href="#BaseClipBackend.__init__-115"><span class="linenos">115</span></a>        <span class="n">device_preference</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="BaseClipBackend.__init__-116"><a href="#BaseClipBackend.__init__-116"><span class="linenos">116</span></a>        <span class="n">max_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="BaseClipBackend.__init__-117"><a href="#BaseClipBackend.__init__-117"><span class="linenos">117</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="BaseClipBackend.__init__-118"><a href="#BaseClipBackend.__init__-118"><span class="linenos">118</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BaseClipBackend.__init__-119"><a href="#BaseClipBackend.__init__-119"><span class="linenos">119</span></a><span class="sd">        Construct a backend with model resources.</span>
</span><span id="BaseClipBackend.__init__-120"><a href="#BaseClipBackend.__init__-120"><span class="linenos">120</span></a>
</span><span id="BaseClipBackend.__init__-121"><a href="#BaseClipBackend.__init__-121"><span class="linenos">121</span></a><span class="sd">        Args:</span>
</span><span id="BaseClipBackend.__init__-122"><a href="#BaseClipBackend.__init__-122"><span class="linenos">122</span></a><span class="sd">            resources: ModelResources object containing all model files and configs</span>
</span><span id="BaseClipBackend.__init__-123"><a href="#BaseClipBackend.__init__-123"><span class="linenos">123</span></a><span class="sd">            device_preference: Hint for device selection (e.g., &quot;cuda&quot;, &quot;mps&quot;, &quot;cpu&quot;).</span>
</span><span id="BaseClipBackend.__init__-124"><a href="#BaseClipBackend.__init__-124"><span class="linenos">124</span></a><span class="sd">            max_batch_size: Hint for batching; implementation may clamp lower/higher.</span>
</span><span id="BaseClipBackend.__init__-125"><a href="#BaseClipBackend.__init__-125"><span class="linenos">125</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaseClipBackend.__init__-126"><a href="#BaseClipBackend.__init__-126"><span class="linenos">126</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="BaseClipBackend.__init__-127"><a href="#BaseClipBackend.__init__-127"><span class="linenos">127</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">resources</span> <span class="o">=</span> <span class="n">resources</span>
</span><span id="BaseClipBackend.__init__-128"><a href="#BaseClipBackend.__init__-128"><span class="linenos">128</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_device_pref</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="n">device_preference</span>
</span><span id="BaseClipBackend.__init__-129"><a href="#BaseClipBackend.__init__-129"><span class="linenos">129</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_max_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="n">max_batch_size</span>
</span></pre></div>


            <div class="docstring"><p>Construct a backend with model resources.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>resources:</strong>  ModelResources object containing all model files and configs</li>
<li><strong>device_preference:</strong>  Hint for device selection (e.g., "cuda", "mps", "cpu").</li>
<li><strong>max_batch_size:</strong>  Hint for batching; implementation may clamp lower/higher.</li>
</ul>
</div>


                            </div>
                            <div id="BaseClipBackend.resources" class="classattr">
                                <div class="attr variable">
            <span class="name">resources</span>

        
    </div>
    <a class="headerlink" href="#BaseClipBackend.resources"></a>
    
    

                            </div>
                            <div id="BaseClipBackend.initialize" class="classattr">
                                        <input id="BaseClipBackend.initialize-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-abc.abstractmethod">@abc.abstractmethod</div>

        <span class="def">def</span>
        <span class="name">initialize</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

                <label class="view-source-button" for="BaseClipBackend.initialize-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BaseClipBackend.initialize"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BaseClipBackend.initialize-133"><a href="#BaseClipBackend.initialize-133"><span class="linenos">133</span></a>    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="BaseClipBackend.initialize-134"><a href="#BaseClipBackend.initialize-134"><span class="linenos">134</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="BaseClipBackend.initialize-135"><a href="#BaseClipBackend.initialize-135"><span class="linenos">135</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Load weights and prepare runtime resources. Must be idempotent.&quot;&quot;&quot;</span>
</span><span id="BaseClipBackend.initialize-136"><a href="#BaseClipBackend.initialize-136"><span class="linenos">136</span></a>        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></pre></div>


            <div class="docstring"><p>Load weights and prepare runtime resources. Must be idempotent.</p>
</div>


                            </div>
                            <div id="BaseClipBackend.close" class="classattr">
                                        <input id="BaseClipBackend.close-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">close</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

                <label class="view-source-button" for="BaseClipBackend.close-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BaseClipBackend.close"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BaseClipBackend.close-138"><a href="#BaseClipBackend.close-138"><span class="linenos">138</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="BaseClipBackend.close-139"><a href="#BaseClipBackend.close-139"><span class="linenos">139</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Release runtime resources. Optional override.&quot;&quot;&quot;</span>
</span><span id="BaseClipBackend.close-140"><a href="#BaseClipBackend.close-140"><span class="linenos">140</span></a>        <span class="c1"># Default no-op</span>
</span><span id="BaseClipBackend.close-141"><a href="#BaseClipBackend.close-141"><span class="linenos">141</span></a>        <span class="k">return</span>
</span></pre></div>


            <div class="docstring"><p>Release runtime resources. Optional override.</p>
</div>


                            </div>
                            <div id="BaseClipBackend.is_initialized" class="classattr">
                                        <input id="BaseClipBackend.is_initialized-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">is_initialized</span><span class="annotation">: bool</span>

                <label class="view-source-button" for="BaseClipBackend.is_initialized-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BaseClipBackend.is_initialized"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BaseClipBackend.is_initialized-143"><a href="#BaseClipBackend.is_initialized-143"><span class="linenos">143</span></a>    <span class="nd">@property</span>
</span><span id="BaseClipBackend.is_initialized-144"><a href="#BaseClipBackend.is_initialized-144"><span class="linenos">144</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">is_initialized</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
</span><span id="BaseClipBackend.is_initialized-145"><a href="#BaseClipBackend.is_initialized-145"><span class="linenos">145</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Whether initialize() has successfully completed.&quot;&quot;&quot;</span>
</span><span id="BaseClipBackend.is_initialized-146"><a href="#BaseClipBackend.is_initialized-146"><span class="linenos">146</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span>
</span></pre></div>


            <div class="docstring"><p>Whether initialize() has successfully completed.</p>
</div>


                            </div>
                            <div id="BaseClipBackend.text_to_vector" class="classattr">
                                        <input id="BaseClipBackend.text_to_vector-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-abc.abstractmethod">@abc.abstractmethod</div>

        <span class="def">def</span>
        <span class="name">text_to_vector</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">text</span><span class="p">:</span> <span class="nb">str</span></span><span class="return-annotation">) -> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dtype</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">]]</span>:</span></span>

                <label class="view-source-button" for="BaseClipBackend.text_to_vector-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BaseClipBackend.text_to_vector"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BaseClipBackend.text_to_vector-150"><a href="#BaseClipBackend.text_to_vector-150"><span class="linenos">150</span></a>    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="BaseClipBackend.text_to_vector-151"><a href="#BaseClipBackend.text_to_vector-151"><span class="linenos">151</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">text_to_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="BaseClipBackend.text_to_vector-152"><a href="#BaseClipBackend.text_to_vector-152"><span class="linenos">152</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BaseClipBackend.text_to_vector-153"><a href="#BaseClipBackend.text_to_vector-153"><span class="linenos">153</span></a><span class="sd">        Encode a text string to a unit-normalized embedding vector.</span>
</span><span id="BaseClipBackend.text_to_vector-154"><a href="#BaseClipBackend.text_to_vector-154"><span class="linenos">154</span></a>
</span><span id="BaseClipBackend.text_to_vector-155"><a href="#BaseClipBackend.text_to_vector-155"><span class="linenos">155</span></a><span class="sd">        Returns:</span>
</span><span id="BaseClipBackend.text_to_vector-156"><a href="#BaseClipBackend.text_to_vector-156"><span class="linenos">156</span></a><span class="sd">            np.ndarray with shape (D,) and dtype float32, L2-normalized to 1.0</span>
</span><span id="BaseClipBackend.text_to_vector-157"><a href="#BaseClipBackend.text_to_vector-157"><span class="linenos">157</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaseClipBackend.text_to_vector-158"><a href="#BaseClipBackend.text_to_vector-158"><span class="linenos">158</span></a>        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></pre></div>


            <div class="docstring"><p>Encode a text string to a unit-normalized embedding vector.</p>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>np.ndarray with shape (D,) and dtype float32, L2-normalized to 1.0</p>
</blockquote>
</div>


                            </div>
                            <div id="BaseClipBackend.image_to_vector" class="classattr">
                                        <input id="BaseClipBackend.image_to_vector-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-abc.abstractmethod">@abc.abstractmethod</div>

        <span class="def">def</span>
        <span class="name">image_to_vector</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">image_bytes</span><span class="p">:</span> <span class="nb">bytes</span></span><span class="return-annotation">) -> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dtype</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">]]</span>:</span></span>

                <label class="view-source-button" for="BaseClipBackend.image_to_vector-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BaseClipBackend.image_to_vector"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BaseClipBackend.image_to_vector-160"><a href="#BaseClipBackend.image_to_vector-160"><span class="linenos">160</span></a>    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="BaseClipBackend.image_to_vector-161"><a href="#BaseClipBackend.image_to_vector-161"><span class="linenos">161</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">image_to_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_bytes</span><span class="p">:</span> <span class="nb">bytes</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="BaseClipBackend.image_to_vector-162"><a href="#BaseClipBackend.image_to_vector-162"><span class="linenos">162</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BaseClipBackend.image_to_vector-163"><a href="#BaseClipBackend.image_to_vector-163"><span class="linenos">163</span></a><span class="sd">        Encode image bytes to a unit-normalized embedding vector.</span>
</span><span id="BaseClipBackend.image_to_vector-164"><a href="#BaseClipBackend.image_to_vector-164"><span class="linenos">164</span></a>
</span><span id="BaseClipBackend.image_to_vector-165"><a href="#BaseClipBackend.image_to_vector-165"><span class="linenos">165</span></a><span class="sd">        Returns:</span>
</span><span id="BaseClipBackend.image_to_vector-166"><a href="#BaseClipBackend.image_to_vector-166"><span class="linenos">166</span></a><span class="sd">            np.ndarray with shape (D,) and dtype float32, L2-normalized to 1.0</span>
</span><span id="BaseClipBackend.image_to_vector-167"><a href="#BaseClipBackend.image_to_vector-167"><span class="linenos">167</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaseClipBackend.image_to_vector-168"><a href="#BaseClipBackend.image_to_vector-168"><span class="linenos">168</span></a>        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></pre></div>


            <div class="docstring"><p>Encode image bytes to a unit-normalized embedding vector.</p>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>np.ndarray with shape (D,) and dtype float32, L2-normalized to 1.0</p>
</blockquote>
</div>


                            </div>
                            <div id="BaseClipBackend.image_batch_to_vectors" class="classattr">
                                        <input id="BaseClipBackend.image_batch_to_vectors-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">image_batch_to_vectors</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">images</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">bytes</span><span class="p">]</span></span><span class="return-annotation">) -> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dtype</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">]]</span>:</span></span>

                <label class="view-source-button" for="BaseClipBackend.image_batch_to_vectors-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BaseClipBackend.image_batch_to_vectors"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BaseClipBackend.image_batch_to_vectors-170"><a href="#BaseClipBackend.image_batch_to_vectors-170"><span class="linenos">170</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">image_batch_to_vectors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">bytes</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-171"><a href="#BaseClipBackend.image_batch_to_vectors-171"><span class="linenos">171</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-172"><a href="#BaseClipBackend.image_batch_to_vectors-172"><span class="linenos">172</span></a><span class="sd">        Encode a list of image bytes into a batch of unit-normalized vectors.</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-173"><a href="#BaseClipBackend.image_batch_to_vectors-173"><span class="linenos">173</span></a>
</span><span id="BaseClipBackend.image_batch_to_vectors-174"><a href="#BaseClipBackend.image_batch_to_vectors-174"><span class="linenos">174</span></a><span class="sd">        Defaults to a sequential fallback using image_to_vector(). Backends that</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-175"><a href="#BaseClipBackend.image_batch_to_vectors-175"><span class="linenos">175</span></a><span class="sd">        support true batched execution should override for better throughput.</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-176"><a href="#BaseClipBackend.image_batch_to_vectors-176"><span class="linenos">176</span></a>
</span><span id="BaseClipBackend.image_batch_to_vectors-177"><a href="#BaseClipBackend.image_batch_to_vectors-177"><span class="linenos">177</span></a><span class="sd">        Returns:</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-178"><a href="#BaseClipBackend.image_batch_to_vectors-178"><span class="linenos">178</span></a><span class="sd">            np.ndarray with shape (N, D) and dtype float32, each row L2-normalized.</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-179"><a href="#BaseClipBackend.image_batch_to_vectors-179"><span class="linenos">179</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-180"><a href="#BaseClipBackend.image_batch_to_vectors-180"><span class="linenos">180</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">images</span><span class="p">:</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-181"><a href="#BaseClipBackend.image_batch_to_vectors-181"><span class="linenos">181</span></a>            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-182"><a href="#BaseClipBackend.image_batch_to_vectors-182"><span class="linenos">182</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-183"><a href="#BaseClipBackend.image_batch_to_vectors-183"><span class="linenos">183</span></a>            <span class="n">vecs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-184"><a href="#BaseClipBackend.image_batch_to_vectors-184"><span class="linenos">184</span></a>            <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">images</span><span class="p">:</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-185"><a href="#BaseClipBackend.image_batch_to_vectors-185"><span class="linenos">185</span></a>                <span class="k">try</span><span class="p">:</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-186"><a href="#BaseClipBackend.image_batch_to_vectors-186"><span class="linenos">186</span></a>                    <span class="n">vec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_to_vector</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-187"><a href="#BaseClipBackend.image_batch_to_vectors-187"><span class="linenos">187</span></a>                    <span class="n">vecs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vec</span><span class="p">)</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-188"><a href="#BaseClipBackend.image_batch_to_vectors-188"><span class="linenos">188</span></a>                <span class="k">except</span> <span class="p">(</span><span class="n">BackendError</span><span class="p">,</span> <span class="ne">RuntimeError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-189"><a href="#BaseClipBackend.image_batch_to_vectors-189"><span class="linenos">189</span></a>                    <span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-190"><a href="#BaseClipBackend.image_batch_to_vectors-190"><span class="linenos">190</span></a>
</span><span id="BaseClipBackend.image_batch_to_vectors-191"><a href="#BaseClipBackend.image_batch_to_vectors-191"><span class="linenos">191</span></a>                    <span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-192"><a href="#BaseClipBackend.image_batch_to_vectors-192"><span class="linenos">192</span></a>                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to encode one image in batch: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-193"><a href="#BaseClipBackend.image_batch_to_vectors-193"><span class="linenos">193</span></a>                    <span class="k">continue</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-194"><a href="#BaseClipBackend.image_batch_to_vectors-194"><span class="linenos">194</span></a>
</span><span id="BaseClipBackend.image_batch_to_vectors-195"><a href="#BaseClipBackend.image_batch_to_vectors-195"><span class="linenos">195</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="n">vecs</span><span class="p">:</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-196"><a href="#BaseClipBackend.image_batch_to_vectors-196"><span class="linenos">196</span></a>                <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span><span class="s2">&quot;All images in batch failed to encode&quot;</span><span class="p">)</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-197"><a href="#BaseClipBackend.image_batch_to_vectors-197"><span class="linenos">197</span></a>
</span><span id="BaseClipBackend.image_batch_to_vectors-198"><a href="#BaseClipBackend.image_batch_to_vectors-198"><span class="linenos">198</span></a>            <span class="c1"># Validate consistent dims</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-199"><a href="#BaseClipBackend.image_batch_to_vectors-199"><span class="linenos">199</span></a>            <span class="n">dim</span> <span class="o">=</span> <span class="n">vecs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-200"><a href="#BaseClipBackend.image_batch_to_vectors-200"><span class="linenos">200</span></a>            <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">vecs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-201"><a href="#BaseClipBackend.image_batch_to_vectors-201"><span class="linenos">201</span></a>            <span class="k">if</span> <span class="n">out</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">2</span> <span class="ow">or</span> <span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">dim</span><span class="p">:</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-202"><a href="#BaseClipBackend.image_batch_to_vectors-202"><span class="linenos">202</span></a>                <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-203"><a href="#BaseClipBackend.image_batch_to_vectors-203"><span class="linenos">203</span></a>                    <span class="s2">&quot;image_batch_to_vectors: inconsistent vector dimensions.&quot;</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-204"><a href="#BaseClipBackend.image_batch_to_vectors-204"><span class="linenos">204</span></a>                <span class="p">)</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-205"><a href="#BaseClipBackend.image_batch_to_vectors-205"><span class="linenos">205</span></a>            <span class="k">return</span> <span class="n">out</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-206"><a href="#BaseClipBackend.image_batch_to_vectors-206"><span class="linenos">206</span></a>
</span><span id="BaseClipBackend.image_batch_to_vectors-207"><a href="#BaseClipBackend.image_batch_to_vectors-207"><span class="linenos">207</span></a>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="BaseClipBackend.image_batch_to_vectors-208"><a href="#BaseClipBackend.image_batch_to_vectors-208"><span class="linenos">208</span></a>            <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Batch image encoding failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span></pre></div>


            <div class="docstring"><p>Encode a list of image bytes into a batch of unit-normalized vectors.</p>

<p>Defaults to a sequential fallback using image_to_vector(). Backends that
support true batched execution should override for better throughput.</p>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>np.ndarray with shape (N, D) and dtype float32, each row L2-normalized.</p>
</blockquote>
</div>


                            </div>
                            <div id="BaseClipBackend.text_batch_to_vectors" class="classattr">
                                        <input id="BaseClipBackend.text_batch_to_vectors-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">text_batch_to_vectors</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">texts</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span></span><span class="return-annotation">) -> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dtype</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">]]</span>:</span></span>

                <label class="view-source-button" for="BaseClipBackend.text_batch_to_vectors-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BaseClipBackend.text_batch_to_vectors"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BaseClipBackend.text_batch_to_vectors-210"><a href="#BaseClipBackend.text_batch_to_vectors-210"><span class="linenos">210</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">text_batch_to_vectors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">texts</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-211"><a href="#BaseClipBackend.text_batch_to_vectors-211"><span class="linenos">211</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-212"><a href="#BaseClipBackend.text_batch_to_vectors-212"><span class="linenos">212</span></a><span class="sd">        Encode a list of text strings into a batch of unit-normalized vectors.</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-213"><a href="#BaseClipBackend.text_batch_to_vectors-213"><span class="linenos">213</span></a>
</span><span id="BaseClipBackend.text_batch_to_vectors-214"><a href="#BaseClipBackend.text_batch_to_vectors-214"><span class="linenos">214</span></a><span class="sd">        Defaults to a sequential fallback using text_to_vector(). Backends that</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-215"><a href="#BaseClipBackend.text_batch_to_vectors-215"><span class="linenos">215</span></a><span class="sd">        support true batched execution should override for better throughput.</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-216"><a href="#BaseClipBackend.text_batch_to_vectors-216"><span class="linenos">216</span></a>
</span><span id="BaseClipBackend.text_batch_to_vectors-217"><a href="#BaseClipBackend.text_batch_to_vectors-217"><span class="linenos">217</span></a><span class="sd">        Returns:</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-218"><a href="#BaseClipBackend.text_batch_to_vectors-218"><span class="linenos">218</span></a><span class="sd">            np.ndarray with shape (N, D) and dtype float32, each row L2-normalized.</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-219"><a href="#BaseClipBackend.text_batch_to_vectors-219"><span class="linenos">219</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-220"><a href="#BaseClipBackend.text_batch_to_vectors-220"><span class="linenos">220</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">texts</span><span class="p">:</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-221"><a href="#BaseClipBackend.text_batch_to_vectors-221"><span class="linenos">221</span></a>            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-222"><a href="#BaseClipBackend.text_batch_to_vectors-222"><span class="linenos">222</span></a>
</span><span id="BaseClipBackend.text_batch_to_vectors-223"><a href="#BaseClipBackend.text_batch_to_vectors-223"><span class="linenos">223</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-224"><a href="#BaseClipBackend.text_batch_to_vectors-224"><span class="linenos">224</span></a>            <span class="n">vecs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-225"><a href="#BaseClipBackend.text_batch_to_vectors-225"><span class="linenos">225</span></a>            <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">:</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-226"><a href="#BaseClipBackend.text_batch_to_vectors-226"><span class="linenos">226</span></a>                <span class="k">try</span><span class="p">:</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-227"><a href="#BaseClipBackend.text_batch_to_vectors-227"><span class="linenos">227</span></a>                    <span class="n">vec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_to_vector</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-228"><a href="#BaseClipBackend.text_batch_to_vectors-228"><span class="linenos">228</span></a>                    <span class="n">vecs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vec</span><span class="p">)</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-229"><a href="#BaseClipBackend.text_batch_to_vectors-229"><span class="linenos">229</span></a>                <span class="k">except</span> <span class="p">(</span><span class="n">BackendError</span><span class="p">,</span> <span class="ne">RuntimeError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-230"><a href="#BaseClipBackend.text_batch_to_vectors-230"><span class="linenos">230</span></a>                    <span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-231"><a href="#BaseClipBackend.text_batch_to_vectors-231"><span class="linenos">231</span></a>
</span><span id="BaseClipBackend.text_batch_to_vectors-232"><a href="#BaseClipBackend.text_batch_to_vectors-232"><span class="linenos">232</span></a>                    <span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-233"><a href="#BaseClipBackend.text_batch_to_vectors-233"><span class="linenos">233</span></a>                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to encode one text in batch: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-234"><a href="#BaseClipBackend.text_batch_to_vectors-234"><span class="linenos">234</span></a>                    <span class="k">continue</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-235"><a href="#BaseClipBackend.text_batch_to_vectors-235"><span class="linenos">235</span></a>
</span><span id="BaseClipBackend.text_batch_to_vectors-236"><a href="#BaseClipBackend.text_batch_to_vectors-236"><span class="linenos">236</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="n">vecs</span><span class="p">:</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-237"><a href="#BaseClipBackend.text_batch_to_vectors-237"><span class="linenos">237</span></a>                <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span><span class="s2">&quot;All texts in batch failed to encode&quot;</span><span class="p">)</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-238"><a href="#BaseClipBackend.text_batch_to_vectors-238"><span class="linenos">238</span></a>
</span><span id="BaseClipBackend.text_batch_to_vectors-239"><a href="#BaseClipBackend.text_batch_to_vectors-239"><span class="linenos">239</span></a>            <span class="c1"># Validate consistent dims</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-240"><a href="#BaseClipBackend.text_batch_to_vectors-240"><span class="linenos">240</span></a>            <span class="n">dim</span> <span class="o">=</span> <span class="n">vecs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-241"><a href="#BaseClipBackend.text_batch_to_vectors-241"><span class="linenos">241</span></a>            <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">vecs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-242"><a href="#BaseClipBackend.text_batch_to_vectors-242"><span class="linenos">242</span></a>            <span class="k">if</span> <span class="n">out</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">2</span> <span class="ow">or</span> <span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">dim</span><span class="p">:</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-243"><a href="#BaseClipBackend.text_batch_to_vectors-243"><span class="linenos">243</span></a>                <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-244"><a href="#BaseClipBackend.text_batch_to_vectors-244"><span class="linenos">244</span></a>                    <span class="s2">&quot;text_batch_to_vectors: inconsistent vector dimensions.&quot;</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-245"><a href="#BaseClipBackend.text_batch_to_vectors-245"><span class="linenos">245</span></a>                <span class="p">)</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-246"><a href="#BaseClipBackend.text_batch_to_vectors-246"><span class="linenos">246</span></a>            <span class="k">return</span> <span class="n">out</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-247"><a href="#BaseClipBackend.text_batch_to_vectors-247"><span class="linenos">247</span></a>
</span><span id="BaseClipBackend.text_batch_to_vectors-248"><a href="#BaseClipBackend.text_batch_to_vectors-248"><span class="linenos">248</span></a>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="BaseClipBackend.text_batch_to_vectors-249"><a href="#BaseClipBackend.text_batch_to_vectors-249"><span class="linenos">249</span></a>            <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Batch text encoding failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span></pre></div>


            <div class="docstring"><p>Encode a list of text strings into a batch of unit-normalized vectors.</p>

<p>Defaults to a sequential fallback using text_to_vector(). Backends that
support true batched execution should override for better throughput.</p>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>np.ndarray with shape (N, D) and dtype float32, each row L2-normalized.</p>
</blockquote>
</div>


                            </div>
                            <div id="BaseClipBackend.get_info" class="classattr">
                                        <input id="BaseClipBackend.get_info-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-abc.abstractmethod">@abc.abstractmethod</div>

        <span class="def">def</span>
        <span class="name">get_info</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">) -> <span class="n"><a href="#BackendInfo">BackendInfo</a></span>:</span></span>

                <label class="view-source-button" for="BaseClipBackend.get_info-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BaseClipBackend.get_info"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BaseClipBackend.get_info-253"><a href="#BaseClipBackend.get_info-253"><span class="linenos">253</span></a>    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="BaseClipBackend.get_info-254"><a href="#BaseClipBackend.get_info-254"><span class="linenos">254</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_info</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BackendInfo</span><span class="p">:</span>
</span><span id="BaseClipBackend.get_info-255"><a href="#BaseClipBackend.get_info-255"><span class="linenos">255</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BaseClipBackend.get_info-256"><a href="#BaseClipBackend.get_info-256"><span class="linenos">256</span></a><span class="sd">        Return a BackendInfo describing runtime, device, model identifiers,</span>
</span><span id="BaseClipBackend.get_info-257"><a href="#BaseClipBackend.get_info-257"><span class="linenos">257</span></a><span class="sd">        embedding dimensions, precision supports, batchability, etc.</span>
</span><span id="BaseClipBackend.get_info-258"><a href="#BaseClipBackend.get_info-258"><span class="linenos">258</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaseClipBackend.get_info-259"><a href="#BaseClipBackend.get_info-259"><span class="linenos">259</span></a>        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></pre></div>


            <div class="docstring"><p>Return a BackendInfo describing runtime, device, model identifiers,
embedding dimensions, precision supports, batchability, etc.</p>
</div>


                            </div>
                            <div id="BaseClipBackend.unit_normalize" class="classattr">
                                        <input id="BaseClipBackend.unit_normalize-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-staticmethod">@staticmethod</div>

        <span class="def">def</span>
        <span class="name">unit_normalize</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">vec</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dtype</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">]]</span>,</span><span class="param">	<span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>,</span><span class="param">	<span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-08</span></span><span class="return-annotation">) -> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dtype</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">]]</span>:</span></span>

                <label class="view-source-button" for="BaseClipBackend.unit_normalize-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BaseClipBackend.unit_normalize"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BaseClipBackend.unit_normalize-263"><a href="#BaseClipBackend.unit_normalize-263"><span class="linenos">263</span></a>    <span class="nd">@staticmethod</span>
</span><span id="BaseClipBackend.unit_normalize-264"><a href="#BaseClipBackend.unit_normalize-264"><span class="linenos">264</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">unit_normalize</span><span class="p">(</span>
</span><span id="BaseClipBackend.unit_normalize-265"><a href="#BaseClipBackend.unit_normalize-265"><span class="linenos">265</span></a>        <span class="n">vec</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">],</span> <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span>
</span><span id="BaseClipBackend.unit_normalize-266"><a href="#BaseClipBackend.unit_normalize-266"><span class="linenos">266</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="BaseClipBackend.unit_normalize-267"><a href="#BaseClipBackend.unit_normalize-267"><span class="linenos">267</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BaseClipBackend.unit_normalize-268"><a href="#BaseClipBackend.unit_normalize-268"><span class="linenos">268</span></a><span class="sd">        L2-normalize vectors along the given axis.</span>
</span><span id="BaseClipBackend.unit_normalize-269"><a href="#BaseClipBackend.unit_normalize-269"><span class="linenos">269</span></a>
</span><span id="BaseClipBackend.unit_normalize-270"><a href="#BaseClipBackend.unit_normalize-270"><span class="linenos">270</span></a><span class="sd">        Args:</span>
</span><span id="BaseClipBackend.unit_normalize-271"><a href="#BaseClipBackend.unit_normalize-271"><span class="linenos">271</span></a><span class="sd">            vec: Input array</span>
</span><span id="BaseClipBackend.unit_normalize-272"><a href="#BaseClipBackend.unit_normalize-272"><span class="linenos">272</span></a><span class="sd">            axis: Axis to normalize over</span>
</span><span id="BaseClipBackend.unit_normalize-273"><a href="#BaseClipBackend.unit_normalize-273"><span class="linenos">273</span></a><span class="sd">            eps: Numerical stability epsilon</span>
</span><span id="BaseClipBackend.unit_normalize-274"><a href="#BaseClipBackend.unit_normalize-274"><span class="linenos">274</span></a>
</span><span id="BaseClipBackend.unit_normalize-275"><a href="#BaseClipBackend.unit_normalize-275"><span class="linenos">275</span></a><span class="sd">        Returns:</span>
</span><span id="BaseClipBackend.unit_normalize-276"><a href="#BaseClipBackend.unit_normalize-276"><span class="linenos">276</span></a><span class="sd">            Unit-normalized array (float32)</span>
</span><span id="BaseClipBackend.unit_normalize-277"><a href="#BaseClipBackend.unit_normalize-277"><span class="linenos">277</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaseClipBackend.unit_normalize-278"><a href="#BaseClipBackend.unit_normalize-278"><span class="linenos">278</span></a>        <span class="n">v</span> <span class="o">=</span> <span class="n">vec</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="BaseClipBackend.unit_normalize-279"><a href="#BaseClipBackend.unit_normalize-279"><span class="linenos">279</span></a>        <span class="n">norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="BaseClipBackend.unit_normalize-280"><a href="#BaseClipBackend.unit_normalize-280"><span class="linenos">280</span></a>        <span class="n">norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">norm</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span>
</span><span id="BaseClipBackend.unit_normalize-281"><a href="#BaseClipBackend.unit_normalize-281"><span class="linenos">281</span></a>        <span class="k">return</span> <span class="n">v</span> <span class="o">/</span> <span class="n">norm</span>
</span></pre></div>


            <div class="docstring"><p>L2-normalize vectors along the given axis.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>vec:</strong>  Input array</li>
<li><strong>axis:</strong>  Axis to normalize over</li>
<li><strong>eps:</strong>  Numerical stability epsilon</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>Unit-normalized array (float32)</p>
</blockquote>
</div>


                            </div>
                </section>
                <section id="BackendInfo">
                            <input id="BackendInfo-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
                    <div class="decorator decorator-dataclass">@dataclass</div>

    <span class="def">class</span>
    <span class="name">BackendInfo</span>:

                <label class="view-source-button" for="BackendInfo-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BackendInfo"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BackendInfo-54"><a href="#BackendInfo-54"><span class="linenos">54</span></a><span class="nd">@dataclass</span>
</span><span id="BackendInfo-55"><a href="#BackendInfo-55"><span class="linenos">55</span></a><span class="k">class</span><span class="w"> </span><span class="nc">BackendInfo</span><span class="p">:</span>
</span><span id="BackendInfo-56"><a href="#BackendInfo-56"><span class="linenos">56</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="BackendInfo-57"><a href="#BackendInfo-57"><span class="linenos">57</span></a><span class="sd">    Describes the active backend configuration and model metadata.</span>
</span><span id="BackendInfo-58"><a href="#BackendInfo-58"><span class="linenos">58</span></a>
</span><span id="BackendInfo-59"><a href="#BackendInfo-59"><span class="linenos">59</span></a><span class="sd">    All fields are optional except `runtime`. Populate as much as possible so the</span>
</span><span id="BackendInfo-60"><a href="#BackendInfo-60"><span class="linenos">60</span></a><span class="sd">    gRPC capability message can surface accurate details.</span>
</span><span id="BackendInfo-61"><a href="#BackendInfo-61"><span class="linenos">61</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="BackendInfo-62"><a href="#BackendInfo-62"><span class="linenos">62</span></a>
</span><span id="BackendInfo-63"><a href="#BackendInfo-63"><span class="linenos">63</span></a>    <span class="n">runtime</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="BackendInfo-64"><a href="#BackendInfo-64"><span class="linenos">64</span></a>    <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># e.g., &quot;cuda:0&quot;, &quot;mps&quot;, &quot;cpu&quot;, &quot;rk3588-npu&quot;</span>
</span><span id="BackendInfo-65"><a href="#BackendInfo-65"><span class="linenos">65</span></a>    <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="BackendInfo-66"><a href="#BackendInfo-66"><span class="linenos">66</span></a>        <span class="kc">None</span>  <span class="c1"># a stable identifier (e.g., &quot;ViT-B-32_laion2b_s34b_b79k&quot;)</span>
</span><span id="BackendInfo-67"><a href="#BackendInfo-67"><span class="linenos">67</span></a>    <span class="p">)</span>
</span><span id="BackendInfo-68"><a href="#BackendInfo-68"><span class="linenos">68</span></a>    <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># human-friendly name (&quot;ViT-B-32&quot;)</span>
</span><span id="BackendInfo-69"><a href="#BackendInfo-69"><span class="linenos">69</span></a>    <span class="n">pretrained</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># e.g., &quot;laion2b_s34b_b79k&quot;</span>
</span><span id="BackendInfo-70"><a href="#BackendInfo-70"><span class="linenos">70</span></a>    <span class="n">version</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># backend or model version string</span>
</span><span id="BackendInfo-71"><a href="#BackendInfo-71"><span class="linenos">71</span></a>    <span class="n">image_embedding_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="BackendInfo-72"><a href="#BackendInfo-72"><span class="linenos">72</span></a>    <span class="n">text_embedding_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="BackendInfo-73"><a href="#BackendInfo-73"><span class="linenos">73</span></a>    <span class="n">precisions</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="nb">list</span><span class="p">)</span>  <span class="c1"># e.g., [&quot;fp32&quot;,&quot;fp16&quot;,&quot;int8&quot;]</span>
</span><span id="BackendInfo-74"><a href="#BackendInfo-74"><span class="linenos">74</span></a>    <span class="n">max_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># backend hint (if any)</span>
</span><span id="BackendInfo-75"><a href="#BackendInfo-75"><span class="linenos">75</span></a>    <span class="n">supports_image_batch</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="BackendInfo-76"><a href="#BackendInfo-76"><span class="linenos">76</span></a>    <span class="n">extra</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
</span><span id="BackendInfo-77"><a href="#BackendInfo-77"><span class="linenos">77</span></a>        <span class="n">default_factory</span><span class="o">=</span><span class="nb">dict</span>
</span><span id="BackendInfo-78"><a href="#BackendInfo-78"><span class="linenos">78</span></a>    <span class="p">)</span>  <span class="c1"># arbitrary key/value pairs</span>
</span><span id="BackendInfo-79"><a href="#BackendInfo-79"><span class="linenos">79</span></a>
</span><span id="BackendInfo-80"><a href="#BackendInfo-80"><span class="linenos">80</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">as_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">object</span><span class="p">]:</span>
</span><span id="BackendInfo-81"><a href="#BackendInfo-81"><span class="linenos">81</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert to a plain dict (safe for JSON serialization).&quot;&quot;&quot;</span>
</span><span id="BackendInfo-82"><a href="#BackendInfo-82"><span class="linenos">82</span></a>        <span class="k">return</span> <span class="p">{</span>
</span><span id="BackendInfo-83"><a href="#BackendInfo-83"><span class="linenos">83</span></a>            <span class="s2">&quot;runtime&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">runtime</span><span class="p">,</span>
</span><span id="BackendInfo-84"><a href="#BackendInfo-84"><span class="linenos">84</span></a>            <span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
</span><span id="BackendInfo-85"><a href="#BackendInfo-85"><span class="linenos">85</span></a>            <span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_id</span><span class="p">,</span>
</span><span id="BackendInfo-86"><a href="#BackendInfo-86"><span class="linenos">86</span></a>            <span class="s2">&quot;model_name&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span>
</span><span id="BackendInfo-87"><a href="#BackendInfo-87"><span class="linenos">87</span></a>            <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pretrained</span><span class="p">,</span>
</span><span id="BackendInfo-88"><a href="#BackendInfo-88"><span class="linenos">88</span></a>            <span class="s2">&quot;version&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">version</span><span class="p">,</span>
</span><span id="BackendInfo-89"><a href="#BackendInfo-89"><span class="linenos">89</span></a>            <span class="s2">&quot;image_embedding_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_embedding_dim</span><span class="p">,</span>
</span><span id="BackendInfo-90"><a href="#BackendInfo-90"><span class="linenos">90</span></a>            <span class="s2">&quot;text_embedding_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_embedding_dim</span><span class="p">,</span>
</span><span id="BackendInfo-91"><a href="#BackendInfo-91"><span class="linenos">91</span></a>            <span class="s2">&quot;precisions&quot;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">precisions</span><span class="p">),</span>
</span><span id="BackendInfo-92"><a href="#BackendInfo-92"><span class="linenos">92</span></a>            <span class="s2">&quot;max_batch_size&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_batch_size</span><span class="p">,</span>
</span><span id="BackendInfo-93"><a href="#BackendInfo-93"><span class="linenos">93</span></a>            <span class="s2">&quot;supports_image_batch&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">supports_image_batch</span><span class="p">,</span>
</span><span id="BackendInfo-94"><a href="#BackendInfo-94"><span class="linenos">94</span></a>            <span class="s2">&quot;extra&quot;</span><span class="p">:</span> <span class="nb">dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">extra</span><span class="p">),</span>
</span><span id="BackendInfo-95"><a href="#BackendInfo-95"><span class="linenos">95</span></a>        <span class="p">}</span>
</span></pre></div>


            <div class="docstring"><p>Describes the active backend configuration and model metadata.</p>

<p>All fields are optional except <code><a href="#BackendInfo.runtime">runtime</a></code>. Populate as much as possible so the
gRPC capability message can surface accurate details.</p>
</div>


                            <div id="BackendInfo.__init__" class="classattr">
                                <div class="attr function">
            
        <span class="name">BackendInfo</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">runtime</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">pretrained</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">version</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">image_embedding_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">text_embedding_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">precisions</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">factory</span><span class="o">&gt;</span>,</span><span class="param">	<span class="n">max_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">supports_image_batch</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="n">extra</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">factory</span><span class="o">&gt;</span></span>)</span>

        
    </div>
    <a class="headerlink" href="#BackendInfo.__init__"></a>
    
    

                            </div>
                            <div id="BackendInfo.runtime" class="classattr">
                                <div class="attr variable">
            <span class="name">runtime</span><span class="annotation">: str</span>

        
    </div>
    <a class="headerlink" href="#BackendInfo.runtime"></a>
    
    

                            </div>
                            <div id="BackendInfo.device" class="classattr">
                                <div class="attr variable">
            <span class="name">device</span><span class="annotation">: str | None</span>        =
<span class="default_value">None</span>

        
    </div>
    <a class="headerlink" href="#BackendInfo.device"></a>
    
    

                            </div>
                            <div id="BackendInfo.model_id" class="classattr">
                                <div class="attr variable">
            <span class="name">model_id</span><span class="annotation">: str | None</span>        =
<span class="default_value">None</span>

        
    </div>
    <a class="headerlink" href="#BackendInfo.model_id"></a>
    
    

                            </div>
                            <div id="BackendInfo.model_name" class="classattr">
                                <div class="attr variable">
            <span class="name">model_name</span><span class="annotation">: str | None</span>        =
<span class="default_value">None</span>

        
    </div>
    <a class="headerlink" href="#BackendInfo.model_name"></a>
    
    

                            </div>
                            <div id="BackendInfo.pretrained" class="classattr">
                                <div class="attr variable">
            <span class="name">pretrained</span><span class="annotation">: str | None</span>        =
<span class="default_value">None</span>

        
    </div>
    <a class="headerlink" href="#BackendInfo.pretrained"></a>
    
    

                            </div>
                            <div id="BackendInfo.version" class="classattr">
                                <div class="attr variable">
            <span class="name">version</span><span class="annotation">: str | None</span>        =
<span class="default_value">None</span>

        
    </div>
    <a class="headerlink" href="#BackendInfo.version"></a>
    
    

                            </div>
                            <div id="BackendInfo.image_embedding_dim" class="classattr">
                                <div class="attr variable">
            <span class="name">image_embedding_dim</span><span class="annotation">: int | None</span>        =
<span class="default_value">None</span>

        
    </div>
    <a class="headerlink" href="#BackendInfo.image_embedding_dim"></a>
    
    

                            </div>
                            <div id="BackendInfo.text_embedding_dim" class="classattr">
                                <div class="attr variable">
            <span class="name">text_embedding_dim</span><span class="annotation">: int | None</span>        =
<span class="default_value">None</span>

        
    </div>
    <a class="headerlink" href="#BackendInfo.text_embedding_dim"></a>
    
    

                            </div>
                            <div id="BackendInfo.precisions" class="classattr">
                                <div class="attr variable">
            <span class="name">precisions</span><span class="annotation">: list[str]</span>

        
    </div>
    <a class="headerlink" href="#BackendInfo.precisions"></a>
    
    

                            </div>
                            <div id="BackendInfo.max_batch_size" class="classattr">
                                <div class="attr variable">
            <span class="name">max_batch_size</span><span class="annotation">: int | None</span>        =
<span class="default_value">None</span>

        
    </div>
    <a class="headerlink" href="#BackendInfo.max_batch_size"></a>
    
    

                            </div>
                            <div id="BackendInfo.supports_image_batch" class="classattr">
                                <div class="attr variable">
            <span class="name">supports_image_batch</span><span class="annotation">: bool</span>        =
<span class="default_value">False</span>

        
    </div>
    <a class="headerlink" href="#BackendInfo.supports_image_batch"></a>
    
    

                            </div>
                            <div id="BackendInfo.extra" class="classattr">
                                <div class="attr variable">
            <span class="name">extra</span><span class="annotation">: dict[str, str | None]</span>

        
    </div>
    <a class="headerlink" href="#BackendInfo.extra"></a>
    
    

                            </div>
                            <div id="BackendInfo.as_dict" class="classattr">
                                        <input id="BackendInfo.as_dict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">as_dict</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">) -> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">object</span><span class="p">]</span>:</span></span>

                <label class="view-source-button" for="BackendInfo.as_dict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BackendInfo.as_dict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BackendInfo.as_dict-80"><a href="#BackendInfo.as_dict-80"><span class="linenos">80</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">as_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">object</span><span class="p">]:</span>
</span><span id="BackendInfo.as_dict-81"><a href="#BackendInfo.as_dict-81"><span class="linenos">81</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert to a plain dict (safe for JSON serialization).&quot;&quot;&quot;</span>
</span><span id="BackendInfo.as_dict-82"><a href="#BackendInfo.as_dict-82"><span class="linenos">82</span></a>        <span class="k">return</span> <span class="p">{</span>
</span><span id="BackendInfo.as_dict-83"><a href="#BackendInfo.as_dict-83"><span class="linenos">83</span></a>            <span class="s2">&quot;runtime&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">runtime</span><span class="p">,</span>
</span><span id="BackendInfo.as_dict-84"><a href="#BackendInfo.as_dict-84"><span class="linenos">84</span></a>            <span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
</span><span id="BackendInfo.as_dict-85"><a href="#BackendInfo.as_dict-85"><span class="linenos">85</span></a>            <span class="s2">&quot;model_id&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_id</span><span class="p">,</span>
</span><span id="BackendInfo.as_dict-86"><a href="#BackendInfo.as_dict-86"><span class="linenos">86</span></a>            <span class="s2">&quot;model_name&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span>
</span><span id="BackendInfo.as_dict-87"><a href="#BackendInfo.as_dict-87"><span class="linenos">87</span></a>            <span class="s2">&quot;pretrained&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">pretrained</span><span class="p">,</span>
</span><span id="BackendInfo.as_dict-88"><a href="#BackendInfo.as_dict-88"><span class="linenos">88</span></a>            <span class="s2">&quot;version&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">version</span><span class="p">,</span>
</span><span id="BackendInfo.as_dict-89"><a href="#BackendInfo.as_dict-89"><span class="linenos">89</span></a>            <span class="s2">&quot;image_embedding_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_embedding_dim</span><span class="p">,</span>
</span><span id="BackendInfo.as_dict-90"><a href="#BackendInfo.as_dict-90"><span class="linenos">90</span></a>            <span class="s2">&quot;text_embedding_dim&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_embedding_dim</span><span class="p">,</span>
</span><span id="BackendInfo.as_dict-91"><a href="#BackendInfo.as_dict-91"><span class="linenos">91</span></a>            <span class="s2">&quot;precisions&quot;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">precisions</span><span class="p">),</span>
</span><span id="BackendInfo.as_dict-92"><a href="#BackendInfo.as_dict-92"><span class="linenos">92</span></a>            <span class="s2">&quot;max_batch_size&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_batch_size</span><span class="p">,</span>
</span><span id="BackendInfo.as_dict-93"><a href="#BackendInfo.as_dict-93"><span class="linenos">93</span></a>            <span class="s2">&quot;supports_image_batch&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">supports_image_batch</span><span class="p">,</span>
</span><span id="BackendInfo.as_dict-94"><a href="#BackendInfo.as_dict-94"><span class="linenos">94</span></a>            <span class="s2">&quot;extra&quot;</span><span class="p">:</span> <span class="nb">dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">extra</span><span class="p">),</span>
</span><span id="BackendInfo.as_dict-95"><a href="#BackendInfo.as_dict-95"><span class="linenos">95</span></a>        <span class="p">}</span>
</span></pre></div>


            <div class="docstring"><p>Convert to a plain dict (safe for JSON serialization).</p>
</div>


                            </div>
                </section>
                <section id="RuntimeKind">
                            <input id="RuntimeKind-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">RuntimeKind</span><wbr>(<span class="base">builtins.str</span>, <span class="base">enum.Enum</span>):

                <label class="view-source-button" for="RuntimeKind-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#RuntimeKind"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="RuntimeKind-46"><a href="#RuntimeKind-46"><span class="linenos">46</span></a><span class="k">class</span><span class="w"> </span><span class="nc">RuntimeKind</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">enum</span><span class="o">.</span><span class="n">Enum</span><span class="p">):</span>
</span><span id="RuntimeKind-47"><a href="#RuntimeKind-47"><span class="linenos">47</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Enumerates the primary runtime families for backends.&quot;&quot;&quot;</span>
</span><span id="RuntimeKind-48"><a href="#RuntimeKind-48"><span class="linenos">48</span></a>
</span><span id="RuntimeKind-49"><a href="#RuntimeKind-49"><span class="linenos">49</span></a>    <span class="n">TORCH</span> <span class="o">=</span> <span class="s2">&quot;torch&quot;</span>
</span><span id="RuntimeKind-50"><a href="#RuntimeKind-50"><span class="linenos">50</span></a>    <span class="n">ONNXRT</span> <span class="o">=</span> <span class="s2">&quot;onnxrt&quot;</span>
</span><span id="RuntimeKind-51"><a href="#RuntimeKind-51"><span class="linenos">51</span></a>    <span class="n">RKNN</span> <span class="o">=</span> <span class="s2">&quot;rknn&quot;</span>
</span></pre></div>


            <div class="docstring"><p>Enumerates the primary runtime families for backends.</p>
</div>


                            <div id="RuntimeKind.TORCH" class="classattr">
                                <div class="attr variable">
            <span class="name">TORCH</span>        =
<span class="default_value">&lt;<a href="#RuntimeKind.TORCH">RuntimeKind.TORCH</a>: &#39;torch&#39;&gt;</span>

        
    </div>
    <a class="headerlink" href="#RuntimeKind.TORCH"></a>
    
    

                            </div>
                            <div id="RuntimeKind.ONNXRT" class="classattr">
                                <div class="attr variable">
            <span class="name">ONNXRT</span>        =
<span class="default_value">&lt;<a href="#RuntimeKind.ONNXRT">RuntimeKind.ONNXRT</a>: &#39;onnxrt&#39;&gt;</span>

        
    </div>
    <a class="headerlink" href="#RuntimeKind.ONNXRT"></a>
    
    

                            </div>
                            <div id="RuntimeKind.RKNN" class="classattr">
                                <div class="attr variable">
            <span class="name">RKNN</span>        =
<span class="default_value">&lt;<a href="#RuntimeKind.RKNN">RuntimeKind.RKNN</a>: &#39;rknn&#39;&gt;</span>

        
    </div>
    <a class="headerlink" href="#RuntimeKind.RKNN"></a>
    
    

                            </div>
                </section>
                <section id="TorchBackend">
                            <input id="TorchBackend-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">TorchBackend</span><wbr>(<span class="base"><a href="#BaseClipBackend">lumen_clip.backends.BaseClipBackend</a></span>):

                <label class="view-source-button" for="TorchBackend-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TorchBackend"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TorchBackend-64"><a href="#TorchBackend-64"><span class="linenos"> 64</span></a><span class="k">class</span><span class="w"> </span><span class="nc">TorchBackend</span><span class="p">(</span><span class="n">BaseClipBackend</span><span class="p">):</span>
</span><span id="TorchBackend-65"><a href="#TorchBackend-65"><span class="linenos"> 65</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="TorchBackend-66"><a href="#TorchBackend-66"><span class="linenos"> 66</span></a><span class="sd">    A PyTorch/OpenCLIP backend implementing BaseClipBackend.</span>
</span><span id="TorchBackend-67"><a href="#TorchBackend-67"><span class="linenos"> 67</span></a>
</span><span id="TorchBackend-68"><a href="#TorchBackend-68"><span class="linenos"> 68</span></a><span class="sd">    Args:</span>
</span><span id="TorchBackend-69"><a href="#TorchBackend-69"><span class="linenos"> 69</span></a><span class="sd">        resources: ModelResources object containing model files and configs</span>
</span><span id="TorchBackend-70"><a href="#TorchBackend-70"><span class="linenos"> 70</span></a><span class="sd">        device_preference: Optional hint for device selection (&quot;cuda&quot;, &quot;mps&quot;, &quot;cpu&quot;).</span>
</span><span id="TorchBackend-71"><a href="#TorchBackend-71"><span class="linenos"> 71</span></a><span class="sd">        max_batch_size: Optional hint for batch size; not enforced by backend.</span>
</span><span id="TorchBackend-72"><a href="#TorchBackend-72"><span class="linenos"> 72</span></a>
</span><span id="TorchBackend-73"><a href="#TorchBackend-73"><span class="linenos"> 73</span></a><span class="sd">    Behavior:</span>
</span><span id="TorchBackend-74"><a href="#TorchBackend-74"><span class="linenos"> 74</span></a><span class="sd">        - initialize() loads the model from local files, tokenizer, and preprocess pipeline</span>
</span><span id="TorchBackend-75"><a href="#TorchBackend-75"><span class="linenos"> 75</span></a><span class="sd">        - Always loads FP32 weights (model.pt)</span>
</span><span id="TorchBackend-76"><a href="#TorchBackend-76"><span class="linenos"> 76</span></a><span class="sd">        - Uses mixed precision (AMP) on GPU (CUDA/MPS) for inference</span>
</span><span id="TorchBackend-77"><a href="#TorchBackend-77"><span class="linenos"> 77</span></a><span class="sd">        - text_to_vector() encodes a text prompt via the model&#39;s text encoder</span>
</span><span id="TorchBackend-78"><a href="#TorchBackend-78"><span class="linenos"> 78</span></a><span class="sd">        - image_to_vector() decodes and preprocesses image bytes, then encodes via the image encoder</span>
</span><span id="TorchBackend-79"><a href="#TorchBackend-79"><span class="linenos"> 79</span></a><span class="sd">        - image_batch_to_vectors() performs a single batched forward pass for multiple images</span>
</span><span id="TorchBackend-80"><a href="#TorchBackend-80"><span class="linenos"> 80</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="TorchBackend-81"><a href="#TorchBackend-81"><span class="linenos"> 81</span></a>
</span><span id="TorchBackend-82"><a href="#TorchBackend-82"><span class="linenos"> 82</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="TorchBackend-83"><a href="#TorchBackend-83"><span class="linenos"> 83</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="TorchBackend-84"><a href="#TorchBackend-84"><span class="linenos"> 84</span></a>        <span class="n">resources</span><span class="p">:</span> <span class="s2">&quot;ModelResources&quot;</span><span class="p">,</span>
</span><span id="TorchBackend-85"><a href="#TorchBackend-85"><span class="linenos"> 85</span></a>        <span class="n">device_preference</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="TorchBackend-86"><a href="#TorchBackend-86"><span class="linenos"> 86</span></a>        <span class="n">max_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="TorchBackend-87"><a href="#TorchBackend-87"><span class="linenos"> 87</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="TorchBackend-88"><a href="#TorchBackend-88"><span class="linenos"> 88</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="TorchBackend-89"><a href="#TorchBackend-89"><span class="linenos"> 89</span></a>            <span class="n">resources</span><span class="o">=</span><span class="n">resources</span><span class="p">,</span>
</span><span id="TorchBackend-90"><a href="#TorchBackend-90"><span class="linenos"> 90</span></a>            <span class="n">device_preference</span><span class="o">=</span><span class="n">device_preference</span><span class="p">,</span>
</span><span id="TorchBackend-91"><a href="#TorchBackend-91"><span class="linenos"> 91</span></a>            <span class="n">max_batch_size</span><span class="o">=</span><span class="n">max_batch_size</span><span class="p">,</span>
</span><span id="TorchBackend-92"><a href="#TorchBackend-92"><span class="linenos"> 92</span></a>        <span class="p">)</span>
</span><span id="TorchBackend-93"><a href="#TorchBackend-93"><span class="linenos"> 93</span></a>
</span><span id="TorchBackend-94"><a href="#TorchBackend-94"><span class="linenos"> 94</span></a>        <span class="c1"># Runtime objects</span>
</span><span id="TorchBackend-95"><a href="#TorchBackend-95"><span class="linenos"> 95</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_device</span><span class="p">(</span><span class="n">device_preference</span><span class="p">)</span>
</span><span id="TorchBackend-96"><a href="#TorchBackend-96"><span class="linenos"> 96</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="TorchBackend-97"><a href="#TorchBackend-97"><span class="linenos"> 97</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="TorchBackend-98"><a href="#TorchBackend-98"><span class="linenos"> 98</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="TorchBackend-99"><a href="#TorchBackend-99"><span class="linenos"> 99</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_load_time_seconds</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="TorchBackend-100"><a href="#TorchBackend-100"><span class="linenos">100</span></a>
</span><span id="TorchBackend-101"><a href="#TorchBackend-101"><span class="linenos">101</span></a>        <span class="c1"># Mixed precision settings</span>
</span><span id="TorchBackend-102"><a href="#TorchBackend-102"><span class="linenos">102</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_use_amp</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</span><span id="TorchBackend-103"><a href="#TorchBackend-103"><span class="linenos">103</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_amp_dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
</span><span id="TorchBackend-104"><a href="#TorchBackend-104"><span class="linenos">104</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_current_precision</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;fp32&quot;</span>  <span class="c1"># Will be updated after init</span>
</span><span id="TorchBackend-105"><a href="#TorchBackend-105"><span class="linenos">105</span></a>
</span><span id="TorchBackend-106"><a href="#TorchBackend-106"><span class="linenos">106</span></a>    <span class="c1"># ---------- Lifecycle ----------</span>
</span><span id="TorchBackend-107"><a href="#TorchBackend-107"><span class="linenos">107</span></a>
</span><span id="TorchBackend-108"><a href="#TorchBackend-108"><span class="linenos">108</span></a>    <span class="nd">@override</span>
</span><span id="TorchBackend-109"><a href="#TorchBackend-109"><span class="linenos">109</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="TorchBackend-110"><a href="#TorchBackend-110"><span class="linenos">110</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span><span class="p">:</span>
</span><span id="TorchBackend-111"><a href="#TorchBackend-111"><span class="linenos">111</span></a>            <span class="k">return</span>
</span><span id="TorchBackend-112"><a href="#TorchBackend-112"><span class="linenos">112</span></a>
</span><span id="TorchBackend-113"><a href="#TorchBackend-113"><span class="linenos">113</span></a>        <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</span><span id="TorchBackend-114"><a href="#TorchBackend-114"><span class="linenos">114</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="TorchBackend-115"><a href="#TorchBackend-115"><span class="linenos">115</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Initializing TorchBackend for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="TorchBackend-116"><a href="#TorchBackend-116"><span class="linenos">116</span></a>
</span><span id="TorchBackend-117"><a href="#TorchBackend-117"><span class="linenos">117</span></a>            <span class="c1"># 1. Get model architecture name from config</span>
</span><span id="TorchBackend-118"><a href="#TorchBackend-118"><span class="linenos">118</span></a>            <span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">config</span>
</span><span id="TorchBackend-119"><a href="#TorchBackend-119"><span class="linenos">119</span></a>            <span class="n">model_name</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;model_name&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">model_name</span><span class="p">)</span>
</span><span id="TorchBackend-120"><a href="#TorchBackend-120"><span class="linenos">120</span></a>
</span><span id="TorchBackend-121"><a href="#TorchBackend-121"><span class="linenos">121</span></a>            <span class="c1"># 2. Create model architecture without pretrained weights</span>
</span><span id="TorchBackend-122"><a href="#TorchBackend-122"><span class="linenos">122</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Creating model architecture: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="TorchBackend-123"><a href="#TorchBackend-123"><span class="linenos">123</span></a>            <span class="n">model_obj</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">preprocess</span> <span class="o">=</span> <span class="n">open_clip</span><span class="o">.</span><span class="n">create_model_and_transforms</span><span class="p">(</span>
</span><span id="TorchBackend-124"><a href="#TorchBackend-124"><span class="linenos">124</span></a>                <span class="n">model_name</span><span class="p">,</span>
</span><span id="TorchBackend-125"><a href="#TorchBackend-125"><span class="linenos">125</span></a>                <span class="n">pretrained</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># No automatic download</span>
</span><span id="TorchBackend-126"><a href="#TorchBackend-126"><span class="linenos">126</span></a>            <span class="p">)</span>
</span><span id="TorchBackend-127"><a href="#TorchBackend-127"><span class="linenos">127</span></a>
</span><span id="TorchBackend-128"><a href="#TorchBackend-128"><span class="linenos">128</span></a>            <span class="c1"># 3. Load local weights</span>
</span><span id="TorchBackend-129"><a href="#TorchBackend-129"><span class="linenos">129</span></a>            <span class="n">model_file</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">get_model_file</span><span class="p">(</span><span class="s2">&quot;model.pt&quot;</span><span class="p">)</span>
</span><span id="TorchBackend-130"><a href="#TorchBackend-130"><span class="linenos">130</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="n">model_file</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
</span><span id="TorchBackend-131"><a href="#TorchBackend-131"><span class="linenos">131</span></a>                <span class="k">raise</span> <span class="n">TorchModelLoadingError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model file not found: </span><span class="si">{</span><span class="n">model_file</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="TorchBackend-132"><a href="#TorchBackend-132"><span class="linenos">132</span></a>
</span><span id="TorchBackend-133"><a href="#TorchBackend-133"><span class="linenos">133</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading weights from </span><span class="si">{</span><span class="n">model_file</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="TorchBackend-134"><a href="#TorchBackend-134"><span class="linenos">134</span></a>            <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_file</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
</span><span id="TorchBackend-135"><a href="#TorchBackend-135"><span class="linenos">135</span></a>
</span><span id="TorchBackend-136"><a href="#TorchBackend-136"><span class="linenos">136</span></a>            <span class="c1"># Handle potential state_dict wrapper (e.g., {&quot;model&quot;: ...})</span>
</span><span id="TorchBackend-137"><a href="#TorchBackend-137"><span class="linenos">137</span></a>            <span class="k">if</span> <span class="s2">&quot;model&quot;</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="p">:</span>
</span><span id="TorchBackend-138"><a href="#TorchBackend-138"><span class="linenos">138</span></a>                <span class="n">state_dict</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">]</span>
</span><span id="TorchBackend-139"><a href="#TorchBackend-139"><span class="linenos">139</span></a>            <span class="k">if</span> <span class="s2">&quot;state_dict&quot;</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="p">:</span>
</span><span id="TorchBackend-140"><a href="#TorchBackend-140"><span class="linenos">140</span></a>                <span class="n">state_dict</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;state_dict&quot;</span><span class="p">]</span>
</span><span id="TorchBackend-141"><a href="#TorchBackend-141"><span class="linenos">141</span></a>
</span><span id="TorchBackend-142"><a href="#TorchBackend-142"><span class="linenos">142</span></a>            <span class="n">model_obj</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
</span><span id="TorchBackend-143"><a href="#TorchBackend-143"><span class="linenos">143</span></a>
</span><span id="TorchBackend-144"><a href="#TorchBackend-144"><span class="linenos">144</span></a>            <span class="n">model_module</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">model_obj</span><span class="p">)</span>
</span><span id="TorchBackend-145"><a href="#TorchBackend-145"><span class="linenos">145</span></a>            <span class="n">model_module</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
</span><span id="TorchBackend-146"><a href="#TorchBackend-146"><span class="linenos">146</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">model_module</span>
</span><span id="TorchBackend-147"><a href="#TorchBackend-147"><span class="linenos">147</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">preprocess</span><span class="p">)</span>
</span><span id="TorchBackend-148"><a href="#TorchBackend-148"><span class="linenos">148</span></a>
</span><span id="TorchBackend-149"><a href="#TorchBackend-149"><span class="linenos">149</span></a>            <span class="c1"># 4. Load tokenizer</span>
</span><span id="TorchBackend-150"><a href="#TorchBackend-150"><span class="linenos">150</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load_tokenizer</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
</span><span id="TorchBackend-151"><a href="#TorchBackend-151"><span class="linenos">151</span></a>
</span><span id="TorchBackend-152"><a href="#TorchBackend-152"><span class="linenos">152</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_load_time_seconds</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span>
</span><span id="TorchBackend-153"><a href="#TorchBackend-153"><span class="linenos">153</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="TorchBackend-154"><a href="#TorchBackend-154"><span class="linenos">154</span></a>
</span><span id="TorchBackend-155"><a href="#TorchBackend-155"><span class="linenos">155</span></a>            <span class="c1"># Update precision info</span>
</span><span id="TorchBackend-156"><a href="#TorchBackend-156"><span class="linenos">156</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_amp</span><span class="p">:</span>
</span><span id="TorchBackend-157"><a href="#TorchBackend-157"><span class="linenos">157</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_current_precision</span> <span class="o">=</span> <span class="s2">&quot;fp32+amp(fp16)&quot;</span>
</span><span id="TorchBackend-158"><a href="#TorchBackend-158"><span class="linenos">158</span></a>                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mixed precision (AMP) enabled on </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="TorchBackend-159"><a href="#TorchBackend-159"><span class="linenos">159</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="TorchBackend-160"><a href="#TorchBackend-160"><span class="linenos">160</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_current_precision</span> <span class="o">=</span> <span class="s2">&quot;fp32&quot;</span>
</span><span id="TorchBackend-161"><a href="#TorchBackend-161"><span class="linenos">161</span></a>
</span><span id="TorchBackend-162"><a href="#TorchBackend-162"><span class="linenos">162</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
</span><span id="TorchBackend-163"><a href="#TorchBackend-163"><span class="linenos">163</span></a>                <span class="sa">f</span><span class="s2">&quot;✅ TorchBackend initialized in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_load_time_seconds</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s&quot;</span>
</span><span id="TorchBackend-164"><a href="#TorchBackend-164"><span class="linenos">164</span></a>            <span class="p">)</span>
</span><span id="TorchBackend-165"><a href="#TorchBackend-165"><span class="linenos">165</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   Precision: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_current_precision</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="TorchBackend-166"><a href="#TorchBackend-166"><span class="linenos">166</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   Device: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="TorchBackend-167"><a href="#TorchBackend-167"><span class="linenos">167</span></a>
</span><span id="TorchBackend-168"><a href="#TorchBackend-168"><span class="linenos">168</span></a>        <span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="TorchBackend-169"><a href="#TorchBackend-169"><span class="linenos">169</span></a>            <span class="k">raise</span> <span class="n">TorchModelLoadingError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Required dependencies not found: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span><span id="TorchBackend-170"><a href="#TorchBackend-170"><span class="linenos">170</span></a>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="TorchBackend-171"><a href="#TorchBackend-171"><span class="linenos">171</span></a>            <span class="k">raise</span> <span class="n">TorchModelLoadingError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model loading failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span><span id="TorchBackend-172"><a href="#TorchBackend-172"><span class="linenos">172</span></a>
</span><span id="TorchBackend-173"><a href="#TorchBackend-173"><span class="linenos">173</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_load_tokenizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span id="TorchBackend-174"><a href="#TorchBackend-174"><span class="linenos">174</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Load tokenizer from tokenizer.json or fallback to SimpleTokenizer.&quot;&quot;&quot;</span>
</span><span id="TorchBackend-175"><a href="#TorchBackend-175"><span class="linenos">175</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">tokenizer_config</span><span class="p">:</span>
</span><span id="TorchBackend-176"><a href="#TorchBackend-176"><span class="linenos">176</span></a>            <span class="k">try</span><span class="p">:</span>
</span><span id="TorchBackend-177"><a href="#TorchBackend-177"><span class="linenos">177</span></a>                <span class="c1"># Try to use HuggingFace tokenizers</span>
</span><span id="TorchBackend-178"><a href="#TorchBackend-178"><span class="linenos">178</span></a>                <span class="kn">from</span><span class="w"> </span><span class="nn">tokenizers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tokenizer</span> <span class="k">as</span> <span class="n">HFTokenizer</span>
</span><span id="TorchBackend-179"><a href="#TorchBackend-179"><span class="linenos">179</span></a>
</span><span id="TorchBackend-180"><a href="#TorchBackend-180"><span class="linenos">180</span></a>                <span class="n">tokenizer_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">model_root_path</span> <span class="o">/</span> <span class="s2">&quot;tokenizer.json&quot;</span>
</span><span id="TorchBackend-181"><a href="#TorchBackend-181"><span class="linenos">181</span></a>                <span class="n">hf_tokenizer</span> <span class="o">=</span> <span class="n">HFTokenizer</span><span class="o">.</span><span class="n">from_file</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">tokenizer_path</span><span class="p">))</span>
</span><span id="TorchBackend-182"><a href="#TorchBackend-182"><span class="linenos">182</span></a>
</span><span id="TorchBackend-183"><a href="#TorchBackend-183"><span class="linenos">183</span></a>                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using custom tokenizer from tokenizer.json&quot;</span><span class="p">)</span>
</span><span id="TorchBackend-184"><a href="#TorchBackend-184"><span class="linenos">184</span></a>
</span><span id="TorchBackend-185"><a href="#TorchBackend-185"><span class="linenos">185</span></a>                <span class="c1"># Wrap HF tokenizer to match open_clip interface</span>
</span><span id="TorchBackend-186"><a href="#TorchBackend-186"><span class="linenos">186</span></a>                <span class="k">def</span><span class="w"> </span><span class="nf">tokenize_fn</span><span class="p">(</span><span class="n">texts</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="TorchBackend-187"><a href="#TorchBackend-187"><span class="linenos">187</span></a>                    <span class="n">encoded</span> <span class="o">=</span> <span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">encode_batch</span><span class="p">(</span><span class="n">texts</span><span class="p">)</span>
</span><span id="TorchBackend-188"><a href="#TorchBackend-188"><span class="linenos">188</span></a>                    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">enc</span><span class="o">.</span><span class="n">ids</span> <span class="k">for</span> <span class="n">enc</span> <span class="ow">in</span> <span class="n">encoded</span><span class="p">]</span>
</span><span id="TorchBackend-189"><a href="#TorchBackend-189"><span class="linenos">189</span></a>                    <span class="c1"># Pad to max length</span>
</span><span id="TorchBackend-190"><a href="#TorchBackend-190"><span class="linenos">190</span></a>                    <span class="n">max_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">)</span>
</span><span id="TorchBackend-191"><a href="#TorchBackend-191"><span class="linenos">191</span></a>                    <span class="n">padded</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">))</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
</span><span id="TorchBackend-192"><a href="#TorchBackend-192"><span class="linenos">192</span></a>                    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">padded</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
</span><span id="TorchBackend-193"><a href="#TorchBackend-193"><span class="linenos">193</span></a>
</span><span id="TorchBackend-194"><a href="#TorchBackend-194"><span class="linenos">194</span></a>                <span class="k">return</span> <span class="n">tokenize_fn</span>
</span><span id="TorchBackend-195"><a href="#TorchBackend-195"><span class="linenos">195</span></a>
</span><span id="TorchBackend-196"><a href="#TorchBackend-196"><span class="linenos">196</span></a>            <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
</span><span id="TorchBackend-197"><a href="#TorchBackend-197"><span class="linenos">197</span></a>                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
</span><span id="TorchBackend-198"><a href="#TorchBackend-198"><span class="linenos">198</span></a>                    <span class="s2">&quot;tokenizers library not available, falling back to SimpleTokenizer&quot;</span>
</span><span id="TorchBackend-199"><a href="#TorchBackend-199"><span class="linenos">199</span></a>                <span class="p">)</span>
</span><span id="TorchBackend-200"><a href="#TorchBackend-200"><span class="linenos">200</span></a>            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="TorchBackend-201"><a href="#TorchBackend-201"><span class="linenos">201</span></a>                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
</span><span id="TorchBackend-202"><a href="#TorchBackend-202"><span class="linenos">202</span></a>                    <span class="sa">f</span><span class="s2">&quot;Failed to load custom tokenizer: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">, &quot;</span>
</span><span id="TorchBackend-203"><a href="#TorchBackend-203"><span class="linenos">203</span></a>                    <span class="sa">f</span><span class="s2">&quot;falling back to SimpleTokenizer&quot;</span>
</span><span id="TorchBackend-204"><a href="#TorchBackend-204"><span class="linenos">204</span></a>                <span class="p">)</span>
</span><span id="TorchBackend-205"><a href="#TorchBackend-205"><span class="linenos">205</span></a>
</span><span id="TorchBackend-206"><a href="#TorchBackend-206"><span class="linenos">206</span></a>        <span class="c1"># Fallback to SimpleTokenizer</span>
</span><span id="TorchBackend-207"><a href="#TorchBackend-207"><span class="linenos">207</span></a>        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using SimpleTokenizer (fallback)&quot;</span><span class="p">)</span>
</span><span id="TorchBackend-208"><a href="#TorchBackend-208"><span class="linenos">208</span></a>        <span class="n">tokenizer_fun</span> <span class="o">=</span> <span class="n">open_clip</span><span class="o">.</span><span class="n">get_tokenizer</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
</span><span id="TorchBackend-209"><a href="#TorchBackend-209"><span class="linenos">209</span></a>        <span class="k">return</span> <span class="n">cast</span><span class="p">(</span><span class="n">Callable</span><span class="p">[[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">tokenizer_fun</span><span class="p">)</span>
</span><span id="TorchBackend-210"><a href="#TorchBackend-210"><span class="linenos">210</span></a>
</span><span id="TorchBackend-211"><a href="#TorchBackend-211"><span class="linenos">211</span></a>    <span class="nd">@override</span>
</span><span id="TorchBackend-212"><a href="#TorchBackend-212"><span class="linenos">212</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="TorchBackend-213"><a href="#TorchBackend-213"><span class="linenos">213</span></a>        <span class="c1"># Best-effort release; PyTorch will free on GC.</span>
</span><span id="TorchBackend-214"><a href="#TorchBackend-214"><span class="linenos">214</span></a>        <span class="n">m</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span>
</span><span id="TorchBackend-215"><a href="#TorchBackend-215"><span class="linenos">215</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="TorchBackend-216"><a href="#TorchBackend-216"><span class="linenos">216</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="TorchBackend-217"><a href="#TorchBackend-217"><span class="linenos">217</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="TorchBackend-218"><a href="#TorchBackend-218"><span class="linenos">218</span></a>        <span class="k">if</span> <span class="n">m</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
</span><span id="TorchBackend-219"><a href="#TorchBackend-219"><span class="linenos">219</span></a>            <span class="c1"># Free cached memory for the device</span>
</span><span id="TorchBackend-220"><a href="#TorchBackend-220"><span class="linenos">220</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</span><span id="TorchBackend-221"><a href="#TorchBackend-221"><span class="linenos">221</span></a>
</span><span id="TorchBackend-222"><a href="#TorchBackend-222"><span class="linenos">222</span></a>    <span class="c1"># ---------- Encoding API ----------</span>
</span><span id="TorchBackend-223"><a href="#TorchBackend-223"><span class="linenos">223</span></a>
</span><span id="TorchBackend-224"><a href="#TorchBackend-224"><span class="linenos">224</span></a>    <span class="nd">@torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">()</span>
</span><span id="TorchBackend-225"><a href="#TorchBackend-225"><span class="linenos">225</span></a>    <span class="nd">@override</span>
</span><span id="TorchBackend-226"><a href="#TorchBackend-226"><span class="linenos">226</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">text_to_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="TorchBackend-227"><a href="#TorchBackend-227"><span class="linenos">227</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="TorchBackend-228"><a href="#TorchBackend-228"><span class="linenos">228</span></a><span class="sd">        Encode a text string into a unit-normalized float32 embedding vector.</span>
</span><span id="TorchBackend-229"><a href="#TorchBackend-229"><span class="linenos">229</span></a><span class="sd">        Uses mixed precision (AMP) on GPU for better performance.</span>
</span><span id="TorchBackend-230"><a href="#TorchBackend-230"><span class="linenos">230</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="TorchBackend-231"><a href="#TorchBackend-231"><span class="linenos">231</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_initialized</span><span class="p">()</span>
</span><span id="TorchBackend-232"><a href="#TorchBackend-232"><span class="linenos">232</span></a>
</span><span id="TorchBackend-233"><a href="#TorchBackend-233"><span class="linenos">233</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">text</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
</span><span id="TorchBackend-234"><a href="#TorchBackend-234"><span class="linenos">234</span></a>            <span class="k">raise</span> <span class="n">InvalidInputError</span><span class="p">(</span><span class="s2">&quot;text cannot be empty or whitespace only&quot;</span><span class="p">)</span>
</span><span id="TorchBackend-235"><a href="#TorchBackend-235"><span class="linenos">235</span></a>
</span><span id="TorchBackend-236"><a href="#TorchBackend-236"><span class="linenos">236</span></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">10000</span><span class="p">:</span>  <span class="c1"># Reasonable length limit</span>
</span><span id="TorchBackend-237"><a href="#TorchBackend-237"><span class="linenos">237</span></a>            <span class="k">raise</span> <span class="n">InvalidInputError</span><span class="p">(</span><span class="s2">&quot;text too long (max 10000 characters)&quot;</span><span class="p">)</span>
</span><span id="TorchBackend-238"><a href="#TorchBackend-238"><span class="linenos">238</span></a>
</span><span id="TorchBackend-239"><a href="#TorchBackend-239"><span class="linenos">239</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="TorchBackend-240"><a href="#TorchBackend-240"><span class="linenos">240</span></a>            <span class="c1"># Create a simple CLIP-compatible prompt</span>
</span><span id="TorchBackend-241"><a href="#TorchBackend-241"><span class="linenos">241</span></a>            <span class="n">prompt</span> <span class="o">=</span> <span class="n">text</span>
</span><span id="TorchBackend-242"><a href="#TorchBackend-242"><span class="linenos">242</span></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="TorchBackend-243"><a href="#TorchBackend-243"><span class="linenos">243</span></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="TorchBackend-244"><a href="#TorchBackend-244"><span class="linenos">244</span></a>
</span><span id="TorchBackend-245"><a href="#TorchBackend-245"><span class="linenos">245</span></a>            <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">Callable</span><span class="p">[[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span><span class="p">)</span>
</span><span id="TorchBackend-246"><a href="#TorchBackend-246"><span class="linenos">246</span></a>            <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">([</span><span class="n">prompt</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
</span><span id="TorchBackend-247"><a href="#TorchBackend-247"><span class="linenos">247</span></a>
</span><span id="TorchBackend-248"><a href="#TorchBackend-248"><span class="linenos">248</span></a>            <span class="c1"># Use AMP if enabled (GPU only)</span>
</span><span id="TorchBackend-249"><a href="#TorchBackend-249"><span class="linenos">249</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_amp</span><span class="p">:</span>
</span><span id="TorchBackend-250"><a href="#TorchBackend-250"><span class="linenos">250</span></a>                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span>
</span><span id="TorchBackend-251"><a href="#TorchBackend-251"><span class="linenos">251</span></a>                    <span class="n">device_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_amp_dtype</span>
</span><span id="TorchBackend-252"><a href="#TorchBackend-252"><span class="linenos">252</span></a>                <span class="p">):</span>
</span><span id="TorchBackend-253"><a href="#TorchBackend-253"><span class="linenos">253</span></a>                    <span class="n">feats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">encode_text</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>
</span><span id="TorchBackend-254"><a href="#TorchBackend-254"><span class="linenos">254</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="TorchBackend-255"><a href="#TorchBackend-255"><span class="linenos">255</span></a>                <span class="n">feats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">encode_text</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>
</span><span id="TorchBackend-256"><a href="#TorchBackend-256"><span class="linenos">256</span></a>
</span><span id="TorchBackend-257"><a href="#TorchBackend-257"><span class="linenos">257</span></a>            <span class="n">feats</span> <span class="o">=</span> <span class="n">feats</span> <span class="o">/</span> <span class="n">feats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="TorchBackend-258"><a href="#TorchBackend-258"><span class="linenos">258</span></a>
</span><span id="TorchBackend-259"><a href="#TorchBackend-259"><span class="linenos">259</span></a>            <span class="n">vec</span> <span class="o">=</span> <span class="n">feats</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="TorchBackend-260"><a href="#TorchBackend-260"><span class="linenos">260</span></a>            <span class="k">return</span> <span class="n">vec</span>
</span><span id="TorchBackend-261"><a href="#TorchBackend-261"><span class="linenos">261</span></a>
</span><span id="TorchBackend-262"><a href="#TorchBackend-262"><span class="linenos">262</span></a>        <span class="k">except</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">OutOfMemoryError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="TorchBackend-263"><a href="#TorchBackend-263"><span class="linenos">263</span></a>            <span class="k">raise</span> <span class="n">CUDAMemoryError</span><span class="p">(</span>
</span><span id="TorchBackend-264"><a href="#TorchBackend-264"><span class="linenos">264</span></a>                <span class="sa">f</span><span class="s2">&quot;CUDA out of memory during text encoding: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="TorchBackend-265"><a href="#TorchBackend-265"><span class="linenos">265</span></a>            <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span><span id="TorchBackend-266"><a href="#TorchBackend-266"><span class="linenos">266</span></a>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="TorchBackend-267"><a href="#TorchBackend-267"><span class="linenos">267</span></a>            <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Text encoding failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span><span id="TorchBackend-268"><a href="#TorchBackend-268"><span class="linenos">268</span></a>
</span><span id="TorchBackend-269"><a href="#TorchBackend-269"><span class="linenos">269</span></a>    <span class="nd">@torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">()</span>
</span><span id="TorchBackend-270"><a href="#TorchBackend-270"><span class="linenos">270</span></a>    <span class="nd">@override</span>
</span><span id="TorchBackend-271"><a href="#TorchBackend-271"><span class="linenos">271</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">image_to_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_bytes</span><span class="p">:</span> <span class="nb">bytes</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="TorchBackend-272"><a href="#TorchBackend-272"><span class="linenos">272</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="TorchBackend-273"><a href="#TorchBackend-273"><span class="linenos">273</span></a><span class="sd">        Encode image bytes (RGB) into a unit-normalized float32 embedding vector.</span>
</span><span id="TorchBackend-274"><a href="#TorchBackend-274"><span class="linenos">274</span></a><span class="sd">        Uses mixed precision (AMP) on GPU for better performance.</span>
</span><span id="TorchBackend-275"><a href="#TorchBackend-275"><span class="linenos">275</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="TorchBackend-276"><a href="#TorchBackend-276"><span class="linenos">276</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_initialized</span><span class="p">()</span>
</span><span id="TorchBackend-277"><a href="#TorchBackend-277"><span class="linenos">277</span></a>
</span><span id="TorchBackend-278"><a href="#TorchBackend-278"><span class="linenos">278</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">image_bytes</span><span class="p">:</span>
</span><span id="TorchBackend-279"><a href="#TorchBackend-279"><span class="linenos">279</span></a>            <span class="k">raise</span> <span class="n">InvalidInputError</span><span class="p">(</span><span class="s2">&quot;image_bytes cannot be empty&quot;</span><span class="p">)</span>
</span><span id="TorchBackend-280"><a href="#TorchBackend-280"><span class="linenos">280</span></a>
</span><span id="TorchBackend-281"><a href="#TorchBackend-281"><span class="linenos">281</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="TorchBackend-282"><a href="#TorchBackend-282"><span class="linenos">282</span></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="TorchBackend-283"><a href="#TorchBackend-283"><span class="linenos">283</span></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="TorchBackend-284"><a href="#TorchBackend-284"><span class="linenos">284</span></a>
</span><span id="TorchBackend-285"><a href="#TorchBackend-285"><span class="linenos">285</span></a>            <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">image_bytes</span><span class="p">))</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">)</span>
</span><span id="TorchBackend-286"><a href="#TorchBackend-286"><span class="linenos">286</span></a>            <span class="n">preprocess</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess</span><span class="p">)</span>
</span><span id="TorchBackend-287"><a href="#TorchBackend-287"><span class="linenos">287</span></a>            <span class="n">tensor</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
</span><span id="TorchBackend-288"><a href="#TorchBackend-288"><span class="linenos">288</span></a>
</span><span id="TorchBackend-289"><a href="#TorchBackend-289"><span class="linenos">289</span></a>            <span class="c1"># Use AMP if enabled (GPU only)</span>
</span><span id="TorchBackend-290"><a href="#TorchBackend-290"><span class="linenos">290</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_amp</span><span class="p">:</span>
</span><span id="TorchBackend-291"><a href="#TorchBackend-291"><span class="linenos">291</span></a>                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span>
</span><span id="TorchBackend-292"><a href="#TorchBackend-292"><span class="linenos">292</span></a>                    <span class="n">device_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_amp_dtype</span>
</span><span id="TorchBackend-293"><a href="#TorchBackend-293"><span class="linenos">293</span></a>                <span class="p">):</span>
</span><span id="TorchBackend-294"><a href="#TorchBackend-294"><span class="linenos">294</span></a>                    <span class="n">feats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">encode_image</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>
</span><span id="TorchBackend-295"><a href="#TorchBackend-295"><span class="linenos">295</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="TorchBackend-296"><a href="#TorchBackend-296"><span class="linenos">296</span></a>                <span class="n">feats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">encode_image</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>
</span><span id="TorchBackend-297"><a href="#TorchBackend-297"><span class="linenos">297</span></a>
</span><span id="TorchBackend-298"><a href="#TorchBackend-298"><span class="linenos">298</span></a>            <span class="n">feats</span> <span class="o">=</span> <span class="n">feats</span> <span class="o">/</span> <span class="n">feats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="TorchBackend-299"><a href="#TorchBackend-299"><span class="linenos">299</span></a>
</span><span id="TorchBackend-300"><a href="#TorchBackend-300"><span class="linenos">300</span></a>            <span class="n">vec</span> <span class="o">=</span> <span class="n">feats</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="TorchBackend-301"><a href="#TorchBackend-301"><span class="linenos">301</span></a>            <span class="k">return</span> <span class="n">vec</span>
</span><span id="TorchBackend-302"><a href="#TorchBackend-302"><span class="linenos">302</span></a>
</span><span id="TorchBackend-303"><a href="#TorchBackend-303"><span class="linenos">303</span></a>        <span class="k">except</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">OutOfMemoryError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="TorchBackend-304"><a href="#TorchBackend-304"><span class="linenos">304</span></a>            <span class="k">raise</span> <span class="n">CUDAMemoryError</span><span class="p">(</span>
</span><span id="TorchBackend-305"><a href="#TorchBackend-305"><span class="linenos">305</span></a>                <span class="sa">f</span><span class="s2">&quot;CUDA out of memory during image encoding: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="TorchBackend-306"><a href="#TorchBackend-306"><span class="linenos">306</span></a>            <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span><span id="TorchBackend-307"><a href="#TorchBackend-307"><span class="linenos">307</span></a>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="TorchBackend-308"><a href="#TorchBackend-308"><span class="linenos">308</span></a>            <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Image encoding failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span><span id="TorchBackend-309"><a href="#TorchBackend-309"><span class="linenos">309</span></a>
</span><span id="TorchBackend-310"><a href="#TorchBackend-310"><span class="linenos">310</span></a>    <span class="nd">@torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">()</span>
</span><span id="TorchBackend-311"><a href="#TorchBackend-311"><span class="linenos">311</span></a>    <span class="nd">@override</span>
</span><span id="TorchBackend-312"><a href="#TorchBackend-312"><span class="linenos">312</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">image_batch_to_vectors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">bytes</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="TorchBackend-313"><a href="#TorchBackend-313"><span class="linenos">313</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="TorchBackend-314"><a href="#TorchBackend-314"><span class="linenos">314</span></a><span class="sd">        Encode a list of image bytes using a single batched forward pass.</span>
</span><span id="TorchBackend-315"><a href="#TorchBackend-315"><span class="linenos">315</span></a><span class="sd">        Uses mixed precision (AMP) on GPU for better performance.</span>
</span><span id="TorchBackend-316"><a href="#TorchBackend-316"><span class="linenos">316</span></a><span class="sd">        Falls back to BaseClipBackend&#39;s sequential implementation if images is empty.</span>
</span><span id="TorchBackend-317"><a href="#TorchBackend-317"><span class="linenos">317</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="TorchBackend-318"><a href="#TorchBackend-318"><span class="linenos">318</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">images</span><span class="p">:</span>
</span><span id="TorchBackend-319"><a href="#TorchBackend-319"><span class="linenos">319</span></a>            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">image_batch_to_vectors</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
</span><span id="TorchBackend-320"><a href="#TorchBackend-320"><span class="linenos">320</span></a>
</span><span id="TorchBackend-321"><a href="#TorchBackend-321"><span class="linenos">321</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_initialized</span><span class="p">()</span>
</span><span id="TorchBackend-322"><a href="#TorchBackend-322"><span class="linenos">322</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="TorchBackend-323"><a href="#TorchBackend-323"><span class="linenos">323</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="TorchBackend-324"><a href="#TorchBackend-324"><span class="linenos">324</span></a>        <span class="n">preprocess</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess</span><span class="p">)</span>
</span><span id="TorchBackend-325"><a href="#TorchBackend-325"><span class="linenos">325</span></a>
</span><span id="TorchBackend-326"><a href="#TorchBackend-326"><span class="linenos">326</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="TorchBackend-327"><a href="#TorchBackend-327"><span class="linenos">327</span></a>            <span class="c1"># Decode and preprocess to a batch tensor [N, C, H, W]</span>
</span><span id="TorchBackend-328"><a href="#TorchBackend-328"><span class="linenos">328</span></a>            <span class="n">tensors</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="TorchBackend-329"><a href="#TorchBackend-329"><span class="linenos">329</span></a>            <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">images</span><span class="p">:</span>
</span><span id="TorchBackend-330"><a href="#TorchBackend-330"><span class="linenos">330</span></a>                <span class="k">if</span> <span class="ow">not</span> <span class="n">b</span><span class="p">:</span>
</span><span id="TorchBackend-331"><a href="#TorchBackend-331"><span class="linenos">331</span></a>                    <span class="k">raise</span> <span class="n">InvalidInputError</span><span class="p">(</span><span class="s2">&quot;image bytes cannot be empty&quot;</span><span class="p">)</span>
</span><span id="TorchBackend-332"><a href="#TorchBackend-332"><span class="linenos">332</span></a>
</span><span id="TorchBackend-333"><a href="#TorchBackend-333"><span class="linenos">333</span></a>                <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">b</span><span class="p">))</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">)</span>
</span><span id="TorchBackend-334"><a href="#TorchBackend-334"><span class="linenos">334</span></a>                <span class="n">t</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</span><span id="TorchBackend-335"><a href="#TorchBackend-335"><span class="linenos">335</span></a>                <span class="n">tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
</span><span id="TorchBackend-336"><a href="#TorchBackend-336"><span class="linenos">336</span></a>
</span><span id="TorchBackend-337"><a href="#TorchBackend-337"><span class="linenos">337</span></a>            <span class="n">batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
</span><span id="TorchBackend-338"><a href="#TorchBackend-338"><span class="linenos">338</span></a>
</span><span id="TorchBackend-339"><a href="#TorchBackend-339"><span class="linenos">339</span></a>            <span class="c1"># Use AMP if enabled (GPU only)</span>
</span><span id="TorchBackend-340"><a href="#TorchBackend-340"><span class="linenos">340</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_amp</span><span class="p">:</span>
</span><span id="TorchBackend-341"><a href="#TorchBackend-341"><span class="linenos">341</span></a>                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span>
</span><span id="TorchBackend-342"><a href="#TorchBackend-342"><span class="linenos">342</span></a>                    <span class="n">device_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_amp_dtype</span>
</span><span id="TorchBackend-343"><a href="#TorchBackend-343"><span class="linenos">343</span></a>                <span class="p">):</span>
</span><span id="TorchBackend-344"><a href="#TorchBackend-344"><span class="linenos">344</span></a>                    <span class="n">feats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">encode_image</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>
</span><span id="TorchBackend-345"><a href="#TorchBackend-345"><span class="linenos">345</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="TorchBackend-346"><a href="#TorchBackend-346"><span class="linenos">346</span></a>                <span class="n">feats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">encode_image</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>
</span><span id="TorchBackend-347"><a href="#TorchBackend-347"><span class="linenos">347</span></a>
</span><span id="TorchBackend-348"><a href="#TorchBackend-348"><span class="linenos">348</span></a>            <span class="n">feats</span> <span class="o">=</span> <span class="n">feats</span> <span class="o">/</span> <span class="n">feats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="TorchBackend-349"><a href="#TorchBackend-349"><span class="linenos">349</span></a>
</span><span id="TorchBackend-350"><a href="#TorchBackend-350"><span class="linenos">350</span></a>            <span class="n">arr</span> <span class="o">=</span> <span class="n">feats</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="TorchBackend-351"><a href="#TorchBackend-351"><span class="linenos">351</span></a>            <span class="k">return</span> <span class="n">arr</span>
</span><span id="TorchBackend-352"><a href="#TorchBackend-352"><span class="linenos">352</span></a>
</span><span id="TorchBackend-353"><a href="#TorchBackend-353"><span class="linenos">353</span></a>        <span class="k">except</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">OutOfMemoryError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="TorchBackend-354"><a href="#TorchBackend-354"><span class="linenos">354</span></a>            <span class="k">raise</span> <span class="n">CUDAMemoryError</span><span class="p">(</span>
</span><span id="TorchBackend-355"><a href="#TorchBackend-355"><span class="linenos">355</span></a>                <span class="sa">f</span><span class="s2">&quot;CUDA out of memory during batch image encoding: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="TorchBackend-356"><a href="#TorchBackend-356"><span class="linenos">356</span></a>            <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span><span id="TorchBackend-357"><a href="#TorchBackend-357"><span class="linenos">357</span></a>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="TorchBackend-358"><a href="#TorchBackend-358"><span class="linenos">358</span></a>            <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Batch image encoding failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span><span id="TorchBackend-359"><a href="#TorchBackend-359"><span class="linenos">359</span></a>
</span><span id="TorchBackend-360"><a href="#TorchBackend-360"><span class="linenos">360</span></a>    <span class="nd">@torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">()</span>
</span><span id="TorchBackend-361"><a href="#TorchBackend-361"><span class="linenos">361</span></a>    <span class="nd">@override</span>
</span><span id="TorchBackend-362"><a href="#TorchBackend-362"><span class="linenos">362</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">text_batch_to_vectors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">texts</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="TorchBackend-363"><a href="#TorchBackend-363"><span class="linenos">363</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="TorchBackend-364"><a href="#TorchBackend-364"><span class="linenos">364</span></a><span class="sd">        Encode a batch of text strings into unit-normalized float32 embedding vectors.</span>
</span><span id="TorchBackend-365"><a href="#TorchBackend-365"><span class="linenos">365</span></a><span class="sd">        Uses mixed precision (AMP) on GPU for better performance.</span>
</span><span id="TorchBackend-366"><a href="#TorchBackend-366"><span class="linenos">366</span></a>
</span><span id="TorchBackend-367"><a href="#TorchBackend-367"><span class="linenos">367</span></a><span class="sd">        Args:</span>
</span><span id="TorchBackend-368"><a href="#TorchBackend-368"><span class="linenos">368</span></a><span class="sd">            texts: Sequence of text strings to encode.</span>
</span><span id="TorchBackend-369"><a href="#TorchBackend-369"><span class="linenos">369</span></a>
</span><span id="TorchBackend-370"><a href="#TorchBackend-370"><span class="linenos">370</span></a><span class="sd">        Returns:</span>
</span><span id="TorchBackend-371"><a href="#TorchBackend-371"><span class="linenos">371</span></a><span class="sd">            np.ndarray with shape (N, D) and dtype float32, each row L2-normalized.</span>
</span><span id="TorchBackend-372"><a href="#TorchBackend-372"><span class="linenos">372</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="TorchBackend-373"><a href="#TorchBackend-373"><span class="linenos">373</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_initialized</span><span class="p">()</span>
</span><span id="TorchBackend-374"><a href="#TorchBackend-374"><span class="linenos">374</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="TorchBackend-375"><a href="#TorchBackend-375"><span class="linenos">375</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="TorchBackend-376"><a href="#TorchBackend-376"><span class="linenos">376</span></a>
</span><span id="TorchBackend-377"><a href="#TorchBackend-377"><span class="linenos">377</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">texts</span><span class="p">:</span>
</span><span id="TorchBackend-378"><a href="#TorchBackend-378"><span class="linenos">378</span></a>            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="TorchBackend-379"><a href="#TorchBackend-379"><span class="linenos">379</span></a>
</span><span id="TorchBackend-380"><a href="#TorchBackend-380"><span class="linenos">380</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="TorchBackend-381"><a href="#TorchBackend-381"><span class="linenos">381</span></a>            <span class="c1"># Validate inputs</span>
</span><span id="TorchBackend-382"><a href="#TorchBackend-382"><span class="linenos">382</span></a>            <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">:</span>
</span><span id="TorchBackend-383"><a href="#TorchBackend-383"><span class="linenos">383</span></a>                <span class="k">if</span> <span class="ow">not</span> <span class="n">text</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
</span><span id="TorchBackend-384"><a href="#TorchBackend-384"><span class="linenos">384</span></a>                    <span class="k">raise</span> <span class="n">InvalidInputError</span><span class="p">(</span><span class="s2">&quot;text cannot be empty or whitespace only&quot;</span><span class="p">)</span>
</span><span id="TorchBackend-385"><a href="#TorchBackend-385"><span class="linenos">385</span></a>                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">10000</span><span class="p">:</span>  <span class="c1"># Reasonable length limit</span>
</span><span id="TorchBackend-386"><a href="#TorchBackend-386"><span class="linenos">386</span></a>                    <span class="k">raise</span> <span class="n">InvalidInputError</span><span class="p">(</span><span class="s2">&quot;text too long (max 10000 characters)&quot;</span><span class="p">)</span>
</span><span id="TorchBackend-387"><a href="#TorchBackend-387"><span class="linenos">387</span></a>
</span><span id="TorchBackend-388"><a href="#TorchBackend-388"><span class="linenos">388</span></a>            <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">Callable</span><span class="p">[[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span><span class="p">)</span>
</span><span id="TorchBackend-389"><a href="#TorchBackend-389"><span class="linenos">389</span></a>            <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">texts</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
</span><span id="TorchBackend-390"><a href="#TorchBackend-390"><span class="linenos">390</span></a>
</span><span id="TorchBackend-391"><a href="#TorchBackend-391"><span class="linenos">391</span></a>            <span class="c1"># Use AMP if enabled (GPU only)</span>
</span><span id="TorchBackend-392"><a href="#TorchBackend-392"><span class="linenos">392</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_amp</span><span class="p">:</span>
</span><span id="TorchBackend-393"><a href="#TorchBackend-393"><span class="linenos">393</span></a>                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span>
</span><span id="TorchBackend-394"><a href="#TorchBackend-394"><span class="linenos">394</span></a>                    <span class="n">device_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_amp_dtype</span>
</span><span id="TorchBackend-395"><a href="#TorchBackend-395"><span class="linenos">395</span></a>                <span class="p">):</span>
</span><span id="TorchBackend-396"><a href="#TorchBackend-396"><span class="linenos">396</span></a>                    <span class="n">feats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">encode_text</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>
</span><span id="TorchBackend-397"><a href="#TorchBackend-397"><span class="linenos">397</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="TorchBackend-398"><a href="#TorchBackend-398"><span class="linenos">398</span></a>                <span class="n">feats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">encode_text</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>
</span><span id="TorchBackend-399"><a href="#TorchBackend-399"><span class="linenos">399</span></a>
</span><span id="TorchBackend-400"><a href="#TorchBackend-400"><span class="linenos">400</span></a>            <span class="n">feats</span> <span class="o">=</span> <span class="n">feats</span> <span class="o">/</span> <span class="n">feats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="TorchBackend-401"><a href="#TorchBackend-401"><span class="linenos">401</span></a>
</span><span id="TorchBackend-402"><a href="#TorchBackend-402"><span class="linenos">402</span></a>            <span class="n">vecs</span> <span class="o">=</span> <span class="n">feats</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="TorchBackend-403"><a href="#TorchBackend-403"><span class="linenos">403</span></a>            <span class="k">return</span> <span class="n">vecs</span>
</span><span id="TorchBackend-404"><a href="#TorchBackend-404"><span class="linenos">404</span></a>
</span><span id="TorchBackend-405"><a href="#TorchBackend-405"><span class="linenos">405</span></a>        <span class="k">except</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">OutOfMemoryError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="TorchBackend-406"><a href="#TorchBackend-406"><span class="linenos">406</span></a>            <span class="k">raise</span> <span class="n">CUDAMemoryError</span><span class="p">(</span>
</span><span id="TorchBackend-407"><a href="#TorchBackend-407"><span class="linenos">407</span></a>                <span class="sa">f</span><span class="s2">&quot;CUDA out of memory during batch text encoding: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="TorchBackend-408"><a href="#TorchBackend-408"><span class="linenos">408</span></a>            <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span><span id="TorchBackend-409"><a href="#TorchBackend-409"><span class="linenos">409</span></a>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="TorchBackend-410"><a href="#TorchBackend-410"><span class="linenos">410</span></a>            <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Batch text encoding failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span><span id="TorchBackend-411"><a href="#TorchBackend-411"><span class="linenos">411</span></a>
</span><span id="TorchBackend-412"><a href="#TorchBackend-412"><span class="linenos">412</span></a>    <span class="nd">@override</span>
</span><span id="TorchBackend-413"><a href="#TorchBackend-413"><span class="linenos">413</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_info</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BackendInfo</span><span class="p">:</span>
</span><span id="TorchBackend-414"><a href="#TorchBackend-414"><span class="linenos">414</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="TorchBackend-415"><a href="#TorchBackend-415"><span class="linenos">415</span></a><span class="sd">        Report runtime and model metadata.</span>
</span><span id="TorchBackend-416"><a href="#TorchBackend-416"><span class="linenos">416</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="TorchBackend-417"><a href="#TorchBackend-417"><span class="linenos">417</span></a>        <span class="c1"># Report precision: always loads fp32 weights, uses AMP on GPU</span>
</span><span id="TorchBackend-418"><a href="#TorchBackend-418"><span class="linenos">418</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_amp</span><span class="p">:</span>
</span><span id="TorchBackend-419"><a href="#TorchBackend-419"><span class="linenos">419</span></a>            <span class="n">precisions</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;fp32&quot;</span><span class="p">,</span> <span class="s2">&quot;fp16(amp)&quot;</span><span class="p">]</span>
</span><span id="TorchBackend-420"><a href="#TorchBackend-420"><span class="linenos">420</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="TorchBackend-421"><a href="#TorchBackend-421"><span class="linenos">421</span></a>            <span class="n">precisions</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;fp32&quot;</span><span class="p">]</span>
</span><span id="TorchBackend-422"><a href="#TorchBackend-422"><span class="linenos">422</span></a>
</span><span id="TorchBackend-423"><a href="#TorchBackend-423"><span class="linenos">423</span></a>        <span class="n">version</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">open_clip</span><span class="p">,</span> <span class="s2">&quot;__version__&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span><span id="TorchBackend-424"><a href="#TorchBackend-424"><span class="linenos">424</span></a>
</span><span id="TorchBackend-425"><a href="#TorchBackend-425"><span class="linenos">425</span></a>        <span class="c1"># Get embedding dimension from resources</span>
</span><span id="TorchBackend-426"><a href="#TorchBackend-426"><span class="linenos">426</span></a>        <span class="n">embed_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">get_embedding_dim</span><span class="p">()</span>
</span><span id="TorchBackend-427"><a href="#TorchBackend-427"><span class="linenos">427</span></a>
</span><span id="TorchBackend-428"><a href="#TorchBackend-428"><span class="linenos">428</span></a>        <span class="c1"># Get image size from resources</span>
</span><span id="TorchBackend-429"><a href="#TorchBackend-429"><span class="linenos">429</span></a>        <span class="n">image_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">get_image_size</span><span class="p">()</span>
</span><span id="TorchBackend-430"><a href="#TorchBackend-430"><span class="linenos">430</span></a>        <span class="n">image_size_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">image_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">x</span><span class="si">{</span><span class="n">image_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">if</span> <span class="n">image_size</span> <span class="k">else</span> <span class="kc">None</span>
</span><span id="TorchBackend-431"><a href="#TorchBackend-431"><span class="linenos">431</span></a>
</span><span id="TorchBackend-432"><a href="#TorchBackend-432"><span class="linenos">432</span></a>        <span class="k">return</span> <span class="n">BackendInfo</span><span class="p">(</span>
</span><span id="TorchBackend-433"><a href="#TorchBackend-433"><span class="linenos">433</span></a>            <span class="n">runtime</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span>
</span><span id="TorchBackend-434"><a href="#TorchBackend-434"><span class="linenos">434</span></a>            <span class="n">device</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">),</span>
</span><span id="TorchBackend-435"><a href="#TorchBackend-435"><span class="linenos">435</span></a>            <span class="n">model_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span>
</span><span id="TorchBackend-436"><a href="#TorchBackend-436"><span class="linenos">436</span></a>            <span class="n">model_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
</span><span id="TorchBackend-437"><a href="#TorchBackend-437"><span class="linenos">437</span></a>                <span class="s2">&quot;model_name&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">model_name</span>
</span><span id="TorchBackend-438"><a href="#TorchBackend-438"><span class="linenos">438</span></a>            <span class="p">),</span>
</span><span id="TorchBackend-439"><a href="#TorchBackend-439"><span class="linenos">439</span></a>            <span class="n">pretrained</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># Local weights, no pretrained tag</span>
</span><span id="TorchBackend-440"><a href="#TorchBackend-440"><span class="linenos">440</span></a>            <span class="n">version</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">version</span><span class="p">)</span> <span class="k">if</span> <span class="n">version</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="TorchBackend-441"><a href="#TorchBackend-441"><span class="linenos">441</span></a>            <span class="n">image_embedding_dim</span><span class="o">=</span><span class="n">embed_dim</span><span class="p">,</span>
</span><span id="TorchBackend-442"><a href="#TorchBackend-442"><span class="linenos">442</span></a>            <span class="n">text_embedding_dim</span><span class="o">=</span><span class="n">embed_dim</span><span class="p">,</span>
</span><span id="TorchBackend-443"><a href="#TorchBackend-443"><span class="linenos">443</span></a>            <span class="n">precisions</span><span class="o">=</span><span class="n">precisions</span><span class="p">,</span>
</span><span id="TorchBackend-444"><a href="#TorchBackend-444"><span class="linenos">444</span></a>            <span class="n">max_batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_max_batch_size</span><span class="p">,</span>
</span><span id="TorchBackend-445"><a href="#TorchBackend-445"><span class="linenos">445</span></a>            <span class="n">supports_image_batch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="TorchBackend-446"><a href="#TorchBackend-446"><span class="linenos">446</span></a>            <span class="n">extra</span><span class="o">=</span><span class="p">{</span>
</span><span id="TorchBackend-447"><a href="#TorchBackend-447"><span class="linenos">447</span></a>                <span class="s2">&quot;library&quot;</span><span class="p">:</span> <span class="s2">&quot;open-clip-torch&quot;</span><span class="p">,</span>
</span><span id="TorchBackend-448"><a href="#TorchBackend-448"><span class="linenos">448</span></a>                <span class="s2">&quot;image_size&quot;</span><span class="p">:</span> <span class="n">image_size_str</span><span class="p">,</span>
</span><span id="TorchBackend-449"><a href="#TorchBackend-449"><span class="linenos">449</span></a>                <span class="s2">&quot;config_path&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">model_root_path</span> <span class="o">/</span> <span class="s2">&quot;config.json&quot;</span><span class="p">),</span>
</span><span id="TorchBackend-450"><a href="#TorchBackend-450"><span class="linenos">450</span></a>            <span class="p">},</span>
</span><span id="TorchBackend-451"><a href="#TorchBackend-451"><span class="linenos">451</span></a>        <span class="p">)</span>
</span><span id="TorchBackend-452"><a href="#TorchBackend-452"><span class="linenos">452</span></a>
</span><span id="TorchBackend-453"><a href="#TorchBackend-453"><span class="linenos">453</span></a>    <span class="c1"># ---------- Helpers ----------</span>
</span><span id="TorchBackend-454"><a href="#TorchBackend-454"><span class="linenos">454</span></a>
</span><span id="TorchBackend-455"><a href="#TorchBackend-455"><span class="linenos">455</span></a>    <span class="nd">@staticmethod</span>
</span><span id="TorchBackend-456"><a href="#TorchBackend-456"><span class="linenos">456</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_select_device</span><span class="p">(</span><span class="n">preference</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
</span><span id="TorchBackend-457"><a href="#TorchBackend-457"><span class="linenos">457</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="TorchBackend-458"><a href="#TorchBackend-458"><span class="linenos">458</span></a><span class="sd">        Choose a torch.device based on an optional preference and availability.</span>
</span><span id="TorchBackend-459"><a href="#TorchBackend-459"><span class="linenos">459</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="TorchBackend-460"><a href="#TorchBackend-460"><span class="linenos">460</span></a>        <span class="n">pref</span> <span class="o">=</span> <span class="p">(</span><span class="n">preference</span> <span class="ow">or</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
</span><span id="TorchBackend-461"><a href="#TorchBackend-461"><span class="linenos">461</span></a>        <span class="k">if</span> <span class="n">pref</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
</span><span id="TorchBackend-462"><a href="#TorchBackend-462"><span class="linenos">462</span></a>            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</span><span id="TorchBackend-463"><a href="#TorchBackend-463"><span class="linenos">463</span></a>        <span class="k">if</span> <span class="n">pref</span> <span class="o">==</span> <span class="s2">&quot;mps&quot;</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
</span><span id="TorchBackend-464"><a href="#TorchBackend-464"><span class="linenos">464</span></a>            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;mps&quot;</span><span class="p">)</span>
</span><span id="TorchBackend-465"><a href="#TorchBackend-465"><span class="linenos">465</span></a>        <span class="k">if</span> <span class="n">pref</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span><span class="p">:</span>
</span><span id="TorchBackend-466"><a href="#TorchBackend-466"><span class="linenos">466</span></a>            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</span><span id="TorchBackend-467"><a href="#TorchBackend-467"><span class="linenos">467</span></a>
</span><span id="TorchBackend-468"><a href="#TorchBackend-468"><span class="linenos">468</span></a>        <span class="c1"># Auto-detect best available</span>
</span><span id="TorchBackend-469"><a href="#TorchBackend-469"><span class="linenos">469</span></a>        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
</span><span id="TorchBackend-470"><a href="#TorchBackend-470"><span class="linenos">470</span></a>            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</span><span id="TorchBackend-471"><a href="#TorchBackend-471"><span class="linenos">471</span></a>        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
</span><span id="TorchBackend-472"><a href="#TorchBackend-472"><span class="linenos">472</span></a>            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;mps&quot;</span><span class="p">)</span>
</span><span id="TorchBackend-473"><a href="#TorchBackend-473"><span class="linenos">473</span></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</span><span id="TorchBackend-474"><a href="#TorchBackend-474"><span class="linenos">474</span></a>
</span><span id="TorchBackend-475"><a href="#TorchBackend-475"><span class="linenos">475</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_ensure_initialized</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="TorchBackend-476"><a href="#TorchBackend-476"><span class="linenos">476</span></a>        <span class="k">if</span> <span class="p">(</span>
</span><span id="TorchBackend-477"><a href="#TorchBackend-477"><span class="linenos">477</span></a>            <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span>
</span><span id="TorchBackend-478"><a href="#TorchBackend-478"><span class="linenos">478</span></a>            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="kc">None</span>
</span><span id="TorchBackend-479"><a href="#TorchBackend-479"><span class="linenos">479</span></a>            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess</span> <span class="ow">is</span> <span class="kc">None</span>
</span><span id="TorchBackend-480"><a href="#TorchBackend-480"><span class="linenos">480</span></a>            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span> <span class="ow">is</span> <span class="kc">None</span>
</span><span id="TorchBackend-481"><a href="#TorchBackend-481"><span class="linenos">481</span></a>        <span class="p">):</span>
</span><span id="TorchBackend-482"><a href="#TorchBackend-482"><span class="linenos">482</span></a>            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
</span><span id="TorchBackend-483"><a href="#TorchBackend-483"><span class="linenos">483</span></a>                <span class="s2">&quot;TorchBackend is not initialized. Call initialize() first.&quot;</span>
</span><span id="TorchBackend-484"><a href="#TorchBackend-484"><span class="linenos">484</span></a>            <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>A PyTorch/OpenCLIP backend implementing BaseClipBackend.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>resources:</strong>  ModelResources object containing model files and configs</li>
<li><strong>device_preference:</strong>  Optional hint for device selection ("cuda", "mps", "cpu").</li>
<li><strong>max_batch_size:</strong>  Optional hint for batch size; not enforced by backend.</li>
</ul>

<h6 id="behavior">Behavior:</h6>

<blockquote>
  <ul>
  <li>initialize() loads the model from local files, tokenizer, and preprocess pipeline</li>
  <li>Always loads FP32 weights (model.pt)</li>
  <li>Uses mixed precision (AMP) on GPU (CUDA/MPS) for inference</li>
  <li>text_to_vector() encodes a text prompt via the model's text encoder</li>
  <li>image_to_vector() decodes and preprocesses image bytes, then encodes via the image encoder</li>
  <li>image_batch_to_vectors() performs a single batched forward pass for multiple images</li>
  </ul>
</blockquote>
</div>


                            <div id="TorchBackend.__init__" class="classattr">
                                        <input id="TorchBackend.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">TorchBackend</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">resources</span><span class="p">:</span> <span class="n"><a href="resources.html#ModelResources">lumen_clip.resources.ModelResources</a></span>,</span><span class="param">	<span class="n">device_preference</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">max_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="TorchBackend.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TorchBackend.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TorchBackend.__init__-82"><a href="#TorchBackend.__init__-82"><span class="linenos"> 82</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="TorchBackend.__init__-83"><a href="#TorchBackend.__init__-83"><span class="linenos"> 83</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="TorchBackend.__init__-84"><a href="#TorchBackend.__init__-84"><span class="linenos"> 84</span></a>        <span class="n">resources</span><span class="p">:</span> <span class="s2">&quot;ModelResources&quot;</span><span class="p">,</span>
</span><span id="TorchBackend.__init__-85"><a href="#TorchBackend.__init__-85"><span class="linenos"> 85</span></a>        <span class="n">device_preference</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="TorchBackend.__init__-86"><a href="#TorchBackend.__init__-86"><span class="linenos"> 86</span></a>        <span class="n">max_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="TorchBackend.__init__-87"><a href="#TorchBackend.__init__-87"><span class="linenos"> 87</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="TorchBackend.__init__-88"><a href="#TorchBackend.__init__-88"><span class="linenos"> 88</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="TorchBackend.__init__-89"><a href="#TorchBackend.__init__-89"><span class="linenos"> 89</span></a>            <span class="n">resources</span><span class="o">=</span><span class="n">resources</span><span class="p">,</span>
</span><span id="TorchBackend.__init__-90"><a href="#TorchBackend.__init__-90"><span class="linenos"> 90</span></a>            <span class="n">device_preference</span><span class="o">=</span><span class="n">device_preference</span><span class="p">,</span>
</span><span id="TorchBackend.__init__-91"><a href="#TorchBackend.__init__-91"><span class="linenos"> 91</span></a>            <span class="n">max_batch_size</span><span class="o">=</span><span class="n">max_batch_size</span><span class="p">,</span>
</span><span id="TorchBackend.__init__-92"><a href="#TorchBackend.__init__-92"><span class="linenos"> 92</span></a>        <span class="p">)</span>
</span><span id="TorchBackend.__init__-93"><a href="#TorchBackend.__init__-93"><span class="linenos"> 93</span></a>
</span><span id="TorchBackend.__init__-94"><a href="#TorchBackend.__init__-94"><span class="linenos"> 94</span></a>        <span class="c1"># Runtime objects</span>
</span><span id="TorchBackend.__init__-95"><a href="#TorchBackend.__init__-95"><span class="linenos"> 95</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_device</span><span class="p">(</span><span class="n">device_preference</span><span class="p">)</span>
</span><span id="TorchBackend.__init__-96"><a href="#TorchBackend.__init__-96"><span class="linenos"> 96</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="TorchBackend.__init__-97"><a href="#TorchBackend.__init__-97"><span class="linenos"> 97</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="TorchBackend.__init__-98"><a href="#TorchBackend.__init__-98"><span class="linenos"> 98</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="TorchBackend.__init__-99"><a href="#TorchBackend.__init__-99"><span class="linenos"> 99</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_load_time_seconds</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="TorchBackend.__init__-100"><a href="#TorchBackend.__init__-100"><span class="linenos">100</span></a>
</span><span id="TorchBackend.__init__-101"><a href="#TorchBackend.__init__-101"><span class="linenos">101</span></a>        <span class="c1"># Mixed precision settings</span>
</span><span id="TorchBackend.__init__-102"><a href="#TorchBackend.__init__-102"><span class="linenos">102</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_use_amp</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</span><span id="TorchBackend.__init__-103"><a href="#TorchBackend.__init__-103"><span class="linenos">103</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_amp_dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span>
</span><span id="TorchBackend.__init__-104"><a href="#TorchBackend.__init__-104"><span class="linenos">104</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_current_precision</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;fp32&quot;</span>  <span class="c1"># Will be updated after init</span>
</span></pre></div>


            <div class="docstring"><p>Construct a backend with model resources.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>resources:</strong>  ModelResources object containing all model files and configs</li>
<li><strong>device_preference:</strong>  Hint for device selection (e.g., "cuda", "mps", "cpu").</li>
<li><strong>max_batch_size:</strong>  Hint for batching; implementation may clamp lower/higher.</li>
</ul>
</div>


                            </div>
                            <div id="TorchBackend.initialize" class="classattr">
                                        <input id="TorchBackend.initialize-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-override">@override</div>

        <span class="def">def</span>
        <span class="name">initialize</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

                <label class="view-source-button" for="TorchBackend.initialize-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TorchBackend.initialize"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TorchBackend.initialize-108"><a href="#TorchBackend.initialize-108"><span class="linenos">108</span></a>    <span class="nd">@override</span>
</span><span id="TorchBackend.initialize-109"><a href="#TorchBackend.initialize-109"><span class="linenos">109</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="TorchBackend.initialize-110"><a href="#TorchBackend.initialize-110"><span class="linenos">110</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span><span class="p">:</span>
</span><span id="TorchBackend.initialize-111"><a href="#TorchBackend.initialize-111"><span class="linenos">111</span></a>            <span class="k">return</span>
</span><span id="TorchBackend.initialize-112"><a href="#TorchBackend.initialize-112"><span class="linenos">112</span></a>
</span><span id="TorchBackend.initialize-113"><a href="#TorchBackend.initialize-113"><span class="linenos">113</span></a>        <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</span><span id="TorchBackend.initialize-114"><a href="#TorchBackend.initialize-114"><span class="linenos">114</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="TorchBackend.initialize-115"><a href="#TorchBackend.initialize-115"><span class="linenos">115</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Initializing TorchBackend for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="TorchBackend.initialize-116"><a href="#TorchBackend.initialize-116"><span class="linenos">116</span></a>
</span><span id="TorchBackend.initialize-117"><a href="#TorchBackend.initialize-117"><span class="linenos">117</span></a>            <span class="c1"># 1. Get model architecture name from config</span>
</span><span id="TorchBackend.initialize-118"><a href="#TorchBackend.initialize-118"><span class="linenos">118</span></a>            <span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">config</span>
</span><span id="TorchBackend.initialize-119"><a href="#TorchBackend.initialize-119"><span class="linenos">119</span></a>            <span class="n">model_name</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;model_name&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">model_name</span><span class="p">)</span>
</span><span id="TorchBackend.initialize-120"><a href="#TorchBackend.initialize-120"><span class="linenos">120</span></a>
</span><span id="TorchBackend.initialize-121"><a href="#TorchBackend.initialize-121"><span class="linenos">121</span></a>            <span class="c1"># 2. Create model architecture without pretrained weights</span>
</span><span id="TorchBackend.initialize-122"><a href="#TorchBackend.initialize-122"><span class="linenos">122</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Creating model architecture: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="TorchBackend.initialize-123"><a href="#TorchBackend.initialize-123"><span class="linenos">123</span></a>            <span class="n">model_obj</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">preprocess</span> <span class="o">=</span> <span class="n">open_clip</span><span class="o">.</span><span class="n">create_model_and_transforms</span><span class="p">(</span>
</span><span id="TorchBackend.initialize-124"><a href="#TorchBackend.initialize-124"><span class="linenos">124</span></a>                <span class="n">model_name</span><span class="p">,</span>
</span><span id="TorchBackend.initialize-125"><a href="#TorchBackend.initialize-125"><span class="linenos">125</span></a>                <span class="n">pretrained</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># No automatic download</span>
</span><span id="TorchBackend.initialize-126"><a href="#TorchBackend.initialize-126"><span class="linenos">126</span></a>            <span class="p">)</span>
</span><span id="TorchBackend.initialize-127"><a href="#TorchBackend.initialize-127"><span class="linenos">127</span></a>
</span><span id="TorchBackend.initialize-128"><a href="#TorchBackend.initialize-128"><span class="linenos">128</span></a>            <span class="c1"># 3. Load local weights</span>
</span><span id="TorchBackend.initialize-129"><a href="#TorchBackend.initialize-129"><span class="linenos">129</span></a>            <span class="n">model_file</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">get_model_file</span><span class="p">(</span><span class="s2">&quot;model.pt&quot;</span><span class="p">)</span>
</span><span id="TorchBackend.initialize-130"><a href="#TorchBackend.initialize-130"><span class="linenos">130</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="n">model_file</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
</span><span id="TorchBackend.initialize-131"><a href="#TorchBackend.initialize-131"><span class="linenos">131</span></a>                <span class="k">raise</span> <span class="n">TorchModelLoadingError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model file not found: </span><span class="si">{</span><span class="n">model_file</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="TorchBackend.initialize-132"><a href="#TorchBackend.initialize-132"><span class="linenos">132</span></a>
</span><span id="TorchBackend.initialize-133"><a href="#TorchBackend.initialize-133"><span class="linenos">133</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading weights from </span><span class="si">{</span><span class="n">model_file</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="TorchBackend.initialize-134"><a href="#TorchBackend.initialize-134"><span class="linenos">134</span></a>            <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_file</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
</span><span id="TorchBackend.initialize-135"><a href="#TorchBackend.initialize-135"><span class="linenos">135</span></a>
</span><span id="TorchBackend.initialize-136"><a href="#TorchBackend.initialize-136"><span class="linenos">136</span></a>            <span class="c1"># Handle potential state_dict wrapper (e.g., {&quot;model&quot;: ...})</span>
</span><span id="TorchBackend.initialize-137"><a href="#TorchBackend.initialize-137"><span class="linenos">137</span></a>            <span class="k">if</span> <span class="s2">&quot;model&quot;</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="p">:</span>
</span><span id="TorchBackend.initialize-138"><a href="#TorchBackend.initialize-138"><span class="linenos">138</span></a>                <span class="n">state_dict</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">]</span>
</span><span id="TorchBackend.initialize-139"><a href="#TorchBackend.initialize-139"><span class="linenos">139</span></a>            <span class="k">if</span> <span class="s2">&quot;state_dict&quot;</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="p">:</span>
</span><span id="TorchBackend.initialize-140"><a href="#TorchBackend.initialize-140"><span class="linenos">140</span></a>                <span class="n">state_dict</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;state_dict&quot;</span><span class="p">]</span>
</span><span id="TorchBackend.initialize-141"><a href="#TorchBackend.initialize-141"><span class="linenos">141</span></a>
</span><span id="TorchBackend.initialize-142"><a href="#TorchBackend.initialize-142"><span class="linenos">142</span></a>            <span class="n">model_obj</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
</span><span id="TorchBackend.initialize-143"><a href="#TorchBackend.initialize-143"><span class="linenos">143</span></a>
</span><span id="TorchBackend.initialize-144"><a href="#TorchBackend.initialize-144"><span class="linenos">144</span></a>            <span class="n">model_module</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">model_obj</span><span class="p">)</span>
</span><span id="TorchBackend.initialize-145"><a href="#TorchBackend.initialize-145"><span class="linenos">145</span></a>            <span class="n">model_module</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
</span><span id="TorchBackend.initialize-146"><a href="#TorchBackend.initialize-146"><span class="linenos">146</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">model_module</span>
</span><span id="TorchBackend.initialize-147"><a href="#TorchBackend.initialize-147"><span class="linenos">147</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">preprocess</span><span class="p">)</span>
</span><span id="TorchBackend.initialize-148"><a href="#TorchBackend.initialize-148"><span class="linenos">148</span></a>
</span><span id="TorchBackend.initialize-149"><a href="#TorchBackend.initialize-149"><span class="linenos">149</span></a>            <span class="c1"># 4. Load tokenizer</span>
</span><span id="TorchBackend.initialize-150"><a href="#TorchBackend.initialize-150"><span class="linenos">150</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load_tokenizer</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
</span><span id="TorchBackend.initialize-151"><a href="#TorchBackend.initialize-151"><span class="linenos">151</span></a>
</span><span id="TorchBackend.initialize-152"><a href="#TorchBackend.initialize-152"><span class="linenos">152</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_load_time_seconds</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span>
</span><span id="TorchBackend.initialize-153"><a href="#TorchBackend.initialize-153"><span class="linenos">153</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="TorchBackend.initialize-154"><a href="#TorchBackend.initialize-154"><span class="linenos">154</span></a>
</span><span id="TorchBackend.initialize-155"><a href="#TorchBackend.initialize-155"><span class="linenos">155</span></a>            <span class="c1"># Update precision info</span>
</span><span id="TorchBackend.initialize-156"><a href="#TorchBackend.initialize-156"><span class="linenos">156</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_amp</span><span class="p">:</span>
</span><span id="TorchBackend.initialize-157"><a href="#TorchBackend.initialize-157"><span class="linenos">157</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_current_precision</span> <span class="o">=</span> <span class="s2">&quot;fp32+amp(fp16)&quot;</span>
</span><span id="TorchBackend.initialize-158"><a href="#TorchBackend.initialize-158"><span class="linenos">158</span></a>                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mixed precision (AMP) enabled on </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="TorchBackend.initialize-159"><a href="#TorchBackend.initialize-159"><span class="linenos">159</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="TorchBackend.initialize-160"><a href="#TorchBackend.initialize-160"><span class="linenos">160</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_current_precision</span> <span class="o">=</span> <span class="s2">&quot;fp32&quot;</span>
</span><span id="TorchBackend.initialize-161"><a href="#TorchBackend.initialize-161"><span class="linenos">161</span></a>
</span><span id="TorchBackend.initialize-162"><a href="#TorchBackend.initialize-162"><span class="linenos">162</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
</span><span id="TorchBackend.initialize-163"><a href="#TorchBackend.initialize-163"><span class="linenos">163</span></a>                <span class="sa">f</span><span class="s2">&quot;✅ TorchBackend initialized in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_load_time_seconds</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s&quot;</span>
</span><span id="TorchBackend.initialize-164"><a href="#TorchBackend.initialize-164"><span class="linenos">164</span></a>            <span class="p">)</span>
</span><span id="TorchBackend.initialize-165"><a href="#TorchBackend.initialize-165"><span class="linenos">165</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   Precision: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_current_precision</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="TorchBackend.initialize-166"><a href="#TorchBackend.initialize-166"><span class="linenos">166</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   Device: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="TorchBackend.initialize-167"><a href="#TorchBackend.initialize-167"><span class="linenos">167</span></a>
</span><span id="TorchBackend.initialize-168"><a href="#TorchBackend.initialize-168"><span class="linenos">168</span></a>        <span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="TorchBackend.initialize-169"><a href="#TorchBackend.initialize-169"><span class="linenos">169</span></a>            <span class="k">raise</span> <span class="n">TorchModelLoadingError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Required dependencies not found: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span><span id="TorchBackend.initialize-170"><a href="#TorchBackend.initialize-170"><span class="linenos">170</span></a>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="TorchBackend.initialize-171"><a href="#TorchBackend.initialize-171"><span class="linenos">171</span></a>            <span class="k">raise</span> <span class="n">TorchModelLoadingError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model loading failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span></pre></div>


            <div class="docstring"><p>Load weights and prepare runtime resources. Must be idempotent.</p>
</div>


                            </div>
                            <div id="TorchBackend.close" class="classattr">
                                        <input id="TorchBackend.close-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-override">@override</div>

        <span class="def">def</span>
        <span class="name">close</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

                <label class="view-source-button" for="TorchBackend.close-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TorchBackend.close"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TorchBackend.close-211"><a href="#TorchBackend.close-211"><span class="linenos">211</span></a>    <span class="nd">@override</span>
</span><span id="TorchBackend.close-212"><a href="#TorchBackend.close-212"><span class="linenos">212</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="TorchBackend.close-213"><a href="#TorchBackend.close-213"><span class="linenos">213</span></a>        <span class="c1"># Best-effort release; PyTorch will free on GC.</span>
</span><span id="TorchBackend.close-214"><a href="#TorchBackend.close-214"><span class="linenos">214</span></a>        <span class="n">m</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span>
</span><span id="TorchBackend.close-215"><a href="#TorchBackend.close-215"><span class="linenos">215</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="TorchBackend.close-216"><a href="#TorchBackend.close-216"><span class="linenos">216</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="TorchBackend.close-217"><a href="#TorchBackend.close-217"><span class="linenos">217</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="TorchBackend.close-218"><a href="#TorchBackend.close-218"><span class="linenos">218</span></a>        <span class="k">if</span> <span class="n">m</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
</span><span id="TorchBackend.close-219"><a href="#TorchBackend.close-219"><span class="linenos">219</span></a>            <span class="c1"># Free cached memory for the device</span>
</span><span id="TorchBackend.close-220"><a href="#TorchBackend.close-220"><span class="linenos">220</span></a>            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Release runtime resources. Optional override.</p>
</div>


                            </div>
                            <div id="TorchBackend.text_to_vector" class="classattr">
                                        <input id="TorchBackend.text_to_vector-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-torch.inference_mode">@torch.inference_mode()</div>
        <div class="decorator decorator-override">@override</div>

        <span class="def">def</span>
        <span class="name">text_to_vector</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">text</span><span class="p">:</span> <span class="nb">str</span></span><span class="return-annotation">) -> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dtype</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">]]</span>:</span></span>

                <label class="view-source-button" for="TorchBackend.text_to_vector-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TorchBackend.text_to_vector"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TorchBackend.text_to_vector-224"><a href="#TorchBackend.text_to_vector-224"><span class="linenos">224</span></a>    <span class="nd">@torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">()</span>
</span><span id="TorchBackend.text_to_vector-225"><a href="#TorchBackend.text_to_vector-225"><span class="linenos">225</span></a>    <span class="nd">@override</span>
</span><span id="TorchBackend.text_to_vector-226"><a href="#TorchBackend.text_to_vector-226"><span class="linenos">226</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">text_to_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="TorchBackend.text_to_vector-227"><a href="#TorchBackend.text_to_vector-227"><span class="linenos">227</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="TorchBackend.text_to_vector-228"><a href="#TorchBackend.text_to_vector-228"><span class="linenos">228</span></a><span class="sd">        Encode a text string into a unit-normalized float32 embedding vector.</span>
</span><span id="TorchBackend.text_to_vector-229"><a href="#TorchBackend.text_to_vector-229"><span class="linenos">229</span></a><span class="sd">        Uses mixed precision (AMP) on GPU for better performance.</span>
</span><span id="TorchBackend.text_to_vector-230"><a href="#TorchBackend.text_to_vector-230"><span class="linenos">230</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="TorchBackend.text_to_vector-231"><a href="#TorchBackend.text_to_vector-231"><span class="linenos">231</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_initialized</span><span class="p">()</span>
</span><span id="TorchBackend.text_to_vector-232"><a href="#TorchBackend.text_to_vector-232"><span class="linenos">232</span></a>
</span><span id="TorchBackend.text_to_vector-233"><a href="#TorchBackend.text_to_vector-233"><span class="linenos">233</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">text</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
</span><span id="TorchBackend.text_to_vector-234"><a href="#TorchBackend.text_to_vector-234"><span class="linenos">234</span></a>            <span class="k">raise</span> <span class="n">InvalidInputError</span><span class="p">(</span><span class="s2">&quot;text cannot be empty or whitespace only&quot;</span><span class="p">)</span>
</span><span id="TorchBackend.text_to_vector-235"><a href="#TorchBackend.text_to_vector-235"><span class="linenos">235</span></a>
</span><span id="TorchBackend.text_to_vector-236"><a href="#TorchBackend.text_to_vector-236"><span class="linenos">236</span></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">10000</span><span class="p">:</span>  <span class="c1"># Reasonable length limit</span>
</span><span id="TorchBackend.text_to_vector-237"><a href="#TorchBackend.text_to_vector-237"><span class="linenos">237</span></a>            <span class="k">raise</span> <span class="n">InvalidInputError</span><span class="p">(</span><span class="s2">&quot;text too long (max 10000 characters)&quot;</span><span class="p">)</span>
</span><span id="TorchBackend.text_to_vector-238"><a href="#TorchBackend.text_to_vector-238"><span class="linenos">238</span></a>
</span><span id="TorchBackend.text_to_vector-239"><a href="#TorchBackend.text_to_vector-239"><span class="linenos">239</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="TorchBackend.text_to_vector-240"><a href="#TorchBackend.text_to_vector-240"><span class="linenos">240</span></a>            <span class="c1"># Create a simple CLIP-compatible prompt</span>
</span><span id="TorchBackend.text_to_vector-241"><a href="#TorchBackend.text_to_vector-241"><span class="linenos">241</span></a>            <span class="n">prompt</span> <span class="o">=</span> <span class="n">text</span>
</span><span id="TorchBackend.text_to_vector-242"><a href="#TorchBackend.text_to_vector-242"><span class="linenos">242</span></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="TorchBackend.text_to_vector-243"><a href="#TorchBackend.text_to_vector-243"><span class="linenos">243</span></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="TorchBackend.text_to_vector-244"><a href="#TorchBackend.text_to_vector-244"><span class="linenos">244</span></a>
</span><span id="TorchBackend.text_to_vector-245"><a href="#TorchBackend.text_to_vector-245"><span class="linenos">245</span></a>            <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">Callable</span><span class="p">[[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span><span class="p">)</span>
</span><span id="TorchBackend.text_to_vector-246"><a href="#TorchBackend.text_to_vector-246"><span class="linenos">246</span></a>            <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">([</span><span class="n">prompt</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
</span><span id="TorchBackend.text_to_vector-247"><a href="#TorchBackend.text_to_vector-247"><span class="linenos">247</span></a>
</span><span id="TorchBackend.text_to_vector-248"><a href="#TorchBackend.text_to_vector-248"><span class="linenos">248</span></a>            <span class="c1"># Use AMP if enabled (GPU only)</span>
</span><span id="TorchBackend.text_to_vector-249"><a href="#TorchBackend.text_to_vector-249"><span class="linenos">249</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_amp</span><span class="p">:</span>
</span><span id="TorchBackend.text_to_vector-250"><a href="#TorchBackend.text_to_vector-250"><span class="linenos">250</span></a>                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span>
</span><span id="TorchBackend.text_to_vector-251"><a href="#TorchBackend.text_to_vector-251"><span class="linenos">251</span></a>                    <span class="n">device_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_amp_dtype</span>
</span><span id="TorchBackend.text_to_vector-252"><a href="#TorchBackend.text_to_vector-252"><span class="linenos">252</span></a>                <span class="p">):</span>
</span><span id="TorchBackend.text_to_vector-253"><a href="#TorchBackend.text_to_vector-253"><span class="linenos">253</span></a>                    <span class="n">feats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">encode_text</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>
</span><span id="TorchBackend.text_to_vector-254"><a href="#TorchBackend.text_to_vector-254"><span class="linenos">254</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="TorchBackend.text_to_vector-255"><a href="#TorchBackend.text_to_vector-255"><span class="linenos">255</span></a>                <span class="n">feats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">encode_text</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>
</span><span id="TorchBackend.text_to_vector-256"><a href="#TorchBackend.text_to_vector-256"><span class="linenos">256</span></a>
</span><span id="TorchBackend.text_to_vector-257"><a href="#TorchBackend.text_to_vector-257"><span class="linenos">257</span></a>            <span class="n">feats</span> <span class="o">=</span> <span class="n">feats</span> <span class="o">/</span> <span class="n">feats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="TorchBackend.text_to_vector-258"><a href="#TorchBackend.text_to_vector-258"><span class="linenos">258</span></a>
</span><span id="TorchBackend.text_to_vector-259"><a href="#TorchBackend.text_to_vector-259"><span class="linenos">259</span></a>            <span class="n">vec</span> <span class="o">=</span> <span class="n">feats</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="TorchBackend.text_to_vector-260"><a href="#TorchBackend.text_to_vector-260"><span class="linenos">260</span></a>            <span class="k">return</span> <span class="n">vec</span>
</span><span id="TorchBackend.text_to_vector-261"><a href="#TorchBackend.text_to_vector-261"><span class="linenos">261</span></a>
</span><span id="TorchBackend.text_to_vector-262"><a href="#TorchBackend.text_to_vector-262"><span class="linenos">262</span></a>        <span class="k">except</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">OutOfMemoryError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="TorchBackend.text_to_vector-263"><a href="#TorchBackend.text_to_vector-263"><span class="linenos">263</span></a>            <span class="k">raise</span> <span class="n">CUDAMemoryError</span><span class="p">(</span>
</span><span id="TorchBackend.text_to_vector-264"><a href="#TorchBackend.text_to_vector-264"><span class="linenos">264</span></a>                <span class="sa">f</span><span class="s2">&quot;CUDA out of memory during text encoding: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="TorchBackend.text_to_vector-265"><a href="#TorchBackend.text_to_vector-265"><span class="linenos">265</span></a>            <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span><span id="TorchBackend.text_to_vector-266"><a href="#TorchBackend.text_to_vector-266"><span class="linenos">266</span></a>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="TorchBackend.text_to_vector-267"><a href="#TorchBackend.text_to_vector-267"><span class="linenos">267</span></a>            <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Text encoding failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span></pre></div>


            <div class="docstring"><p>Encode a text string into a unit-normalized float32 embedding vector.
Uses mixed precision (AMP) on GPU for better performance.</p>
</div>


                            </div>
                            <div id="TorchBackend.image_to_vector" class="classattr">
                                        <input id="TorchBackend.image_to_vector-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-torch.inference_mode">@torch.inference_mode()</div>
        <div class="decorator decorator-override">@override</div>

        <span class="def">def</span>
        <span class="name">image_to_vector</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">image_bytes</span><span class="p">:</span> <span class="nb">bytes</span></span><span class="return-annotation">) -> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dtype</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">]]</span>:</span></span>

                <label class="view-source-button" for="TorchBackend.image_to_vector-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TorchBackend.image_to_vector"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TorchBackend.image_to_vector-269"><a href="#TorchBackend.image_to_vector-269"><span class="linenos">269</span></a>    <span class="nd">@torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">()</span>
</span><span id="TorchBackend.image_to_vector-270"><a href="#TorchBackend.image_to_vector-270"><span class="linenos">270</span></a>    <span class="nd">@override</span>
</span><span id="TorchBackend.image_to_vector-271"><a href="#TorchBackend.image_to_vector-271"><span class="linenos">271</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">image_to_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_bytes</span><span class="p">:</span> <span class="nb">bytes</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="TorchBackend.image_to_vector-272"><a href="#TorchBackend.image_to_vector-272"><span class="linenos">272</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="TorchBackend.image_to_vector-273"><a href="#TorchBackend.image_to_vector-273"><span class="linenos">273</span></a><span class="sd">        Encode image bytes (RGB) into a unit-normalized float32 embedding vector.</span>
</span><span id="TorchBackend.image_to_vector-274"><a href="#TorchBackend.image_to_vector-274"><span class="linenos">274</span></a><span class="sd">        Uses mixed precision (AMP) on GPU for better performance.</span>
</span><span id="TorchBackend.image_to_vector-275"><a href="#TorchBackend.image_to_vector-275"><span class="linenos">275</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="TorchBackend.image_to_vector-276"><a href="#TorchBackend.image_to_vector-276"><span class="linenos">276</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_initialized</span><span class="p">()</span>
</span><span id="TorchBackend.image_to_vector-277"><a href="#TorchBackend.image_to_vector-277"><span class="linenos">277</span></a>
</span><span id="TorchBackend.image_to_vector-278"><a href="#TorchBackend.image_to_vector-278"><span class="linenos">278</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">image_bytes</span><span class="p">:</span>
</span><span id="TorchBackend.image_to_vector-279"><a href="#TorchBackend.image_to_vector-279"><span class="linenos">279</span></a>            <span class="k">raise</span> <span class="n">InvalidInputError</span><span class="p">(</span><span class="s2">&quot;image_bytes cannot be empty&quot;</span><span class="p">)</span>
</span><span id="TorchBackend.image_to_vector-280"><a href="#TorchBackend.image_to_vector-280"><span class="linenos">280</span></a>
</span><span id="TorchBackend.image_to_vector-281"><a href="#TorchBackend.image_to_vector-281"><span class="linenos">281</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="TorchBackend.image_to_vector-282"><a href="#TorchBackend.image_to_vector-282"><span class="linenos">282</span></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="TorchBackend.image_to_vector-283"><a href="#TorchBackend.image_to_vector-283"><span class="linenos">283</span></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="TorchBackend.image_to_vector-284"><a href="#TorchBackend.image_to_vector-284"><span class="linenos">284</span></a>
</span><span id="TorchBackend.image_to_vector-285"><a href="#TorchBackend.image_to_vector-285"><span class="linenos">285</span></a>            <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">image_bytes</span><span class="p">))</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">)</span>
</span><span id="TorchBackend.image_to_vector-286"><a href="#TorchBackend.image_to_vector-286"><span class="linenos">286</span></a>            <span class="n">preprocess</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess</span><span class="p">)</span>
</span><span id="TorchBackend.image_to_vector-287"><a href="#TorchBackend.image_to_vector-287"><span class="linenos">287</span></a>            <span class="n">tensor</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
</span><span id="TorchBackend.image_to_vector-288"><a href="#TorchBackend.image_to_vector-288"><span class="linenos">288</span></a>
</span><span id="TorchBackend.image_to_vector-289"><a href="#TorchBackend.image_to_vector-289"><span class="linenos">289</span></a>            <span class="c1"># Use AMP if enabled (GPU only)</span>
</span><span id="TorchBackend.image_to_vector-290"><a href="#TorchBackend.image_to_vector-290"><span class="linenos">290</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_amp</span><span class="p">:</span>
</span><span id="TorchBackend.image_to_vector-291"><a href="#TorchBackend.image_to_vector-291"><span class="linenos">291</span></a>                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span>
</span><span id="TorchBackend.image_to_vector-292"><a href="#TorchBackend.image_to_vector-292"><span class="linenos">292</span></a>                    <span class="n">device_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_amp_dtype</span>
</span><span id="TorchBackend.image_to_vector-293"><a href="#TorchBackend.image_to_vector-293"><span class="linenos">293</span></a>                <span class="p">):</span>
</span><span id="TorchBackend.image_to_vector-294"><a href="#TorchBackend.image_to_vector-294"><span class="linenos">294</span></a>                    <span class="n">feats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">encode_image</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>
</span><span id="TorchBackend.image_to_vector-295"><a href="#TorchBackend.image_to_vector-295"><span class="linenos">295</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="TorchBackend.image_to_vector-296"><a href="#TorchBackend.image_to_vector-296"><span class="linenos">296</span></a>                <span class="n">feats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">encode_image</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>
</span><span id="TorchBackend.image_to_vector-297"><a href="#TorchBackend.image_to_vector-297"><span class="linenos">297</span></a>
</span><span id="TorchBackend.image_to_vector-298"><a href="#TorchBackend.image_to_vector-298"><span class="linenos">298</span></a>            <span class="n">feats</span> <span class="o">=</span> <span class="n">feats</span> <span class="o">/</span> <span class="n">feats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="TorchBackend.image_to_vector-299"><a href="#TorchBackend.image_to_vector-299"><span class="linenos">299</span></a>
</span><span id="TorchBackend.image_to_vector-300"><a href="#TorchBackend.image_to_vector-300"><span class="linenos">300</span></a>            <span class="n">vec</span> <span class="o">=</span> <span class="n">feats</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="TorchBackend.image_to_vector-301"><a href="#TorchBackend.image_to_vector-301"><span class="linenos">301</span></a>            <span class="k">return</span> <span class="n">vec</span>
</span><span id="TorchBackend.image_to_vector-302"><a href="#TorchBackend.image_to_vector-302"><span class="linenos">302</span></a>
</span><span id="TorchBackend.image_to_vector-303"><a href="#TorchBackend.image_to_vector-303"><span class="linenos">303</span></a>        <span class="k">except</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">OutOfMemoryError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="TorchBackend.image_to_vector-304"><a href="#TorchBackend.image_to_vector-304"><span class="linenos">304</span></a>            <span class="k">raise</span> <span class="n">CUDAMemoryError</span><span class="p">(</span>
</span><span id="TorchBackend.image_to_vector-305"><a href="#TorchBackend.image_to_vector-305"><span class="linenos">305</span></a>                <span class="sa">f</span><span class="s2">&quot;CUDA out of memory during image encoding: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="TorchBackend.image_to_vector-306"><a href="#TorchBackend.image_to_vector-306"><span class="linenos">306</span></a>            <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span><span id="TorchBackend.image_to_vector-307"><a href="#TorchBackend.image_to_vector-307"><span class="linenos">307</span></a>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="TorchBackend.image_to_vector-308"><a href="#TorchBackend.image_to_vector-308"><span class="linenos">308</span></a>            <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Image encoding failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span></pre></div>


            <div class="docstring"><p>Encode image bytes (RGB) into a unit-normalized float32 embedding vector.
Uses mixed precision (AMP) on GPU for better performance.</p>
</div>


                            </div>
                            <div id="TorchBackend.image_batch_to_vectors" class="classattr">
                                        <input id="TorchBackend.image_batch_to_vectors-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-torch.inference_mode">@torch.inference_mode()</div>
        <div class="decorator decorator-override">@override</div>

        <span class="def">def</span>
        <span class="name">image_batch_to_vectors</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">images</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">bytes</span><span class="p">]</span></span><span class="return-annotation">) -> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dtype</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">]]</span>:</span></span>

                <label class="view-source-button" for="TorchBackend.image_batch_to_vectors-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TorchBackend.image_batch_to_vectors"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TorchBackend.image_batch_to_vectors-310"><a href="#TorchBackend.image_batch_to_vectors-310"><span class="linenos">310</span></a>    <span class="nd">@torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">()</span>
</span><span id="TorchBackend.image_batch_to_vectors-311"><a href="#TorchBackend.image_batch_to_vectors-311"><span class="linenos">311</span></a>    <span class="nd">@override</span>
</span><span id="TorchBackend.image_batch_to_vectors-312"><a href="#TorchBackend.image_batch_to_vectors-312"><span class="linenos">312</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">image_batch_to_vectors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">bytes</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="TorchBackend.image_batch_to_vectors-313"><a href="#TorchBackend.image_batch_to_vectors-313"><span class="linenos">313</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="TorchBackend.image_batch_to_vectors-314"><a href="#TorchBackend.image_batch_to_vectors-314"><span class="linenos">314</span></a><span class="sd">        Encode a list of image bytes using a single batched forward pass.</span>
</span><span id="TorchBackend.image_batch_to_vectors-315"><a href="#TorchBackend.image_batch_to_vectors-315"><span class="linenos">315</span></a><span class="sd">        Uses mixed precision (AMP) on GPU for better performance.</span>
</span><span id="TorchBackend.image_batch_to_vectors-316"><a href="#TorchBackend.image_batch_to_vectors-316"><span class="linenos">316</span></a><span class="sd">        Falls back to BaseClipBackend&#39;s sequential implementation if images is empty.</span>
</span><span id="TorchBackend.image_batch_to_vectors-317"><a href="#TorchBackend.image_batch_to_vectors-317"><span class="linenos">317</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="TorchBackend.image_batch_to_vectors-318"><a href="#TorchBackend.image_batch_to_vectors-318"><span class="linenos">318</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">images</span><span class="p">:</span>
</span><span id="TorchBackend.image_batch_to_vectors-319"><a href="#TorchBackend.image_batch_to_vectors-319"><span class="linenos">319</span></a>            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">image_batch_to_vectors</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
</span><span id="TorchBackend.image_batch_to_vectors-320"><a href="#TorchBackend.image_batch_to_vectors-320"><span class="linenos">320</span></a>
</span><span id="TorchBackend.image_batch_to_vectors-321"><a href="#TorchBackend.image_batch_to_vectors-321"><span class="linenos">321</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_initialized</span><span class="p">()</span>
</span><span id="TorchBackend.image_batch_to_vectors-322"><a href="#TorchBackend.image_batch_to_vectors-322"><span class="linenos">322</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="TorchBackend.image_batch_to_vectors-323"><a href="#TorchBackend.image_batch_to_vectors-323"><span class="linenos">323</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="TorchBackend.image_batch_to_vectors-324"><a href="#TorchBackend.image_batch_to_vectors-324"><span class="linenos">324</span></a>        <span class="n">preprocess</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">_preprocess</span><span class="p">)</span>
</span><span id="TorchBackend.image_batch_to_vectors-325"><a href="#TorchBackend.image_batch_to_vectors-325"><span class="linenos">325</span></a>
</span><span id="TorchBackend.image_batch_to_vectors-326"><a href="#TorchBackend.image_batch_to_vectors-326"><span class="linenos">326</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="TorchBackend.image_batch_to_vectors-327"><a href="#TorchBackend.image_batch_to_vectors-327"><span class="linenos">327</span></a>            <span class="c1"># Decode and preprocess to a batch tensor [N, C, H, W]</span>
</span><span id="TorchBackend.image_batch_to_vectors-328"><a href="#TorchBackend.image_batch_to_vectors-328"><span class="linenos">328</span></a>            <span class="n">tensors</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="TorchBackend.image_batch_to_vectors-329"><a href="#TorchBackend.image_batch_to_vectors-329"><span class="linenos">329</span></a>            <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">images</span><span class="p">:</span>
</span><span id="TorchBackend.image_batch_to_vectors-330"><a href="#TorchBackend.image_batch_to_vectors-330"><span class="linenos">330</span></a>                <span class="k">if</span> <span class="ow">not</span> <span class="n">b</span><span class="p">:</span>
</span><span id="TorchBackend.image_batch_to_vectors-331"><a href="#TorchBackend.image_batch_to_vectors-331"><span class="linenos">331</span></a>                    <span class="k">raise</span> <span class="n">InvalidInputError</span><span class="p">(</span><span class="s2">&quot;image bytes cannot be empty&quot;</span><span class="p">)</span>
</span><span id="TorchBackend.image_batch_to_vectors-332"><a href="#TorchBackend.image_batch_to_vectors-332"><span class="linenos">332</span></a>
</span><span id="TorchBackend.image_batch_to_vectors-333"><a href="#TorchBackend.image_batch_to_vectors-333"><span class="linenos">333</span></a>                <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">b</span><span class="p">))</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">)</span>
</span><span id="TorchBackend.image_batch_to_vectors-334"><a href="#TorchBackend.image_batch_to_vectors-334"><span class="linenos">334</span></a>                <span class="n">t</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</span><span id="TorchBackend.image_batch_to_vectors-335"><a href="#TorchBackend.image_batch_to_vectors-335"><span class="linenos">335</span></a>                <span class="n">tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
</span><span id="TorchBackend.image_batch_to_vectors-336"><a href="#TorchBackend.image_batch_to_vectors-336"><span class="linenos">336</span></a>
</span><span id="TorchBackend.image_batch_to_vectors-337"><a href="#TorchBackend.image_batch_to_vectors-337"><span class="linenos">337</span></a>            <span class="n">batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
</span><span id="TorchBackend.image_batch_to_vectors-338"><a href="#TorchBackend.image_batch_to_vectors-338"><span class="linenos">338</span></a>
</span><span id="TorchBackend.image_batch_to_vectors-339"><a href="#TorchBackend.image_batch_to_vectors-339"><span class="linenos">339</span></a>            <span class="c1"># Use AMP if enabled (GPU only)</span>
</span><span id="TorchBackend.image_batch_to_vectors-340"><a href="#TorchBackend.image_batch_to_vectors-340"><span class="linenos">340</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_amp</span><span class="p">:</span>
</span><span id="TorchBackend.image_batch_to_vectors-341"><a href="#TorchBackend.image_batch_to_vectors-341"><span class="linenos">341</span></a>                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span>
</span><span id="TorchBackend.image_batch_to_vectors-342"><a href="#TorchBackend.image_batch_to_vectors-342"><span class="linenos">342</span></a>                    <span class="n">device_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_amp_dtype</span>
</span><span id="TorchBackend.image_batch_to_vectors-343"><a href="#TorchBackend.image_batch_to_vectors-343"><span class="linenos">343</span></a>                <span class="p">):</span>
</span><span id="TorchBackend.image_batch_to_vectors-344"><a href="#TorchBackend.image_batch_to_vectors-344"><span class="linenos">344</span></a>                    <span class="n">feats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">encode_image</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>
</span><span id="TorchBackend.image_batch_to_vectors-345"><a href="#TorchBackend.image_batch_to_vectors-345"><span class="linenos">345</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="TorchBackend.image_batch_to_vectors-346"><a href="#TorchBackend.image_batch_to_vectors-346"><span class="linenos">346</span></a>                <span class="n">feats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">encode_image</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>
</span><span id="TorchBackend.image_batch_to_vectors-347"><a href="#TorchBackend.image_batch_to_vectors-347"><span class="linenos">347</span></a>
</span><span id="TorchBackend.image_batch_to_vectors-348"><a href="#TorchBackend.image_batch_to_vectors-348"><span class="linenos">348</span></a>            <span class="n">feats</span> <span class="o">=</span> <span class="n">feats</span> <span class="o">/</span> <span class="n">feats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="TorchBackend.image_batch_to_vectors-349"><a href="#TorchBackend.image_batch_to_vectors-349"><span class="linenos">349</span></a>
</span><span id="TorchBackend.image_batch_to_vectors-350"><a href="#TorchBackend.image_batch_to_vectors-350"><span class="linenos">350</span></a>            <span class="n">arr</span> <span class="o">=</span> <span class="n">feats</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="TorchBackend.image_batch_to_vectors-351"><a href="#TorchBackend.image_batch_to_vectors-351"><span class="linenos">351</span></a>            <span class="k">return</span> <span class="n">arr</span>
</span><span id="TorchBackend.image_batch_to_vectors-352"><a href="#TorchBackend.image_batch_to_vectors-352"><span class="linenos">352</span></a>
</span><span id="TorchBackend.image_batch_to_vectors-353"><a href="#TorchBackend.image_batch_to_vectors-353"><span class="linenos">353</span></a>        <span class="k">except</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">OutOfMemoryError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="TorchBackend.image_batch_to_vectors-354"><a href="#TorchBackend.image_batch_to_vectors-354"><span class="linenos">354</span></a>            <span class="k">raise</span> <span class="n">CUDAMemoryError</span><span class="p">(</span>
</span><span id="TorchBackend.image_batch_to_vectors-355"><a href="#TorchBackend.image_batch_to_vectors-355"><span class="linenos">355</span></a>                <span class="sa">f</span><span class="s2">&quot;CUDA out of memory during batch image encoding: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="TorchBackend.image_batch_to_vectors-356"><a href="#TorchBackend.image_batch_to_vectors-356"><span class="linenos">356</span></a>            <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span><span id="TorchBackend.image_batch_to_vectors-357"><a href="#TorchBackend.image_batch_to_vectors-357"><span class="linenos">357</span></a>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="TorchBackend.image_batch_to_vectors-358"><a href="#TorchBackend.image_batch_to_vectors-358"><span class="linenos">358</span></a>            <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Batch image encoding failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span></pre></div>


            <div class="docstring"><p>Encode a list of image bytes using a single batched forward pass.
Uses mixed precision (AMP) on GPU for better performance.
Falls back to BaseClipBackend's sequential implementation if images is empty.</p>
</div>


                            </div>
                            <div id="TorchBackend.text_batch_to_vectors" class="classattr">
                                        <input id="TorchBackend.text_batch_to_vectors-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-torch.inference_mode">@torch.inference_mode()</div>
        <div class="decorator decorator-override">@override</div>

        <span class="def">def</span>
        <span class="name">text_batch_to_vectors</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">texts</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span></span><span class="return-annotation">) -> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dtype</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">]]</span>:</span></span>

                <label class="view-source-button" for="TorchBackend.text_batch_to_vectors-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TorchBackend.text_batch_to_vectors"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TorchBackend.text_batch_to_vectors-360"><a href="#TorchBackend.text_batch_to_vectors-360"><span class="linenos">360</span></a>    <span class="nd">@torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">()</span>
</span><span id="TorchBackend.text_batch_to_vectors-361"><a href="#TorchBackend.text_batch_to_vectors-361"><span class="linenos">361</span></a>    <span class="nd">@override</span>
</span><span id="TorchBackend.text_batch_to_vectors-362"><a href="#TorchBackend.text_batch_to_vectors-362"><span class="linenos">362</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">text_batch_to_vectors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">texts</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="TorchBackend.text_batch_to_vectors-363"><a href="#TorchBackend.text_batch_to_vectors-363"><span class="linenos">363</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="TorchBackend.text_batch_to_vectors-364"><a href="#TorchBackend.text_batch_to_vectors-364"><span class="linenos">364</span></a><span class="sd">        Encode a batch of text strings into unit-normalized float32 embedding vectors.</span>
</span><span id="TorchBackend.text_batch_to_vectors-365"><a href="#TorchBackend.text_batch_to_vectors-365"><span class="linenos">365</span></a><span class="sd">        Uses mixed precision (AMP) on GPU for better performance.</span>
</span><span id="TorchBackend.text_batch_to_vectors-366"><a href="#TorchBackend.text_batch_to_vectors-366"><span class="linenos">366</span></a>
</span><span id="TorchBackend.text_batch_to_vectors-367"><a href="#TorchBackend.text_batch_to_vectors-367"><span class="linenos">367</span></a><span class="sd">        Args:</span>
</span><span id="TorchBackend.text_batch_to_vectors-368"><a href="#TorchBackend.text_batch_to_vectors-368"><span class="linenos">368</span></a><span class="sd">            texts: Sequence of text strings to encode.</span>
</span><span id="TorchBackend.text_batch_to_vectors-369"><a href="#TorchBackend.text_batch_to_vectors-369"><span class="linenos">369</span></a>
</span><span id="TorchBackend.text_batch_to_vectors-370"><a href="#TorchBackend.text_batch_to_vectors-370"><span class="linenos">370</span></a><span class="sd">        Returns:</span>
</span><span id="TorchBackend.text_batch_to_vectors-371"><a href="#TorchBackend.text_batch_to_vectors-371"><span class="linenos">371</span></a><span class="sd">            np.ndarray with shape (N, D) and dtype float32, each row L2-normalized.</span>
</span><span id="TorchBackend.text_batch_to_vectors-372"><a href="#TorchBackend.text_batch_to_vectors-372"><span class="linenos">372</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="TorchBackend.text_batch_to_vectors-373"><a href="#TorchBackend.text_batch_to_vectors-373"><span class="linenos">373</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_initialized</span><span class="p">()</span>
</span><span id="TorchBackend.text_batch_to_vectors-374"><a href="#TorchBackend.text_batch_to_vectors-374"><span class="linenos">374</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="TorchBackend.text_batch_to_vectors-375"><a href="#TorchBackend.text_batch_to_vectors-375"><span class="linenos">375</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="TorchBackend.text_batch_to_vectors-376"><a href="#TorchBackend.text_batch_to_vectors-376"><span class="linenos">376</span></a>
</span><span id="TorchBackend.text_batch_to_vectors-377"><a href="#TorchBackend.text_batch_to_vectors-377"><span class="linenos">377</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">texts</span><span class="p">:</span>
</span><span id="TorchBackend.text_batch_to_vectors-378"><a href="#TorchBackend.text_batch_to_vectors-378"><span class="linenos">378</span></a>            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="TorchBackend.text_batch_to_vectors-379"><a href="#TorchBackend.text_batch_to_vectors-379"><span class="linenos">379</span></a>
</span><span id="TorchBackend.text_batch_to_vectors-380"><a href="#TorchBackend.text_batch_to_vectors-380"><span class="linenos">380</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="TorchBackend.text_batch_to_vectors-381"><a href="#TorchBackend.text_batch_to_vectors-381"><span class="linenos">381</span></a>            <span class="c1"># Validate inputs</span>
</span><span id="TorchBackend.text_batch_to_vectors-382"><a href="#TorchBackend.text_batch_to_vectors-382"><span class="linenos">382</span></a>            <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">:</span>
</span><span id="TorchBackend.text_batch_to_vectors-383"><a href="#TorchBackend.text_batch_to_vectors-383"><span class="linenos">383</span></a>                <span class="k">if</span> <span class="ow">not</span> <span class="n">text</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
</span><span id="TorchBackend.text_batch_to_vectors-384"><a href="#TorchBackend.text_batch_to_vectors-384"><span class="linenos">384</span></a>                    <span class="k">raise</span> <span class="n">InvalidInputError</span><span class="p">(</span><span class="s2">&quot;text cannot be empty or whitespace only&quot;</span><span class="p">)</span>
</span><span id="TorchBackend.text_batch_to_vectors-385"><a href="#TorchBackend.text_batch_to_vectors-385"><span class="linenos">385</span></a>                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">10000</span><span class="p">:</span>  <span class="c1"># Reasonable length limit</span>
</span><span id="TorchBackend.text_batch_to_vectors-386"><a href="#TorchBackend.text_batch_to_vectors-386"><span class="linenos">386</span></a>                    <span class="k">raise</span> <span class="n">InvalidInputError</span><span class="p">(</span><span class="s2">&quot;text too long (max 10000 characters)&quot;</span><span class="p">)</span>
</span><span id="TorchBackend.text_batch_to_vectors-387"><a href="#TorchBackend.text_batch_to_vectors-387"><span class="linenos">387</span></a>
</span><span id="TorchBackend.text_batch_to_vectors-388"><a href="#TorchBackend.text_batch_to_vectors-388"><span class="linenos">388</span></a>            <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">Callable</span><span class="p">[[</span><span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span><span class="p">)</span>
</span><span id="TorchBackend.text_batch_to_vectors-389"><a href="#TorchBackend.text_batch_to_vectors-389"><span class="linenos">389</span></a>            <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">texts</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
</span><span id="TorchBackend.text_batch_to_vectors-390"><a href="#TorchBackend.text_batch_to_vectors-390"><span class="linenos">390</span></a>
</span><span id="TorchBackend.text_batch_to_vectors-391"><a href="#TorchBackend.text_batch_to_vectors-391"><span class="linenos">391</span></a>            <span class="c1"># Use AMP if enabled (GPU only)</span>
</span><span id="TorchBackend.text_batch_to_vectors-392"><a href="#TorchBackend.text_batch_to_vectors-392"><span class="linenos">392</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_amp</span><span class="p">:</span>
</span><span id="TorchBackend.text_batch_to_vectors-393"><a href="#TorchBackend.text_batch_to_vectors-393"><span class="linenos">393</span></a>                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span>
</span><span id="TorchBackend.text_batch_to_vectors-394"><a href="#TorchBackend.text_batch_to_vectors-394"><span class="linenos">394</span></a>                    <span class="n">device_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_amp_dtype</span>
</span><span id="TorchBackend.text_batch_to_vectors-395"><a href="#TorchBackend.text_batch_to_vectors-395"><span class="linenos">395</span></a>                <span class="p">):</span>
</span><span id="TorchBackend.text_batch_to_vectors-396"><a href="#TorchBackend.text_batch_to_vectors-396"><span class="linenos">396</span></a>                    <span class="n">feats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">encode_text</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>
</span><span id="TorchBackend.text_batch_to_vectors-397"><a href="#TorchBackend.text_batch_to_vectors-397"><span class="linenos">397</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="TorchBackend.text_batch_to_vectors-398"><a href="#TorchBackend.text_batch_to_vectors-398"><span class="linenos">398</span></a>                <span class="n">feats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">encode_text</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>
</span><span id="TorchBackend.text_batch_to_vectors-399"><a href="#TorchBackend.text_batch_to_vectors-399"><span class="linenos">399</span></a>
</span><span id="TorchBackend.text_batch_to_vectors-400"><a href="#TorchBackend.text_batch_to_vectors-400"><span class="linenos">400</span></a>            <span class="n">feats</span> <span class="o">=</span> <span class="n">feats</span> <span class="o">/</span> <span class="n">feats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="TorchBackend.text_batch_to_vectors-401"><a href="#TorchBackend.text_batch_to_vectors-401"><span class="linenos">401</span></a>
</span><span id="TorchBackend.text_batch_to_vectors-402"><a href="#TorchBackend.text_batch_to_vectors-402"><span class="linenos">402</span></a>            <span class="n">vecs</span> <span class="o">=</span> <span class="n">feats</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="TorchBackend.text_batch_to_vectors-403"><a href="#TorchBackend.text_batch_to_vectors-403"><span class="linenos">403</span></a>            <span class="k">return</span> <span class="n">vecs</span>
</span><span id="TorchBackend.text_batch_to_vectors-404"><a href="#TorchBackend.text_batch_to_vectors-404"><span class="linenos">404</span></a>
</span><span id="TorchBackend.text_batch_to_vectors-405"><a href="#TorchBackend.text_batch_to_vectors-405"><span class="linenos">405</span></a>        <span class="k">except</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">OutOfMemoryError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="TorchBackend.text_batch_to_vectors-406"><a href="#TorchBackend.text_batch_to_vectors-406"><span class="linenos">406</span></a>            <span class="k">raise</span> <span class="n">CUDAMemoryError</span><span class="p">(</span>
</span><span id="TorchBackend.text_batch_to_vectors-407"><a href="#TorchBackend.text_batch_to_vectors-407"><span class="linenos">407</span></a>                <span class="sa">f</span><span class="s2">&quot;CUDA out of memory during batch text encoding: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="TorchBackend.text_batch_to_vectors-408"><a href="#TorchBackend.text_batch_to_vectors-408"><span class="linenos">408</span></a>            <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span><span id="TorchBackend.text_batch_to_vectors-409"><a href="#TorchBackend.text_batch_to_vectors-409"><span class="linenos">409</span></a>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="TorchBackend.text_batch_to_vectors-410"><a href="#TorchBackend.text_batch_to_vectors-410"><span class="linenos">410</span></a>            <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Batch text encoding failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span></pre></div>


            <div class="docstring"><p>Encode a batch of text strings into unit-normalized float32 embedding vectors.
Uses mixed precision (AMP) on GPU for better performance.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>texts:</strong>  Sequence of text strings to encode.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>np.ndarray with shape (N, D) and dtype float32, each row L2-normalized.</p>
</blockquote>
</div>


                            </div>
                            <div id="TorchBackend.get_info" class="classattr">
                                        <input id="TorchBackend.get_info-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-override">@override</div>

        <span class="def">def</span>
        <span class="name">get_info</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">) -> <span class="n"><a href="#BackendInfo">BackendInfo</a></span>:</span></span>

                <label class="view-source-button" for="TorchBackend.get_info-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TorchBackend.get_info"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TorchBackend.get_info-412"><a href="#TorchBackend.get_info-412"><span class="linenos">412</span></a>    <span class="nd">@override</span>
</span><span id="TorchBackend.get_info-413"><a href="#TorchBackend.get_info-413"><span class="linenos">413</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_info</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BackendInfo</span><span class="p">:</span>
</span><span id="TorchBackend.get_info-414"><a href="#TorchBackend.get_info-414"><span class="linenos">414</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="TorchBackend.get_info-415"><a href="#TorchBackend.get_info-415"><span class="linenos">415</span></a><span class="sd">        Report runtime and model metadata.</span>
</span><span id="TorchBackend.get_info-416"><a href="#TorchBackend.get_info-416"><span class="linenos">416</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="TorchBackend.get_info-417"><a href="#TorchBackend.get_info-417"><span class="linenos">417</span></a>        <span class="c1"># Report precision: always loads fp32 weights, uses AMP on GPU</span>
</span><span id="TorchBackend.get_info-418"><a href="#TorchBackend.get_info-418"><span class="linenos">418</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_amp</span><span class="p">:</span>
</span><span id="TorchBackend.get_info-419"><a href="#TorchBackend.get_info-419"><span class="linenos">419</span></a>            <span class="n">precisions</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;fp32&quot;</span><span class="p">,</span> <span class="s2">&quot;fp16(amp)&quot;</span><span class="p">]</span>
</span><span id="TorchBackend.get_info-420"><a href="#TorchBackend.get_info-420"><span class="linenos">420</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="TorchBackend.get_info-421"><a href="#TorchBackend.get_info-421"><span class="linenos">421</span></a>            <span class="n">precisions</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;fp32&quot;</span><span class="p">]</span>
</span><span id="TorchBackend.get_info-422"><a href="#TorchBackend.get_info-422"><span class="linenos">422</span></a>
</span><span id="TorchBackend.get_info-423"><a href="#TorchBackend.get_info-423"><span class="linenos">423</span></a>        <span class="n">version</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">open_clip</span><span class="p">,</span> <span class="s2">&quot;__version__&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span><span id="TorchBackend.get_info-424"><a href="#TorchBackend.get_info-424"><span class="linenos">424</span></a>
</span><span id="TorchBackend.get_info-425"><a href="#TorchBackend.get_info-425"><span class="linenos">425</span></a>        <span class="c1"># Get embedding dimension from resources</span>
</span><span id="TorchBackend.get_info-426"><a href="#TorchBackend.get_info-426"><span class="linenos">426</span></a>        <span class="n">embed_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">get_embedding_dim</span><span class="p">()</span>
</span><span id="TorchBackend.get_info-427"><a href="#TorchBackend.get_info-427"><span class="linenos">427</span></a>
</span><span id="TorchBackend.get_info-428"><a href="#TorchBackend.get_info-428"><span class="linenos">428</span></a>        <span class="c1"># Get image size from resources</span>
</span><span id="TorchBackend.get_info-429"><a href="#TorchBackend.get_info-429"><span class="linenos">429</span></a>        <span class="n">image_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">get_image_size</span><span class="p">()</span>
</span><span id="TorchBackend.get_info-430"><a href="#TorchBackend.get_info-430"><span class="linenos">430</span></a>        <span class="n">image_size_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">image_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">x</span><span class="si">{</span><span class="n">image_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">if</span> <span class="n">image_size</span> <span class="k">else</span> <span class="kc">None</span>
</span><span id="TorchBackend.get_info-431"><a href="#TorchBackend.get_info-431"><span class="linenos">431</span></a>
</span><span id="TorchBackend.get_info-432"><a href="#TorchBackend.get_info-432"><span class="linenos">432</span></a>        <span class="k">return</span> <span class="n">BackendInfo</span><span class="p">(</span>
</span><span id="TorchBackend.get_info-433"><a href="#TorchBackend.get_info-433"><span class="linenos">433</span></a>            <span class="n">runtime</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span>
</span><span id="TorchBackend.get_info-434"><a href="#TorchBackend.get_info-434"><span class="linenos">434</span></a>            <span class="n">device</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">),</span>
</span><span id="TorchBackend.get_info-435"><a href="#TorchBackend.get_info-435"><span class="linenos">435</span></a>            <span class="n">model_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span>
</span><span id="TorchBackend.get_info-436"><a href="#TorchBackend.get_info-436"><span class="linenos">436</span></a>            <span class="n">model_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
</span><span id="TorchBackend.get_info-437"><a href="#TorchBackend.get_info-437"><span class="linenos">437</span></a>                <span class="s2">&quot;model_name&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">model_name</span>
</span><span id="TorchBackend.get_info-438"><a href="#TorchBackend.get_info-438"><span class="linenos">438</span></a>            <span class="p">),</span>
</span><span id="TorchBackend.get_info-439"><a href="#TorchBackend.get_info-439"><span class="linenos">439</span></a>            <span class="n">pretrained</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># Local weights, no pretrained tag</span>
</span><span id="TorchBackend.get_info-440"><a href="#TorchBackend.get_info-440"><span class="linenos">440</span></a>            <span class="n">version</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">version</span><span class="p">)</span> <span class="k">if</span> <span class="n">version</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="TorchBackend.get_info-441"><a href="#TorchBackend.get_info-441"><span class="linenos">441</span></a>            <span class="n">image_embedding_dim</span><span class="o">=</span><span class="n">embed_dim</span><span class="p">,</span>
</span><span id="TorchBackend.get_info-442"><a href="#TorchBackend.get_info-442"><span class="linenos">442</span></a>            <span class="n">text_embedding_dim</span><span class="o">=</span><span class="n">embed_dim</span><span class="p">,</span>
</span><span id="TorchBackend.get_info-443"><a href="#TorchBackend.get_info-443"><span class="linenos">443</span></a>            <span class="n">precisions</span><span class="o">=</span><span class="n">precisions</span><span class="p">,</span>
</span><span id="TorchBackend.get_info-444"><a href="#TorchBackend.get_info-444"><span class="linenos">444</span></a>            <span class="n">max_batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_max_batch_size</span><span class="p">,</span>
</span><span id="TorchBackend.get_info-445"><a href="#TorchBackend.get_info-445"><span class="linenos">445</span></a>            <span class="n">supports_image_batch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="TorchBackend.get_info-446"><a href="#TorchBackend.get_info-446"><span class="linenos">446</span></a>            <span class="n">extra</span><span class="o">=</span><span class="p">{</span>
</span><span id="TorchBackend.get_info-447"><a href="#TorchBackend.get_info-447"><span class="linenos">447</span></a>                <span class="s2">&quot;library&quot;</span><span class="p">:</span> <span class="s2">&quot;open-clip-torch&quot;</span><span class="p">,</span>
</span><span id="TorchBackend.get_info-448"><a href="#TorchBackend.get_info-448"><span class="linenos">448</span></a>                <span class="s2">&quot;image_size&quot;</span><span class="p">:</span> <span class="n">image_size_str</span><span class="p">,</span>
</span><span id="TorchBackend.get_info-449"><a href="#TorchBackend.get_info-449"><span class="linenos">449</span></a>                <span class="s2">&quot;config_path&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">model_root_path</span> <span class="o">/</span> <span class="s2">&quot;config.json&quot;</span><span class="p">),</span>
</span><span id="TorchBackend.get_info-450"><a href="#TorchBackend.get_info-450"><span class="linenos">450</span></a>            <span class="p">},</span>
</span><span id="TorchBackend.get_info-451"><a href="#TorchBackend.get_info-451"><span class="linenos">451</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Report runtime and model metadata.</p>
</div>


                            </div>
                </section>
                <section id="ONNXRTBackend">
                            <input id="ONNXRTBackend-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ONNXRTBackend</span><wbr>(<span class="base"><a href="#BaseClipBackend">lumen_clip.backends.BaseClipBackend</a></span>):

                <label class="view-source-button" for="ONNXRTBackend-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ONNXRTBackend"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ONNXRTBackend-64"><a href="#ONNXRTBackend-64"><span class="linenos"> 64</span></a><span class="k">class</span><span class="w"> </span><span class="nc">ONNXRTBackend</span><span class="p">(</span><span class="n">BaseClipBackend</span><span class="p">):</span>
</span><span id="ONNXRTBackend-65"><a href="#ONNXRTBackend-65"><span class="linenos"> 65</span></a>    <span class="c1"># Class-level attribute annotations to satisfy static type checkers</span>
</span><span id="ONNXRTBackend-66"><a href="#ONNXRTBackend-66"><span class="linenos"> 66</span></a>    <span class="n">_providers</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
</span><span id="ONNXRTBackend-67"><a href="#ONNXRTBackend-67"><span class="linenos"> 67</span></a>    <span class="n">_prefer_fp16</span><span class="p">:</span> <span class="nb">bool</span>
</span><span id="ONNXRTBackend-68"><a href="#ONNXRTBackend-68"><span class="linenos"> 68</span></a>    <span class="n">_initialized</span><span class="p">:</span> <span class="nb">bool</span>
</span><span id="ONNXRTBackend-69"><a href="#ONNXRTBackend-69"><span class="linenos"> 69</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ONNXRTBackend-70"><a href="#ONNXRTBackend-70"><span class="linenos"> 70</span></a><span class="sd">    ONNX Runtime backend implementing BaseClipBackend.</span>
</span><span id="ONNXRTBackend-71"><a href="#ONNXRTBackend-71"><span class="linenos"> 71</span></a>
</span><span id="ONNXRTBackend-72"><a href="#ONNXRTBackend-72"><span class="linenos"> 72</span></a><span class="sd">    Args:</span>
</span><span id="ONNXRTBackend-73"><a href="#ONNXRTBackend-73"><span class="linenos"> 73</span></a><span class="sd">        resources: ModelResources object containing model files and configs</span>
</span><span id="ONNXRTBackend-74"><a href="#ONNXRTBackend-74"><span class="linenos"> 74</span></a><span class="sd">        providers: ONNX Runtime execution providers (e.g., [&quot;CPUExecutionProvider&quot;])</span>
</span><span id="ONNXRTBackend-75"><a href="#ONNXRTBackend-75"><span class="linenos"> 75</span></a><span class="sd">        device_preference: Optional hint for device selection</span>
</span><span id="ONNXRTBackend-76"><a href="#ONNXRTBackend-76"><span class="linenos"> 76</span></a><span class="sd">        max_batch_size: Optional hint for batch size</span>
</span><span id="ONNXRTBackend-77"><a href="#ONNXRTBackend-77"><span class="linenos"> 77</span></a><span class="sd">        prefer_fp16: If True and GPU available, prefer FP16 models over FP32</span>
</span><span id="ONNXRTBackend-78"><a href="#ONNXRTBackend-78"><span class="linenos"> 78</span></a>
</span><span id="ONNXRTBackend-79"><a href="#ONNXRTBackend-79"><span class="linenos"> 79</span></a><span class="sd">    Behavior:</span>
</span><span id="ONNXRTBackend-80"><a href="#ONNXRTBackend-80"><span class="linenos"> 80</span></a><span class="sd">        - initialize() loads precision-aware model files:</span>
</span><span id="ONNXRTBackend-81"><a href="#ONNXRTBackend-81"><span class="linenos"> 81</span></a><span class="sd">          - GPU: tries vision.fp16.onnx first, falls back to vision.onnx</span>
</span><span id="ONNXRTBackend-82"><a href="#ONNXRTBackend-82"><span class="linenos"> 82</span></a><span class="sd">          - CPU: uses vision.onnx (FP32) by default</span>
</span><span id="ONNXRTBackend-83"><a href="#ONNXRTBackend-83"><span class="linenos"> 83</span></a><span class="sd">        - Auto-detects model input dtype and adapts preprocessing accordingly</span>
</span><span id="ONNXRTBackend-84"><a href="#ONNXRTBackend-84"><span class="linenos"> 84</span></a><span class="sd">        - text_to_vector() tokenizes and encodes text via the text encoder</span>
</span><span id="ONNXRTBackend-85"><a href="#ONNXRTBackend-85"><span class="linenos"> 85</span></a><span class="sd">        - image_to_vector() preprocesses and encodes images via the vision encoder</span>
</span><span id="ONNXRTBackend-86"><a href="#ONNXRTBackend-86"><span class="linenos"> 86</span></a><span class="sd">        - All outputs are converted to unit-normalized float32 vectors</span>
</span><span id="ONNXRTBackend-87"><a href="#ONNXRTBackend-87"><span class="linenos"> 87</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ONNXRTBackend-88"><a href="#ONNXRTBackend-88"><span class="linenos"> 88</span></a>
</span><span id="ONNXRTBackend-89"><a href="#ONNXRTBackend-89"><span class="linenos"> 89</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="ONNXRTBackend-90"><a href="#ONNXRTBackend-90"><span class="linenos"> 90</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="ONNXRTBackend-91"><a href="#ONNXRTBackend-91"><span class="linenos"> 91</span></a>        <span class="n">resources</span><span class="p">:</span> <span class="s2">&quot;ModelResources&quot;</span><span class="p">,</span>
</span><span id="ONNXRTBackend-92"><a href="#ONNXRTBackend-92"><span class="linenos"> 92</span></a>        <span class="n">providers</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="ONNXRTBackend-93"><a href="#ONNXRTBackend-93"><span class="linenos"> 93</span></a>        <span class="n">device_preference</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="ONNXRTBackend-94"><a href="#ONNXRTBackend-94"><span class="linenos"> 94</span></a>        <span class="n">max_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="ONNXRTBackend-95"><a href="#ONNXRTBackend-95"><span class="linenos"> 95</span></a>        <span class="n">prefer_fp16</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="ONNXRTBackend-96"><a href="#ONNXRTBackend-96"><span class="linenos"> 96</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ONNXRTBackend-97"><a href="#ONNXRTBackend-97"><span class="linenos"> 97</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="ONNXRTBackend-98"><a href="#ONNXRTBackend-98"><span class="linenos"> 98</span></a>            <span class="n">resources</span><span class="o">=</span><span class="n">resources</span><span class="p">,</span>
</span><span id="ONNXRTBackend-99"><a href="#ONNXRTBackend-99"><span class="linenos"> 99</span></a>            <span class="n">device_preference</span><span class="o">=</span><span class="n">device_preference</span><span class="p">,</span>
</span><span id="ONNXRTBackend-100"><a href="#ONNXRTBackend-100"><span class="linenos">100</span></a>            <span class="n">max_batch_size</span><span class="o">=</span><span class="n">max_batch_size</span><span class="p">,</span>
</span><span id="ONNXRTBackend-101"><a href="#ONNXRTBackend-101"><span class="linenos">101</span></a>        <span class="p">)</span>
</span><span id="ONNXRTBackend-102"><a href="#ONNXRTBackend-102"><span class="linenos">102</span></a>
</span><span id="ONNXRTBackend-103"><a href="#ONNXRTBackend-103"><span class="linenos">103</span></a>        <span class="c1"># Execution providers</span>
</span><span id="ONNXRTBackend-104"><a href="#ONNXRTBackend-104"><span class="linenos">104</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_providers</span> <span class="o">=</span> <span class="n">providers</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_default_providers</span><span class="p">(</span><span class="n">device_preference</span><span class="p">)</span>
</span><span id="ONNXRTBackend-105"><a href="#ONNXRTBackend-105"><span class="linenos">105</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_prefer_fp16</span> <span class="o">=</span> <span class="n">prefer_fp16</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_gpu_available</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_providers</span><span class="p">)</span>
</span><span id="ONNXRTBackend-106"><a href="#ONNXRTBackend-106"><span class="linenos">106</span></a>
</span><span id="ONNXRTBackend-107"><a href="#ONNXRTBackend-107"><span class="linenos">107</span></a>        <span class="c1"># Runtime objects</span>
</span><span id="ONNXRTBackend-108"><a href="#ONNXRTBackend-108"><span class="linenos">108</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_sess_vision</span><span class="p">:</span> <span class="n">ort</span><span class="o">.</span><span class="n">InferenceSession</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend-109"><a href="#ONNXRTBackend-109"><span class="linenos">109</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_sess_text</span><span class="p">:</span> <span class="n">ort</span><span class="o">.</span><span class="n">InferenceSession</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend-110"><a href="#ONNXRTBackend-110"><span class="linenos">110</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend-111"><a href="#ONNXRTBackend-111"><span class="linenos">111</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_image_preprocessor</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend-112"><a href="#ONNXRTBackend-112"><span class="linenos">112</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_load_time_seconds</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend-113"><a href="#ONNXRTBackend-113"><span class="linenos">113</span></a>
</span><span id="ONNXRTBackend-114"><a href="#ONNXRTBackend-114"><span class="linenos">114</span></a>        <span class="c1"># Precision tracking</span>
</span><span id="ONNXRTBackend-115"><a href="#ONNXRTBackend-115"><span class="linenos">115</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_vision_precision</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;unknown&quot;</span>
</span><span id="ONNXRTBackend-116"><a href="#ONNXRTBackend-116"><span class="linenos">116</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_text_precision</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;unknown&quot;</span>
</span><span id="ONNXRTBackend-117"><a href="#ONNXRTBackend-117"><span class="linenos">117</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_vision_input_dtype</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="ONNXRTBackend-118"><a href="#ONNXRTBackend-118"><span class="linenos">118</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_text_input_dtype</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
</span><span id="ONNXRTBackend-119"><a href="#ONNXRTBackend-119"><span class="linenos">119</span></a>
</span><span id="ONNXRTBackend-120"><a href="#ONNXRTBackend-120"><span class="linenos">120</span></a>    <span class="nd">@override</span>
</span><span id="ONNXRTBackend-121"><a href="#ONNXRTBackend-121"><span class="linenos">121</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ONNXRTBackend-122"><a href="#ONNXRTBackend-122"><span class="linenos">122</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Load ONNX models and prepare preprocessing.&quot;&quot;&quot;</span>
</span><span id="ONNXRTBackend-123"><a href="#ONNXRTBackend-123"><span class="linenos">123</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span><span class="p">:</span>
</span><span id="ONNXRTBackend-124"><a href="#ONNXRTBackend-124"><span class="linenos">124</span></a>            <span class="k">return</span>
</span><span id="ONNXRTBackend-125"><a href="#ONNXRTBackend-125"><span class="linenos">125</span></a>
</span><span id="ONNXRTBackend-126"><a href="#ONNXRTBackend-126"><span class="linenos">126</span></a>        <span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
</span><span id="ONNXRTBackend-127"><a href="#ONNXRTBackend-127"><span class="linenos">127</span></a>
</span><span id="ONNXRTBackend-128"><a href="#ONNXRTBackend-128"><span class="linenos">128</span></a>        <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</span><span id="ONNXRTBackend-129"><a href="#ONNXRTBackend-129"><span class="linenos">129</span></a>
</span><span id="ONNXRTBackend-130"><a href="#ONNXRTBackend-130"><span class="linenos">130</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="ONNXRTBackend-131"><a href="#ONNXRTBackend-131"><span class="linenos">131</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Initializing ONNXRTBackend for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="ONNXRTBackend-132"><a href="#ONNXRTBackend-132"><span class="linenos">132</span></a>
</span><span id="ONNXRTBackend-133"><a href="#ONNXRTBackend-133"><span class="linenos">133</span></a>            <span class="n">sess_options</span> <span class="o">=</span> <span class="n">ort</span><span class="o">.</span><span class="n">SessionOptions</span><span class="p">()</span>
</span><span id="ONNXRTBackend-134"><a href="#ONNXRTBackend-134"><span class="linenos">134</span></a>            <span class="n">sess_options</span><span class="o">.</span><span class="n">graph_optimization_level</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="ONNXRTBackend-135"><a href="#ONNXRTBackend-135"><span class="linenos">135</span></a>                <span class="n">ort</span><span class="o">.</span><span class="n">GraphOptimizationLevel</span><span class="o">.</span><span class="n">ORT_ENABLE_ALL</span>
</span><span id="ONNXRTBackend-136"><a href="#ONNXRTBackend-136"><span class="linenos">136</span></a>            <span class="p">)</span>
</span><span id="ONNXRTBackend-137"><a href="#ONNXRTBackend-137"><span class="linenos">137</span></a>
</span><span id="ONNXRTBackend-138"><a href="#ONNXRTBackend-138"><span class="linenos">138</span></a>            <span class="c1"># 1. Load vision encoder with precision selection</span>
</span><span id="ONNXRTBackend-139"><a href="#ONNXRTBackend-139"><span class="linenos">139</span></a>            <span class="n">vision_path</span><span class="p">,</span> <span class="n">vision_precision</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_model_file</span><span class="p">(</span><span class="s2">&quot;vision&quot;</span><span class="p">)</span>
</span><span id="ONNXRTBackend-140"><a href="#ONNXRTBackend-140"><span class="linenos">140</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
</span><span id="ONNXRTBackend-141"><a href="#ONNXRTBackend-141"><span class="linenos">141</span></a>                <span class="sa">f</span><span class="s2">&quot;Loading vision encoder from </span><span class="si">{</span><span class="n">vision_path</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">vision_precision</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="ONNXRTBackend-142"><a href="#ONNXRTBackend-142"><span class="linenos">142</span></a>            <span class="p">)</span>
</span><span id="ONNXRTBackend-143"><a href="#ONNXRTBackend-143"><span class="linenos">143</span></a>
</span><span id="ONNXRTBackend-144"><a href="#ONNXRTBackend-144"><span class="linenos">144</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_sess_vision</span> <span class="o">=</span> <span class="n">ort</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span>
</span><span id="ONNXRTBackend-145"><a href="#ONNXRTBackend-145"><span class="linenos">145</span></a>                <span class="nb">str</span><span class="p">(</span><span class="n">vision_path</span><span class="p">),</span>
</span><span id="ONNXRTBackend-146"><a href="#ONNXRTBackend-146"><span class="linenos">146</span></a>                <span class="n">sess_options</span><span class="p">,</span>
</span><span id="ONNXRTBackend-147"><a href="#ONNXRTBackend-147"><span class="linenos">147</span></a>                <span class="n">providers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_providers</span><span class="p">,</span>
</span><span id="ONNXRTBackend-148"><a href="#ONNXRTBackend-148"><span class="linenos">148</span></a>            <span class="p">)</span>
</span><span id="ONNXRTBackend-149"><a href="#ONNXRTBackend-149"><span class="linenos">149</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_vision_precision</span> <span class="o">=</span> <span class="n">vision_precision</span>
</span><span id="ONNXRTBackend-150"><a href="#ONNXRTBackend-150"><span class="linenos">150</span></a>
</span><span id="ONNXRTBackend-151"><a href="#ONNXRTBackend-151"><span class="linenos">151</span></a>            <span class="c1"># Detect vision input dtype</span>
</span><span id="ONNXRTBackend-152"><a href="#ONNXRTBackend-152"><span class="linenos">152</span></a>            <span class="n">vision_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_vision</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ONNXRTBackend-153"><a href="#ONNXRTBackend-153"><span class="linenos">153</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_vision_input_dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_onnx_type_to_numpy</span><span class="p">(</span><span class="n">vision_input</span><span class="o">.</span><span class="n">type</span><span class="p">)</span>
</span><span id="ONNXRTBackend-154"><a href="#ONNXRTBackend-154"><span class="linenos">154</span></a>
</span><span id="ONNXRTBackend-155"><a href="#ONNXRTBackend-155"><span class="linenos">155</span></a>            <span class="c1"># 2. Load text encoder with precision selection</span>
</span><span id="ONNXRTBackend-156"><a href="#ONNXRTBackend-156"><span class="linenos">156</span></a>            <span class="n">text_path</span><span class="p">,</span> <span class="n">text_precision</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_model_file</span><span class="p">(</span><span class="s2">&quot;text&quot;</span><span class="p">)</span>
</span><span id="ONNXRTBackend-157"><a href="#ONNXRTBackend-157"><span class="linenos">157</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading text encoder from </span><span class="si">{</span><span class="n">text_path</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">text_precision</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
</span><span id="ONNXRTBackend-158"><a href="#ONNXRTBackend-158"><span class="linenos">158</span></a>
</span><span id="ONNXRTBackend-159"><a href="#ONNXRTBackend-159"><span class="linenos">159</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_sess_text</span> <span class="o">=</span> <span class="n">ort</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span>
</span><span id="ONNXRTBackend-160"><a href="#ONNXRTBackend-160"><span class="linenos">160</span></a>                <span class="nb">str</span><span class="p">(</span><span class="n">text_path</span><span class="p">),</span>
</span><span id="ONNXRTBackend-161"><a href="#ONNXRTBackend-161"><span class="linenos">161</span></a>                <span class="n">sess_options</span><span class="p">,</span>
</span><span id="ONNXRTBackend-162"><a href="#ONNXRTBackend-162"><span class="linenos">162</span></a>                <span class="n">providers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_providers</span><span class="p">,</span>
</span><span id="ONNXRTBackend-163"><a href="#ONNXRTBackend-163"><span class="linenos">163</span></a>            <span class="p">)</span>
</span><span id="ONNXRTBackend-164"><a href="#ONNXRTBackend-164"><span class="linenos">164</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_text_precision</span> <span class="o">=</span> <span class="n">text_precision</span>
</span><span id="ONNXRTBackend-165"><a href="#ONNXRTBackend-165"><span class="linenos">165</span></a>
</span><span id="ONNXRTBackend-166"><a href="#ONNXRTBackend-166"><span class="linenos">166</span></a>            <span class="c1"># Detect text input dtype</span>
</span><span id="ONNXRTBackend-167"><a href="#ONNXRTBackend-167"><span class="linenos">167</span></a>            <span class="n">text_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_text</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ONNXRTBackend-168"><a href="#ONNXRTBackend-168"><span class="linenos">168</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_text_input_dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_onnx_type_to_numpy</span><span class="p">(</span><span class="n">text_input</span><span class="o">.</span><span class="n">type</span><span class="p">)</span>
</span><span id="ONNXRTBackend-169"><a href="#ONNXRTBackend-169"><span class="linenos">169</span></a>
</span><span id="ONNXRTBackend-170"><a href="#ONNXRTBackend-170"><span class="linenos">170</span></a>            <span class="c1"># 3. Setup tokenizer</span>
</span><span id="ONNXRTBackend-171"><a href="#ONNXRTBackend-171"><span class="linenos">171</span></a>            <span class="c1"># Cast to the declared callable signature to satisfy static type checkers.</span>
</span><span id="ONNXRTBackend-172"><a href="#ONNXRTBackend-172"><span class="linenos">172</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span>
</span><span id="ONNXRTBackend-173"><a href="#ONNXRTBackend-173"><span class="linenos">173</span></a>                <span class="n">Callable</span><span class="p">[[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load_tokenizer</span><span class="p">()</span>
</span><span id="ONNXRTBackend-174"><a href="#ONNXRTBackend-174"><span class="linenos">174</span></a>            <span class="p">)</span>
</span><span id="ONNXRTBackend-175"><a href="#ONNXRTBackend-175"><span class="linenos">175</span></a>
</span><span id="ONNXRTBackend-176"><a href="#ONNXRTBackend-176"><span class="linenos">176</span></a>            <span class="c1"># 4. Setup image preprocessor</span>
</span><span id="ONNXRTBackend-177"><a href="#ONNXRTBackend-177"><span class="linenos">177</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_image_preprocessor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_image_preprocessor</span><span class="p">()</span>
</span><span id="ONNXRTBackend-178"><a href="#ONNXRTBackend-178"><span class="linenos">178</span></a>
</span><span id="ONNXRTBackend-179"><a href="#ONNXRTBackend-179"><span class="linenos">179</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_load_time_seconds</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span>
</span><span id="ONNXRTBackend-180"><a href="#ONNXRTBackend-180"><span class="linenos">180</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="ONNXRTBackend-181"><a href="#ONNXRTBackend-181"><span class="linenos">181</span></a>
</span><span id="ONNXRTBackend-182"><a href="#ONNXRTBackend-182"><span class="linenos">182</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
</span><span id="ONNXRTBackend-183"><a href="#ONNXRTBackend-183"><span class="linenos">183</span></a>                <span class="sa">f</span><span class="s2">&quot;✅ ONNXRTBackend initialized in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_load_time_seconds</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s&quot;</span>
</span><span id="ONNXRTBackend-184"><a href="#ONNXRTBackend-184"><span class="linenos">184</span></a>            <span class="p">)</span>
</span><span id="ONNXRTBackend-185"><a href="#ONNXRTBackend-185"><span class="linenos">185</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   Providers: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_providers</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="ONNXRTBackend-186"><a href="#ONNXRTBackend-186"><span class="linenos">186</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
</span><span id="ONNXRTBackend-187"><a href="#ONNXRTBackend-187"><span class="linenos">187</span></a>                <span class="sa">f</span><span class="s2">&quot;   Vision: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_vision_precision</span><span class="si">}</span><span class="s2"> (input: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_vision_input_dtype</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="ONNXRTBackend-188"><a href="#ONNXRTBackend-188"><span class="linenos">188</span></a>            <span class="p">)</span>
</span><span id="ONNXRTBackend-189"><a href="#ONNXRTBackend-189"><span class="linenos">189</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
</span><span id="ONNXRTBackend-190"><a href="#ONNXRTBackend-190"><span class="linenos">190</span></a>                <span class="sa">f</span><span class="s2">&quot;   Text: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_text_precision</span><span class="si">}</span><span class="s2"> (input: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_text_input_dtype</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="ONNXRTBackend-191"><a href="#ONNXRTBackend-191"><span class="linenos">191</span></a>            <span class="p">)</span>
</span><span id="ONNXRTBackend-192"><a href="#ONNXRTBackend-192"><span class="linenos">192</span></a>
</span><span id="ONNXRTBackend-193"><a href="#ONNXRTBackend-193"><span class="linenos">193</span></a>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="ONNXRTBackend-194"><a href="#ONNXRTBackend-194"><span class="linenos">194</span></a>            <span class="k">raise</span> <span class="n">ONNXRTModelLoadingError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ONNX model loading failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span><span id="ONNXRTBackend-195"><a href="#ONNXRTBackend-195"><span class="linenos">195</span></a>
</span><span id="ONNXRTBackend-196"><a href="#ONNXRTBackend-196"><span class="linenos">196</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_select_model_file</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Path</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
</span><span id="ONNXRTBackend-197"><a href="#ONNXRTBackend-197"><span class="linenos">197</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ONNXRTBackend-198"><a href="#ONNXRTBackend-198"><span class="linenos">198</span></a><span class="sd">        Select model file based on precision preference and availability.</span>
</span><span id="ONNXRTBackend-199"><a href="#ONNXRTBackend-199"><span class="linenos">199</span></a>
</span><span id="ONNXRTBackend-200"><a href="#ONNXRTBackend-200"><span class="linenos">200</span></a><span class="sd">        Args:</span>
</span><span id="ONNXRTBackend-201"><a href="#ONNXRTBackend-201"><span class="linenos">201</span></a><span class="sd">            model_type: &quot;vision&quot; or &quot;text&quot;</span>
</span><span id="ONNXRTBackend-202"><a href="#ONNXRTBackend-202"><span class="linenos">202</span></a>
</span><span id="ONNXRTBackend-203"><a href="#ONNXRTBackend-203"><span class="linenos">203</span></a><span class="sd">        Returns:</span>
</span><span id="ONNXRTBackend-204"><a href="#ONNXRTBackend-204"><span class="linenos">204</span></a><span class="sd">            Tuple of (file_path, precision_string)</span>
</span><span id="ONNXRTBackend-205"><a href="#ONNXRTBackend-205"><span class="linenos">205</span></a>
</span><span id="ONNXRTBackend-206"><a href="#ONNXRTBackend-206"><span class="linenos">206</span></a><span class="sd">        Raises:</span>
</span><span id="ONNXRTBackend-207"><a href="#ONNXRTBackend-207"><span class="linenos">207</span></a><span class="sd">            ONNXRTModelLoadingError: If no suitable model file is found</span>
</span><span id="ONNXRTBackend-208"><a href="#ONNXRTBackend-208"><span class="linenos">208</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ONNXRTBackend-209"><a href="#ONNXRTBackend-209"><span class="linenos">209</span></a>        <span class="n">runtime_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">model_root_path</span> <span class="o">/</span> <span class="s2">&quot;onnx&quot;</span>
</span><span id="ONNXRTBackend-210"><a href="#ONNXRTBackend-210"><span class="linenos">210</span></a>
</span><span id="ONNXRTBackend-211"><a href="#ONNXRTBackend-211"><span class="linenos">211</span></a>        <span class="c1"># Try FP16 first if GPU and preferred</span>
</span><span id="ONNXRTBackend-212"><a href="#ONNXRTBackend-212"><span class="linenos">212</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prefer_fp16</span><span class="p">:</span>
</span><span id="ONNXRTBackend-213"><a href="#ONNXRTBackend-213"><span class="linenos">213</span></a>            <span class="n">fp16_path</span> <span class="o">=</span> <span class="n">runtime_dir</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2">.fp16.onnx&quot;</span>
</span><span id="ONNXRTBackend-214"><a href="#ONNXRTBackend-214"><span class="linenos">214</span></a>            <span class="k">if</span> <span class="n">fp16_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
</span><span id="ONNXRTBackend-215"><a href="#ONNXRTBackend-215"><span class="linenos">215</span></a>                <span class="k">return</span> <span class="n">fp16_path</span><span class="p">,</span> <span class="s2">&quot;fp16&quot;</span>
</span><span id="ONNXRTBackend-216"><a href="#ONNXRTBackend-216"><span class="linenos">216</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FP16 model not found at </span><span class="si">{</span><span class="n">fp16_path</span><span class="si">}</span><span class="s2">, falling back to FP32&quot;</span><span class="p">)</span>
</span><span id="ONNXRTBackend-217"><a href="#ONNXRTBackend-217"><span class="linenos">217</span></a>
</span><span id="ONNXRTBackend-218"><a href="#ONNXRTBackend-218"><span class="linenos">218</span></a>        <span class="c1"># Fall back to FP32 (default naming)</span>
</span><span id="ONNXRTBackend-219"><a href="#ONNXRTBackend-219"><span class="linenos">219</span></a>        <span class="n">fp32_path</span> <span class="o">=</span> <span class="n">runtime_dir</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2">.onnx&quot;</span>
</span><span id="ONNXRTBackend-220"><a href="#ONNXRTBackend-220"><span class="linenos">220</span></a>        <span class="k">if</span> <span class="n">fp32_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
</span><span id="ONNXRTBackend-221"><a href="#ONNXRTBackend-221"><span class="linenos">221</span></a>            <span class="k">return</span> <span class="n">fp32_path</span><span class="p">,</span> <span class="s2">&quot;fp32&quot;</span>
</span><span id="ONNXRTBackend-222"><a href="#ONNXRTBackend-222"><span class="linenos">222</span></a>
</span><span id="ONNXRTBackend-223"><a href="#ONNXRTBackend-223"><span class="linenos">223</span></a>        <span class="c1"># If still not found, check if there&#39;s an fp16 variant as last resort</span>
</span><span id="ONNXRTBackend-224"><a href="#ONNXRTBackend-224"><span class="linenos">224</span></a>        <span class="n">fp16_path</span> <span class="o">=</span> <span class="n">runtime_dir</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2">.fp16.onnx&quot;</span>
</span><span id="ONNXRTBackend-225"><a href="#ONNXRTBackend-225"><span class="linenos">225</span></a>        <span class="k">if</span> <span class="n">fp16_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
</span><span id="ONNXRTBackend-226"><a href="#ONNXRTBackend-226"><span class="linenos">226</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Only FP16 model found, using it despite CPU preference&quot;</span><span class="p">)</span>
</span><span id="ONNXRTBackend-227"><a href="#ONNXRTBackend-227"><span class="linenos">227</span></a>            <span class="k">return</span> <span class="n">fp16_path</span><span class="p">,</span> <span class="s2">&quot;fp16&quot;</span>
</span><span id="ONNXRTBackend-228"><a href="#ONNXRTBackend-228"><span class="linenos">228</span></a>
</span><span id="ONNXRTBackend-229"><a href="#ONNXRTBackend-229"><span class="linenos">229</span></a>        <span class="k">raise</span> <span class="n">ONNXRTModelLoadingError</span><span class="p">(</span>
</span><span id="ONNXRTBackend-230"><a href="#ONNXRTBackend-230"><span class="linenos">230</span></a>            <span class="sa">f</span><span class="s2">&quot;No </span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2"> model found. Expected </span><span class="si">{</span><span class="n">fp32_path</span><span class="si">}</span><span class="s2"> or </span><span class="si">{</span><span class="n">fp16_path</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="ONNXRTBackend-231"><a href="#ONNXRTBackend-231"><span class="linenos">231</span></a>        <span class="p">)</span>
</span><span id="ONNXRTBackend-232"><a href="#ONNXRTBackend-232"><span class="linenos">232</span></a>
</span><span id="ONNXRTBackend-233"><a href="#ONNXRTBackend-233"><span class="linenos">233</span></a>    <span class="nd">@staticmethod</span>
</span><span id="ONNXRTBackend-234"><a href="#ONNXRTBackend-234"><span class="linenos">234</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_onnx_type_to_numpy</span><span class="p">(</span><span class="n">onnx_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">:</span>
</span><span id="ONNXRTBackend-235"><a href="#ONNXRTBackend-235"><span class="linenos">235</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert ONNX type string to numpy dtype.&quot;&quot;&quot;</span>
</span><span id="ONNXRTBackend-236"><a href="#ONNXRTBackend-236"><span class="linenos">236</span></a>        <span class="n">type_lower</span> <span class="o">=</span> <span class="n">onnx_type</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
</span><span id="ONNXRTBackend-237"><a href="#ONNXRTBackend-237"><span class="linenos">237</span></a>        <span class="k">if</span> <span class="s2">&quot;float16&quot;</span> <span class="ow">in</span> <span class="n">type_lower</span> <span class="ow">or</span> <span class="s2">&quot;half&quot;</span> <span class="ow">in</span> <span class="n">type_lower</span><span class="p">:</span>
</span><span id="ONNXRTBackend-238"><a href="#ONNXRTBackend-238"><span class="linenos">238</span></a>            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
</span><span id="ONNXRTBackend-239"><a href="#ONNXRTBackend-239"><span class="linenos">239</span></a>        <span class="k">if</span> <span class="s2">&quot;float&quot;</span> <span class="ow">in</span> <span class="n">type_lower</span><span class="p">:</span>
</span><span id="ONNXRTBackend-240"><a href="#ONNXRTBackend-240"><span class="linenos">240</span></a>            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="ONNXRTBackend-241"><a href="#ONNXRTBackend-241"><span class="linenos">241</span></a>        <span class="k">if</span> <span class="s2">&quot;int64&quot;</span> <span class="ow">in</span> <span class="n">type_lower</span> <span class="ow">or</span> <span class="s2">&quot;long&quot;</span> <span class="ow">in</span> <span class="n">type_lower</span><span class="p">:</span>
</span><span id="ONNXRTBackend-242"><a href="#ONNXRTBackend-242"><span class="linenos">242</span></a>            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
</span><span id="ONNXRTBackend-243"><a href="#ONNXRTBackend-243"><span class="linenos">243</span></a>        <span class="k">if</span> <span class="s2">&quot;int32&quot;</span> <span class="ow">in</span> <span class="n">type_lower</span> <span class="ow">or</span> <span class="s2">&quot;int&quot;</span> <span class="ow">in</span> <span class="n">type_lower</span><span class="p">:</span>
</span><span id="ONNXRTBackend-244"><a href="#ONNXRTBackend-244"><span class="linenos">244</span></a>            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</span><span id="ONNXRTBackend-245"><a href="#ONNXRTBackend-245"><span class="linenos">245</span></a>        <span class="c1"># Default to float32 for unknown types</span>
</span><span id="ONNXRTBackend-246"><a href="#ONNXRTBackend-246"><span class="linenos">246</span></a>        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown ONNX type &#39;</span><span class="si">{</span><span class="n">onnx_type</span><span class="si">}</span><span class="s2">&#39;, defaulting to float32&quot;</span><span class="p">)</span>
</span><span id="ONNXRTBackend-247"><a href="#ONNXRTBackend-247"><span class="linenos">247</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="ONNXRTBackend-248"><a href="#ONNXRTBackend-248"><span class="linenos">248</span></a>
</span><span id="ONNXRTBackend-249"><a href="#ONNXRTBackend-249"><span class="linenos">249</span></a>    <span class="nd">@staticmethod</span>
</span><span id="ONNXRTBackend-250"><a href="#ONNXRTBackend-250"><span class="linenos">250</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_is_gpu_available</span><span class="p">(</span><span class="n">providers</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
</span><span id="ONNXRTBackend-251"><a href="#ONNXRTBackend-251"><span class="linenos">251</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if any GPU execution provider is in the list.&quot;&quot;&quot;</span>
</span><span id="ONNXRTBackend-252"><a href="#ONNXRTBackend-252"><span class="linenos">252</span></a>        <span class="n">gpu_providers</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="ONNXRTBackend-253"><a href="#ONNXRTBackend-253"><span class="linenos">253</span></a>            <span class="s2">&quot;CUDAExecutionProvider&quot;</span><span class="p">,</span>
</span><span id="ONNXRTBackend-254"><a href="#ONNXRTBackend-254"><span class="linenos">254</span></a>            <span class="s2">&quot;CoreMLExecutionProvider&quot;</span><span class="p">,</span>
</span><span id="ONNXRTBackend-255"><a href="#ONNXRTBackend-255"><span class="linenos">255</span></a>            <span class="s2">&quot;DmlExecutionProvider&quot;</span><span class="p">,</span>
</span><span id="ONNXRTBackend-256"><a href="#ONNXRTBackend-256"><span class="linenos">256</span></a>            <span class="s2">&quot;OpenVINOExecutionProvider&quot;</span><span class="p">,</span>
</span><span id="ONNXRTBackend-257"><a href="#ONNXRTBackend-257"><span class="linenos">257</span></a>            <span class="s2">&quot;TensorrtExecutionProvider&quot;</span><span class="p">,</span>
</span><span id="ONNXRTBackend-258"><a href="#ONNXRTBackend-258"><span class="linenos">258</span></a>        <span class="p">}</span>
</span><span id="ONNXRTBackend-259"><a href="#ONNXRTBackend-259"><span class="linenos">259</span></a>        <span class="k">return</span> <span class="nb">any</span><span class="p">(</span><span class="n">p</span> <span class="ow">in</span> <span class="n">gpu_providers</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">providers</span><span class="p">)</span>
</span><span id="ONNXRTBackend-260"><a href="#ONNXRTBackend-260"><span class="linenos">260</span></a>
</span><span id="ONNXRTBackend-261"><a href="#ONNXRTBackend-261"><span class="linenos">261</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_load_tokenizer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
</span><span id="ONNXRTBackend-262"><a href="#ONNXRTBackend-262"><span class="linenos">262</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Load tokenizer from tokenizer.json or fallback to SimpleTokenizer.&quot;&quot;&quot;</span>
</span><span id="ONNXRTBackend-263"><a href="#ONNXRTBackend-263"><span class="linenos">263</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">tokenizer_config</span><span class="p">:</span>
</span><span id="ONNXRTBackend-264"><a href="#ONNXRTBackend-264"><span class="linenos">264</span></a>            <span class="k">try</span><span class="p">:</span>
</span><span id="ONNXRTBackend-265"><a href="#ONNXRTBackend-265"><span class="linenos">265</span></a>                <span class="n">tokenizer_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">model_root_path</span> <span class="o">/</span> <span class="s2">&quot;tokenizer.json&quot;</span>
</span><span id="ONNXRTBackend-266"><a href="#ONNXRTBackend-266"><span class="linenos">266</span></a>                <span class="n">hf_tokenizer</span> <span class="o">=</span> <span class="n">HFTokenizer</span><span class="o">.</span><span class="n">from_file</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">tokenizer_path</span><span class="p">))</span>
</span><span id="ONNXRTBackend-267"><a href="#ONNXRTBackend-267"><span class="linenos">267</span></a>
</span><span id="ONNXRTBackend-268"><a href="#ONNXRTBackend-268"><span class="linenos">268</span></a>                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using custom tokenizer from tokenizer.json&quot;</span><span class="p">)</span>
</span><span id="ONNXRTBackend-269"><a href="#ONNXRTBackend-269"><span class="linenos">269</span></a>
</span><span id="ONNXRTBackend-270"><a href="#ONNXRTBackend-270"><span class="linenos">270</span></a>                <span class="k">def</span><span class="w"> </span><span class="nf">tokenize_fn</span><span class="p">(</span><span class="n">texts</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="ONNXRTBackend-271"><a href="#ONNXRTBackend-271"><span class="linenos">271</span></a>                    <span class="n">texts_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">texts</span><span class="p">)</span>
</span><span id="ONNXRTBackend-272"><a href="#ONNXRTBackend-272"><span class="linenos">272</span></a>                    <span class="n">encoded</span> <span class="o">=</span> <span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">encode_batch</span><span class="p">(</span><span class="n">texts_list</span><span class="p">)</span>
</span><span id="ONNXRTBackend-273"><a href="#ONNXRTBackend-273"><span class="linenos">273</span></a>                    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">enc</span><span class="o">.</span><span class="n">ids</span> <span class="k">for</span> <span class="n">enc</span> <span class="ow">in</span> <span class="n">encoded</span><span class="p">]</span>
</span><span id="ONNXRTBackend-274"><a href="#ONNXRTBackend-274"><span class="linenos">274</span></a>                    <span class="n">CLIP_MAX_LEN</span> <span class="o">=</span> <span class="mi">77</span>
</span><span id="ONNXRTBackend-275"><a href="#ONNXRTBackend-275"><span class="linenos">275</span></a>                    <span class="n">padded</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="ONNXRTBackend-276"><a href="#ONNXRTBackend-276"><span class="linenos">276</span></a>                        <span class="n">t</span><span class="p">[:</span><span class="n">CLIP_MAX_LEN</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">CLIP_MAX_LEN</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">))</span>
</span><span id="ONNXRTBackend-277"><a href="#ONNXRTBackend-277"><span class="linenos">277</span></a>                        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens</span>
</span><span id="ONNXRTBackend-278"><a href="#ONNXRTBackend-278"><span class="linenos">278</span></a>                    <span class="p">]</span>
</span><span id="ONNXRTBackend-279"><a href="#ONNXRTBackend-279"><span class="linenos">279</span></a>                    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">padded</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
</span><span id="ONNXRTBackend-280"><a href="#ONNXRTBackend-280"><span class="linenos">280</span></a>
</span><span id="ONNXRTBackend-281"><a href="#ONNXRTBackend-281"><span class="linenos">281</span></a>                <span class="k">return</span> <span class="n">tokenize_fn</span>
</span><span id="ONNXRTBackend-282"><a href="#ONNXRTBackend-282"><span class="linenos">282</span></a>
</span><span id="ONNXRTBackend-283"><a href="#ONNXRTBackend-283"><span class="linenos">283</span></a>            <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
</span><span id="ONNXRTBackend-284"><a href="#ONNXRTBackend-284"><span class="linenos">284</span></a>                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
</span><span id="ONNXRTBackend-285"><a href="#ONNXRTBackend-285"><span class="linenos">285</span></a>                    <span class="s2">&quot;tokenizers library not available, falling back to SimpleTokenizer&quot;</span>
</span><span id="ONNXRTBackend-286"><a href="#ONNXRTBackend-286"><span class="linenos">286</span></a>                <span class="p">)</span>
</span><span id="ONNXRTBackend-287"><a href="#ONNXRTBackend-287"><span class="linenos">287</span></a>            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="ONNXRTBackend-288"><a href="#ONNXRTBackend-288"><span class="linenos">288</span></a>                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
</span><span id="ONNXRTBackend-289"><a href="#ONNXRTBackend-289"><span class="linenos">289</span></a>                    <span class="sa">f</span><span class="s2">&quot;Failed to load custom tokenizer: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">, falling back to SimpleTokenizer&quot;</span>
</span><span id="ONNXRTBackend-290"><a href="#ONNXRTBackend-290"><span class="linenos">290</span></a>                <span class="p">)</span>
</span><span id="ONNXRTBackend-291"><a href="#ONNXRTBackend-291"><span class="linenos">291</span></a>
</span><span id="ONNXRTBackend-292"><a href="#ONNXRTBackend-292"><span class="linenos">292</span></a>        <span class="c1"># Fallback to SimpleTokenizer</span>
</span><span id="ONNXRTBackend-293"><a href="#ONNXRTBackend-293"><span class="linenos">293</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="ONNXRTBackend-294"><a href="#ONNXRTBackend-294"><span class="linenos">294</span></a>            <span class="kn">from</span><span class="w"> </span><span class="nn">open_clip.tokenizer</span><span class="w"> </span><span class="kn">import</span> <span class="n">SimpleTokenizer</span>
</span><span id="ONNXRTBackend-295"><a href="#ONNXRTBackend-295"><span class="linenos">295</span></a>
</span><span id="ONNXRTBackend-296"><a href="#ONNXRTBackend-296"><span class="linenos">296</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using SimpleTokenizer (fallback)&quot;</span><span class="p">)</span>
</span><span id="ONNXRTBackend-297"><a href="#ONNXRTBackend-297"><span class="linenos">297</span></a>
</span><span id="ONNXRTBackend-298"><a href="#ONNXRTBackend-298"><span class="linenos">298</span></a>            <span class="n">simple_tokenizer</span> <span class="o">=</span> <span class="n">SimpleTokenizer</span><span class="p">()</span>
</span><span id="ONNXRTBackend-299"><a href="#ONNXRTBackend-299"><span class="linenos">299</span></a>
</span><span id="ONNXRTBackend-300"><a href="#ONNXRTBackend-300"><span class="linenos">300</span></a>            <span class="k">def</span><span class="w"> </span><span class="nf">tokenize_fn</span><span class="p">(</span><span class="n">texts</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="ONNXRTBackend-301"><a href="#ONNXRTBackend-301"><span class="linenos">301</span></a>                <span class="n">tokens</span> <span class="o">=</span> <span class="n">simple_tokenizer</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">texts</span><span class="p">))</span>
</span><span id="ONNXRTBackend-302"><a href="#ONNXRTBackend-302"><span class="linenos">302</span></a>                <span class="k">return</span> <span class="n">tokens</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
</span><span id="ONNXRTBackend-303"><a href="#ONNXRTBackend-303"><span class="linenos">303</span></a>
</span><span id="ONNXRTBackend-304"><a href="#ONNXRTBackend-304"><span class="linenos">304</span></a>            <span class="k">return</span> <span class="n">tokenize_fn</span>
</span><span id="ONNXRTBackend-305"><a href="#ONNXRTBackend-305"><span class="linenos">305</span></a>        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
</span><span id="ONNXRTBackend-306"><a href="#ONNXRTBackend-306"><span class="linenos">306</span></a>            <span class="k">raise</span> <span class="n">ONNXRTModelLoadingError</span><span class="p">(</span>
</span><span id="ONNXRTBackend-307"><a href="#ONNXRTBackend-307"><span class="linenos">307</span></a>                <span class="s2">&quot;Neither tokenizers nor open_clip is available for tokenization&quot;</span>
</span><span id="ONNXRTBackend-308"><a href="#ONNXRTBackend-308"><span class="linenos">308</span></a>            <span class="p">)</span>
</span><span id="ONNXRTBackend-309"><a href="#ONNXRTBackend-309"><span class="linenos">309</span></a>
</span><span id="ONNXRTBackend-310"><a href="#ONNXRTBackend-310"><span class="linenos">310</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_create_image_preprocessor</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
</span><span id="ONNXRTBackend-311"><a href="#ONNXRTBackend-311"><span class="linenos">311</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Create image preprocessing function based on model config and input dtype.&quot;&quot;&quot;</span>
</span><span id="ONNXRTBackend-312"><a href="#ONNXRTBackend-312"><span class="linenos">312</span></a>        <span class="c1"># Get image size from config</span>
</span><span id="ONNXRTBackend-313"><a href="#ONNXRTBackend-313"><span class="linenos">313</span></a>        <span class="n">image_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">get_image_size</span><span class="p">()</span> <span class="ow">or</span> <span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
</span><span id="ONNXRTBackend-314"><a href="#ONNXRTBackend-314"><span class="linenos">314</span></a>        <span class="n">target_dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vision_input_dtype</span>
</span><span id="ONNXRTBackend-315"><a href="#ONNXRTBackend-315"><span class="linenos">315</span></a>
</span><span id="ONNXRTBackend-316"><a href="#ONNXRTBackend-316"><span class="linenos">316</span></a>        <span class="c1"># Standard CLIP preprocessing</span>
</span><span id="ONNXRTBackend-317"><a href="#ONNXRTBackend-317"><span class="linenos">317</span></a>        <span class="k">def</span><span class="w"> </span><span class="nf">preprocess</span><span class="p">(</span><span class="n">image</span><span class="p">:</span> <span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="ONNXRTBackend-318"><a href="#ONNXRTBackend-318"><span class="linenos">318</span></a>            <span class="c1"># Resize and center crop</span>
</span><span id="ONNXRTBackend-319"><a href="#ONNXRTBackend-319"><span class="linenos">319</span></a>            <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">)</span>
</span><span id="ONNXRTBackend-320"><a href="#ONNXRTBackend-320"><span class="linenos">320</span></a>            <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">image_size</span><span class="p">,</span> <span class="n">PILImage</span><span class="o">.</span><span class="n">Resampling</span><span class="o">.</span><span class="n">BICUBIC</span><span class="p">)</span>
</span><span id="ONNXRTBackend-321"><a href="#ONNXRTBackend-321"><span class="linenos">321</span></a>
</span><span id="ONNXRTBackend-322"><a href="#ONNXRTBackend-322"><span class="linenos">322</span></a>            <span class="c1"># Convert to numpy array with target dtype</span>
</span><span id="ONNXRTBackend-323"><a href="#ONNXRTBackend-323"><span class="linenos">323</span></a>            <span class="n">img_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">image</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.0</span>
</span><span id="ONNXRTBackend-324"><a href="#ONNXRTBackend-324"><span class="linenos">324</span></a>
</span><span id="ONNXRTBackend-325"><a href="#ONNXRTBackend-325"><span class="linenos">325</span></a>            <span class="c1"># Normalize with ImageNet stats</span>
</span><span id="ONNXRTBackend-326"><a href="#ONNXRTBackend-326"><span class="linenos">326</span></a>            <span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.48145466</span><span class="p">,</span> <span class="mf">0.4578275</span><span class="p">,</span> <span class="mf">0.40821073</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="ONNXRTBackend-327"><a href="#ONNXRTBackend-327"><span class="linenos">327</span></a>            <span class="n">std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.26862954</span><span class="p">,</span> <span class="mf">0.26130258</span><span class="p">,</span> <span class="mf">0.27577711</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="ONNXRTBackend-328"><a href="#ONNXRTBackend-328"><span class="linenos">328</span></a>
</span><span id="ONNXRTBackend-329"><a href="#ONNXRTBackend-329"><span class="linenos">329</span></a>            <span class="n">img_array</span> <span class="o">=</span> <span class="p">(</span><span class="n">img_array</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">std</span>
</span><span id="ONNXRTBackend-330"><a href="#ONNXRTBackend-330"><span class="linenos">330</span></a>
</span><span id="ONNXRTBackend-331"><a href="#ONNXRTBackend-331"><span class="linenos">331</span></a>            <span class="c1"># CHW format and add batch dimension</span>
</span><span id="ONNXRTBackend-332"><a href="#ONNXRTBackend-332"><span class="linenos">332</span></a>            <span class="n">img_array</span> <span class="o">=</span> <span class="n">img_array</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># HWC -&gt; CHW</span>
</span><span id="ONNXRTBackend-333"><a href="#ONNXRTBackend-333"><span class="linenos">333</span></a>            <span class="n">img_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">img_array</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Add batch dim</span>
</span><span id="ONNXRTBackend-334"><a href="#ONNXRTBackend-334"><span class="linenos">334</span></a>
</span><span id="ONNXRTBackend-335"><a href="#ONNXRTBackend-335"><span class="linenos">335</span></a>            <span class="c1"># Convert to target dtype (fp16 or fp32)</span>
</span><span id="ONNXRTBackend-336"><a href="#ONNXRTBackend-336"><span class="linenos">336</span></a>            <span class="n">img_array</span> <span class="o">=</span> <span class="n">img_array</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">target_dtype</span><span class="p">)</span>
</span><span id="ONNXRTBackend-337"><a href="#ONNXRTBackend-337"><span class="linenos">337</span></a>
</span><span id="ONNXRTBackend-338"><a href="#ONNXRTBackend-338"><span class="linenos">338</span></a>            <span class="k">return</span> <span class="n">img_array</span>
</span><span id="ONNXRTBackend-339"><a href="#ONNXRTBackend-339"><span class="linenos">339</span></a>
</span><span id="ONNXRTBackend-340"><a href="#ONNXRTBackend-340"><span class="linenos">340</span></a>        <span class="k">return</span> <span class="n">preprocess</span>
</span><span id="ONNXRTBackend-341"><a href="#ONNXRTBackend-341"><span class="linenos">341</span></a>
</span><span id="ONNXRTBackend-342"><a href="#ONNXRTBackend-342"><span class="linenos">342</span></a>    <span class="nd">@override</span>
</span><span id="ONNXRTBackend-343"><a href="#ONNXRTBackend-343"><span class="linenos">343</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">text_to_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="ONNXRTBackend-344"><a href="#ONNXRTBackend-344"><span class="linenos">344</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Encode text into a unit-normalized float32 vector.&quot;&quot;&quot;</span>
</span><span id="ONNXRTBackend-345"><a href="#ONNXRTBackend-345"><span class="linenos">345</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_initialized</span><span class="p">()</span>
</span><span id="ONNXRTBackend-346"><a href="#ONNXRTBackend-346"><span class="linenos">346</span></a>
</span><span id="ONNXRTBackend-347"><a href="#ONNXRTBackend-347"><span class="linenos">347</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">text</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
</span><span id="ONNXRTBackend-348"><a href="#ONNXRTBackend-348"><span class="linenos">348</span></a>            <span class="k">raise</span> <span class="n">InvalidInputError</span><span class="p">(</span><span class="s2">&quot;text cannot be empty or whitespace only&quot;</span><span class="p">)</span>
</span><span id="ONNXRTBackend-349"><a href="#ONNXRTBackend-349"><span class="linenos">349</span></a>
</span><span id="ONNXRTBackend-350"><a href="#ONNXRTBackend-350"><span class="linenos">350</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="ONNXRTBackend-351"><a href="#ONNXRTBackend-351"><span class="linenos">351</span></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend-352"><a href="#ONNXRTBackend-352"><span class="linenos">352</span></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_text</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend-353"><a href="#ONNXRTBackend-353"><span class="linenos">353</span></a>
</span><span id="ONNXRTBackend-354"><a href="#ONNXRTBackend-354"><span class="linenos">354</span></a>            <span class="c1"># Tokenize (always int64)</span>
</span><span id="ONNXRTBackend-355"><a href="#ONNXRTBackend-355"><span class="linenos">355</span></a>            <span class="n">tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span><span class="p">([</span><span class="n">text</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_text_input_dtype</span><span class="p">)</span>
</span><span id="ONNXRTBackend-356"><a href="#ONNXRTBackend-356"><span class="linenos">356</span></a>
</span><span id="ONNXRTBackend-357"><a href="#ONNXRTBackend-357"><span class="linenos">357</span></a>            <span class="c1"># Run inference</span>
</span><span id="ONNXRTBackend-358"><a href="#ONNXRTBackend-358"><span class="linenos">358</span></a>            <span class="n">input_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_text</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
</span><span id="ONNXRTBackend-359"><a href="#ONNXRTBackend-359"><span class="linenos">359</span></a>            <span class="n">output_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_text</span><span class="o">.</span><span class="n">get_outputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
</span><span id="ONNXRTBackend-360"><a href="#ONNXRTBackend-360"><span class="linenos">360</span></a>
</span><span id="ONNXRTBackend-361"><a href="#ONNXRTBackend-361"><span class="linenos">361</span></a>            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_text</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">output_name</span><span class="p">],</span> <span class="p">{</span><span class="n">input_name</span><span class="p">:</span> <span class="n">tokens</span><span class="p">})</span>
</span><span id="ONNXRTBackend-362"><a href="#ONNXRTBackend-362"><span class="linenos">362</span></a>            <span class="n">embedding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="ONNXRTBackend-363"><a href="#ONNXRTBackend-363"><span class="linenos">363</span></a>
</span><span id="ONNXRTBackend-364"><a href="#ONNXRTBackend-364"><span class="linenos">364</span></a>            <span class="c1"># Normalize</span>
</span><span id="ONNXRTBackend-365"><a href="#ONNXRTBackend-365"><span class="linenos">365</span></a>            <span class="n">embedding</span> <span class="o">=</span> <span class="p">(</span><span class="n">embedding</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">embedding</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="ONNXRTBackend-366"><a href="#ONNXRTBackend-366"><span class="linenos">366</span></a>
</span><span id="ONNXRTBackend-367"><a href="#ONNXRTBackend-367"><span class="linenos">367</span></a>            <span class="k">return</span> <span class="n">embedding</span>
</span><span id="ONNXRTBackend-368"><a href="#ONNXRTBackend-368"><span class="linenos">368</span></a>
</span><span id="ONNXRTBackend-369"><a href="#ONNXRTBackend-369"><span class="linenos">369</span></a>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="ONNXRTBackend-370"><a href="#ONNXRTBackend-370"><span class="linenos">370</span></a>            <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Text encoding failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span><span id="ONNXRTBackend-371"><a href="#ONNXRTBackend-371"><span class="linenos">371</span></a>
</span><span id="ONNXRTBackend-372"><a href="#ONNXRTBackend-372"><span class="linenos">372</span></a>    <span class="nd">@override</span>
</span><span id="ONNXRTBackend-373"><a href="#ONNXRTBackend-373"><span class="linenos">373</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">image_to_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_bytes</span><span class="p">:</span> <span class="nb">bytes</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="ONNXRTBackend-374"><a href="#ONNXRTBackend-374"><span class="linenos">374</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Encode image bytes into a unit-normalized float32 vector.&quot;&quot;&quot;</span>
</span><span id="ONNXRTBackend-375"><a href="#ONNXRTBackend-375"><span class="linenos">375</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_initialized</span><span class="p">()</span>
</span><span id="ONNXRTBackend-376"><a href="#ONNXRTBackend-376"><span class="linenos">376</span></a>
</span><span id="ONNXRTBackend-377"><a href="#ONNXRTBackend-377"><span class="linenos">377</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">image_bytes</span><span class="p">:</span>
</span><span id="ONNXRTBackend-378"><a href="#ONNXRTBackend-378"><span class="linenos">378</span></a>            <span class="k">raise</span> <span class="n">InvalidInputError</span><span class="p">(</span><span class="s2">&quot;image_bytes cannot be empty&quot;</span><span class="p">)</span>
</span><span id="ONNXRTBackend-379"><a href="#ONNXRTBackend-379"><span class="linenos">379</span></a>
</span><span id="ONNXRTBackend-380"><a href="#ONNXRTBackend-380"><span class="linenos">380</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="ONNXRTBackend-381"><a href="#ONNXRTBackend-381"><span class="linenos">381</span></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_image_preprocessor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend-382"><a href="#ONNXRTBackend-382"><span class="linenos">382</span></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_vision</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend-383"><a href="#ONNXRTBackend-383"><span class="linenos">383</span></a>
</span><span id="ONNXRTBackend-384"><a href="#ONNXRTBackend-384"><span class="linenos">384</span></a>            <span class="c1"># Decode and preprocess image</span>
</span><span id="ONNXRTBackend-385"><a href="#ONNXRTBackend-385"><span class="linenos">385</span></a>            <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">image_bytes</span><span class="p">))</span>
</span><span id="ONNXRTBackend-386"><a href="#ONNXRTBackend-386"><span class="linenos">386</span></a>            <span class="n">img_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_image_preprocessor</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</span><span id="ONNXRTBackend-387"><a href="#ONNXRTBackend-387"><span class="linenos">387</span></a>
</span><span id="ONNXRTBackend-388"><a href="#ONNXRTBackend-388"><span class="linenos">388</span></a>            <span class="c1"># Run inference</span>
</span><span id="ONNXRTBackend-389"><a href="#ONNXRTBackend-389"><span class="linenos">389</span></a>            <span class="n">input_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_vision</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
</span><span id="ONNXRTBackend-390"><a href="#ONNXRTBackend-390"><span class="linenos">390</span></a>            <span class="n">output_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_vision</span><span class="o">.</span><span class="n">get_outputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
</span><span id="ONNXRTBackend-391"><a href="#ONNXRTBackend-391"><span class="linenos">391</span></a>
</span><span id="ONNXRTBackend-392"><a href="#ONNXRTBackend-392"><span class="linenos">392</span></a>            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_vision</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">output_name</span><span class="p">],</span> <span class="p">{</span><span class="n">input_name</span><span class="p">:</span> <span class="n">img_tensor</span><span class="p">})</span>
</span><span id="ONNXRTBackend-393"><a href="#ONNXRTBackend-393"><span class="linenos">393</span></a>            <span class="n">embedding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="ONNXRTBackend-394"><a href="#ONNXRTBackend-394"><span class="linenos">394</span></a>
</span><span id="ONNXRTBackend-395"><a href="#ONNXRTBackend-395"><span class="linenos">395</span></a>            <span class="c1"># Normalize</span>
</span><span id="ONNXRTBackend-396"><a href="#ONNXRTBackend-396"><span class="linenos">396</span></a>            <span class="n">embedding</span> <span class="o">=</span> <span class="p">(</span><span class="n">embedding</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">embedding</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="ONNXRTBackend-397"><a href="#ONNXRTBackend-397"><span class="linenos">397</span></a>
</span><span id="ONNXRTBackend-398"><a href="#ONNXRTBackend-398"><span class="linenos">398</span></a>            <span class="k">return</span> <span class="n">embedding</span>
</span><span id="ONNXRTBackend-399"><a href="#ONNXRTBackend-399"><span class="linenos">399</span></a>
</span><span id="ONNXRTBackend-400"><a href="#ONNXRTBackend-400"><span class="linenos">400</span></a>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="ONNXRTBackend-401"><a href="#ONNXRTBackend-401"><span class="linenos">401</span></a>            <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Image encoding failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span><span id="ONNXRTBackend-402"><a href="#ONNXRTBackend-402"><span class="linenos">402</span></a>
</span><span id="ONNXRTBackend-403"><a href="#ONNXRTBackend-403"><span class="linenos">403</span></a>    <span class="nd">@override</span>
</span><span id="ONNXRTBackend-404"><a href="#ONNXRTBackend-404"><span class="linenos">404</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">image_batch_to_vectors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">bytes</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="ONNXRTBackend-405"><a href="#ONNXRTBackend-405"><span class="linenos">405</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Encode a batch of images using batched ONNX inference.&quot;&quot;&quot;</span>
</span><span id="ONNXRTBackend-406"><a href="#ONNXRTBackend-406"><span class="linenos">406</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">images</span><span class="p">:</span>
</span><span id="ONNXRTBackend-407"><a href="#ONNXRTBackend-407"><span class="linenos">407</span></a>            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="ONNXRTBackend-408"><a href="#ONNXRTBackend-408"><span class="linenos">408</span></a>
</span><span id="ONNXRTBackend-409"><a href="#ONNXRTBackend-409"><span class="linenos">409</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_initialized</span><span class="p">()</span>
</span><span id="ONNXRTBackend-410"><a href="#ONNXRTBackend-410"><span class="linenos">410</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_image_preprocessor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend-411"><a href="#ONNXRTBackend-411"><span class="linenos">411</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_vision</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend-412"><a href="#ONNXRTBackend-412"><span class="linenos">412</span></a>
</span><span id="ONNXRTBackend-413"><a href="#ONNXRTBackend-413"><span class="linenos">413</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="ONNXRTBackend-414"><a href="#ONNXRTBackend-414"><span class="linenos">414</span></a>            <span class="c1"># Preprocess all images</span>
</span><span id="ONNXRTBackend-415"><a href="#ONNXRTBackend-415"><span class="linenos">415</span></a>            <span class="n">img_tensors</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="ONNXRTBackend-416"><a href="#ONNXRTBackend-416"><span class="linenos">416</span></a>            <span class="k">for</span> <span class="n">img_bytes</span> <span class="ow">in</span> <span class="n">images</span><span class="p">:</span>
</span><span id="ONNXRTBackend-417"><a href="#ONNXRTBackend-417"><span class="linenos">417</span></a>                <span class="k">if</span> <span class="ow">not</span> <span class="n">img_bytes</span><span class="p">:</span>
</span><span id="ONNXRTBackend-418"><a href="#ONNXRTBackend-418"><span class="linenos">418</span></a>                    <span class="k">raise</span> <span class="n">InvalidInputError</span><span class="p">(</span><span class="s2">&quot;image bytes cannot be empty&quot;</span><span class="p">)</span>
</span><span id="ONNXRTBackend-419"><a href="#ONNXRTBackend-419"><span class="linenos">419</span></a>                <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">img_bytes</span><span class="p">))</span>
</span><span id="ONNXRTBackend-420"><a href="#ONNXRTBackend-420"><span class="linenos">420</span></a>                <span class="n">img_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_image_preprocessor</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</span><span id="ONNXRTBackend-421"><a href="#ONNXRTBackend-421"><span class="linenos">421</span></a>                <span class="n">img_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">img_tensor</span><span class="p">)</span>
</span><span id="ONNXRTBackend-422"><a href="#ONNXRTBackend-422"><span class="linenos">422</span></a>
</span><span id="ONNXRTBackend-423"><a href="#ONNXRTBackend-423"><span class="linenos">423</span></a>            <span class="c1"># Stack into batch</span>
</span><span id="ONNXRTBackend-424"><a href="#ONNXRTBackend-424"><span class="linenos">424</span></a>            <span class="n">batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">img_tensors</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="ONNXRTBackend-425"><a href="#ONNXRTBackend-425"><span class="linenos">425</span></a>
</span><span id="ONNXRTBackend-426"><a href="#ONNXRTBackend-426"><span class="linenos">426</span></a>            <span class="c1"># Run batched inference</span>
</span><span id="ONNXRTBackend-427"><a href="#ONNXRTBackend-427"><span class="linenos">427</span></a>            <span class="n">input_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_vision</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
</span><span id="ONNXRTBackend-428"><a href="#ONNXRTBackend-428"><span class="linenos">428</span></a>            <span class="n">output_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_vision</span><span class="o">.</span><span class="n">get_outputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
</span><span id="ONNXRTBackend-429"><a href="#ONNXRTBackend-429"><span class="linenos">429</span></a>
</span><span id="ONNXRTBackend-430"><a href="#ONNXRTBackend-430"><span class="linenos">430</span></a>            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_vision</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">output_name</span><span class="p">],</span> <span class="p">{</span><span class="n">input_name</span><span class="p">:</span> <span class="n">batch</span><span class="p">})</span>
</span><span id="ONNXRTBackend-431"><a href="#ONNXRTBackend-431"><span class="linenos">431</span></a>            <span class="n">embeddings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="ONNXRTBackend-432"><a href="#ONNXRTBackend-432"><span class="linenos">432</span></a>
</span><span id="ONNXRTBackend-433"><a href="#ONNXRTBackend-433"><span class="linenos">433</span></a>            <span class="c1"># Normalize each vector</span>
</span><span id="ONNXRTBackend-434"><a href="#ONNXRTBackend-434"><span class="linenos">434</span></a>            <span class="n">norms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="ONNXRTBackend-435"><a href="#ONNXRTBackend-435"><span class="linenos">435</span></a>            <span class="n">embeddings</span> <span class="o">=</span> <span class="n">embeddings</span> <span class="o">/</span> <span class="n">norms</span>
</span><span id="ONNXRTBackend-436"><a href="#ONNXRTBackend-436"><span class="linenos">436</span></a>
</span><span id="ONNXRTBackend-437"><a href="#ONNXRTBackend-437"><span class="linenos">437</span></a>            <span class="k">return</span> <span class="n">embeddings</span>
</span><span id="ONNXRTBackend-438"><a href="#ONNXRTBackend-438"><span class="linenos">438</span></a>
</span><span id="ONNXRTBackend-439"><a href="#ONNXRTBackend-439"><span class="linenos">439</span></a>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="ONNXRTBackend-440"><a href="#ONNXRTBackend-440"><span class="linenos">440</span></a>            <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Batch image encoding failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span><span id="ONNXRTBackend-441"><a href="#ONNXRTBackend-441"><span class="linenos">441</span></a>
</span><span id="ONNXRTBackend-442"><a href="#ONNXRTBackend-442"><span class="linenos">442</span></a>    <span class="nd">@override</span>
</span><span id="ONNXRTBackend-443"><a href="#ONNXRTBackend-443"><span class="linenos">443</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">text_batch_to_vectors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">texts</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="ONNXRTBackend-444"><a href="#ONNXRTBackend-444"><span class="linenos">444</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Encode a batch of texts using batched ONNX inference.&quot;&quot;&quot;</span>
</span><span id="ONNXRTBackend-445"><a href="#ONNXRTBackend-445"><span class="linenos">445</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">texts</span><span class="p">:</span>
</span><span id="ONNXRTBackend-446"><a href="#ONNXRTBackend-446"><span class="linenos">446</span></a>            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="ONNXRTBackend-447"><a href="#ONNXRTBackend-447"><span class="linenos">447</span></a>
</span><span id="ONNXRTBackend-448"><a href="#ONNXRTBackend-448"><span class="linenos">448</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_initialized</span><span class="p">()</span>
</span><span id="ONNXRTBackend-449"><a href="#ONNXRTBackend-449"><span class="linenos">449</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend-450"><a href="#ONNXRTBackend-450"><span class="linenos">450</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_text</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend-451"><a href="#ONNXRTBackend-451"><span class="linenos">451</span></a>
</span><span id="ONNXRTBackend-452"><a href="#ONNXRTBackend-452"><span class="linenos">452</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="ONNXRTBackend-453"><a href="#ONNXRTBackend-453"><span class="linenos">453</span></a>            <span class="c1"># Validate inputs</span>
</span><span id="ONNXRTBackend-454"><a href="#ONNXRTBackend-454"><span class="linenos">454</span></a>            <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">:</span>
</span><span id="ONNXRTBackend-455"><a href="#ONNXRTBackend-455"><span class="linenos">455</span></a>                <span class="k">if</span> <span class="ow">not</span> <span class="n">text</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
</span><span id="ONNXRTBackend-456"><a href="#ONNXRTBackend-456"><span class="linenos">456</span></a>                    <span class="k">raise</span> <span class="n">InvalidInputError</span><span class="p">(</span><span class="s2">&quot;text cannot be empty or whitespace only&quot;</span><span class="p">)</span>
</span><span id="ONNXRTBackend-457"><a href="#ONNXRTBackend-457"><span class="linenos">457</span></a>
</span><span id="ONNXRTBackend-458"><a href="#ONNXRTBackend-458"><span class="linenos">458</span></a>            <span class="c1"># Tokenize all texts (always int64)</span>
</span><span id="ONNXRTBackend-459"><a href="#ONNXRTBackend-459"><span class="linenos">459</span></a>            <span class="n">tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">texts</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_text_input_dtype</span><span class="p">)</span>
</span><span id="ONNXRTBackend-460"><a href="#ONNXRTBackend-460"><span class="linenos">460</span></a>
</span><span id="ONNXRTBackend-461"><a href="#ONNXRTBackend-461"><span class="linenos">461</span></a>            <span class="c1"># Run batched inference</span>
</span><span id="ONNXRTBackend-462"><a href="#ONNXRTBackend-462"><span class="linenos">462</span></a>            <span class="n">input_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_text</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
</span><span id="ONNXRTBackend-463"><a href="#ONNXRTBackend-463"><span class="linenos">463</span></a>            <span class="n">output_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_text</span><span class="o">.</span><span class="n">get_outputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
</span><span id="ONNXRTBackend-464"><a href="#ONNXRTBackend-464"><span class="linenos">464</span></a>
</span><span id="ONNXRTBackend-465"><a href="#ONNXRTBackend-465"><span class="linenos">465</span></a>            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_text</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">output_name</span><span class="p">],</span> <span class="p">{</span><span class="n">input_name</span><span class="p">:</span> <span class="n">tokens</span><span class="p">})</span>
</span><span id="ONNXRTBackend-466"><a href="#ONNXRTBackend-466"><span class="linenos">466</span></a>            <span class="n">embeddings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="ONNXRTBackend-467"><a href="#ONNXRTBackend-467"><span class="linenos">467</span></a>
</span><span id="ONNXRTBackend-468"><a href="#ONNXRTBackend-468"><span class="linenos">468</span></a>            <span class="c1"># Normalize each vector</span>
</span><span id="ONNXRTBackend-469"><a href="#ONNXRTBackend-469"><span class="linenos">469</span></a>            <span class="n">norms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="ONNXRTBackend-470"><a href="#ONNXRTBackend-470"><span class="linenos">470</span></a>            <span class="n">embeddings</span> <span class="o">=</span> <span class="n">embeddings</span> <span class="o">/</span> <span class="n">norms</span>
</span><span id="ONNXRTBackend-471"><a href="#ONNXRTBackend-471"><span class="linenos">471</span></a>
</span><span id="ONNXRTBackend-472"><a href="#ONNXRTBackend-472"><span class="linenos">472</span></a>            <span class="k">return</span> <span class="n">embeddings</span>
</span><span id="ONNXRTBackend-473"><a href="#ONNXRTBackend-473"><span class="linenos">473</span></a>
</span><span id="ONNXRTBackend-474"><a href="#ONNXRTBackend-474"><span class="linenos">474</span></a>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="ONNXRTBackend-475"><a href="#ONNXRTBackend-475"><span class="linenos">475</span></a>            <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Batch text encoding failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span><span id="ONNXRTBackend-476"><a href="#ONNXRTBackend-476"><span class="linenos">476</span></a>
</span><span id="ONNXRTBackend-477"><a href="#ONNXRTBackend-477"><span class="linenos">477</span></a>    <span class="nd">@override</span>
</span><span id="ONNXRTBackend-478"><a href="#ONNXRTBackend-478"><span class="linenos">478</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_info</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BackendInfo</span><span class="p">:</span>
</span><span id="ONNXRTBackend-479"><a href="#ONNXRTBackend-479"><span class="linenos">479</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Report ONNX Runtime metadata and configuration.&quot;&quot;&quot;</span>
</span><span id="ONNXRTBackend-480"><a href="#ONNXRTBackend-480"><span class="linenos">480</span></a>        <span class="n">version</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">ort</span><span class="p">,</span> <span class="s2">&quot;__version__&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span><span id="ONNXRTBackend-481"><a href="#ONNXRTBackend-481"><span class="linenos">481</span></a>        <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_infer_device_from_providers</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_providers</span><span class="p">)</span>
</span><span id="ONNXRTBackend-482"><a href="#ONNXRTBackend-482"><span class="linenos">482</span></a>
</span><span id="ONNXRTBackend-483"><a href="#ONNXRTBackend-483"><span class="linenos">483</span></a>        <span class="c1"># Get embedding dimension from resources</span>
</span><span id="ONNXRTBackend-484"><a href="#ONNXRTBackend-484"><span class="linenos">484</span></a>        <span class="n">embed_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">get_embedding_dim</span><span class="p">()</span>
</span><span id="ONNXRTBackend-485"><a href="#ONNXRTBackend-485"><span class="linenos">485</span></a>
</span><span id="ONNXRTBackend-486"><a href="#ONNXRTBackend-486"><span class="linenos">486</span></a>        <span class="c1"># Get image size from resources</span>
</span><span id="ONNXRTBackend-487"><a href="#ONNXRTBackend-487"><span class="linenos">487</span></a>        <span class="n">image_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">get_image_size</span><span class="p">()</span>
</span><span id="ONNXRTBackend-488"><a href="#ONNXRTBackend-488"><span class="linenos">488</span></a>        <span class="n">image_size_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">image_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">x</span><span class="si">{</span><span class="n">image_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">if</span> <span class="n">image_size</span> <span class="k">else</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend-489"><a href="#ONNXRTBackend-489"><span class="linenos">489</span></a>
</span><span id="ONNXRTBackend-490"><a href="#ONNXRTBackend-490"><span class="linenos">490</span></a>        <span class="c1"># Determine precision list</span>
</span><span id="ONNXRTBackend-491"><a href="#ONNXRTBackend-491"><span class="linenos">491</span></a>        <span class="n">precisions</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_vision_precision</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_text_precision</span><span class="p">]))</span>
</span><span id="ONNXRTBackend-492"><a href="#ONNXRTBackend-492"><span class="linenos">492</span></a>        <span class="k">if</span> <span class="s2">&quot;unknown&quot;</span> <span class="ow">in</span> <span class="n">precisions</span><span class="p">:</span>
</span><span id="ONNXRTBackend-493"><a href="#ONNXRTBackend-493"><span class="linenos">493</span></a>            <span class="n">precisions</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s2">&quot;unknown&quot;</span><span class="p">)</span>
</span><span id="ONNXRTBackend-494"><a href="#ONNXRTBackend-494"><span class="linenos">494</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">precisions</span><span class="p">:</span>
</span><span id="ONNXRTBackend-495"><a href="#ONNXRTBackend-495"><span class="linenos">495</span></a>            <span class="n">precisions</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;fp32&quot;</span><span class="p">]</span>
</span><span id="ONNXRTBackend-496"><a href="#ONNXRTBackend-496"><span class="linenos">496</span></a>
</span><span id="ONNXRTBackend-497"><a href="#ONNXRTBackend-497"><span class="linenos">497</span></a>        <span class="k">return</span> <span class="n">BackendInfo</span><span class="p">(</span>
</span><span id="ONNXRTBackend-498"><a href="#ONNXRTBackend-498"><span class="linenos">498</span></a>            <span class="n">runtime</span><span class="o">=</span><span class="s2">&quot;onnx&quot;</span><span class="p">,</span>
</span><span id="ONNXRTBackend-499"><a href="#ONNXRTBackend-499"><span class="linenos">499</span></a>            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
</span><span id="ONNXRTBackend-500"><a href="#ONNXRTBackend-500"><span class="linenos">500</span></a>            <span class="n">model_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span>
</span><span id="ONNXRTBackend-501"><a href="#ONNXRTBackend-501"><span class="linenos">501</span></a>            <span class="n">model_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
</span><span id="ONNXRTBackend-502"><a href="#ONNXRTBackend-502"><span class="linenos">502</span></a>                <span class="s2">&quot;model_name&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">model_name</span>
</span><span id="ONNXRTBackend-503"><a href="#ONNXRTBackend-503"><span class="linenos">503</span></a>            <span class="p">),</span>
</span><span id="ONNXRTBackend-504"><a href="#ONNXRTBackend-504"><span class="linenos">504</span></a>            <span class="n">pretrained</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># Local weights</span>
</span><span id="ONNXRTBackend-505"><a href="#ONNXRTBackend-505"><span class="linenos">505</span></a>            <span class="n">version</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">version</span><span class="p">)</span> <span class="k">if</span> <span class="n">version</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="ONNXRTBackend-506"><a href="#ONNXRTBackend-506"><span class="linenos">506</span></a>            <span class="n">image_embedding_dim</span><span class="o">=</span><span class="n">embed_dim</span><span class="p">,</span>
</span><span id="ONNXRTBackend-507"><a href="#ONNXRTBackend-507"><span class="linenos">507</span></a>            <span class="n">text_embedding_dim</span><span class="o">=</span><span class="n">embed_dim</span><span class="p">,</span>
</span><span id="ONNXRTBackend-508"><a href="#ONNXRTBackend-508"><span class="linenos">508</span></a>            <span class="n">precisions</span><span class="o">=</span><span class="n">precisions</span><span class="p">,</span>
</span><span id="ONNXRTBackend-509"><a href="#ONNXRTBackend-509"><span class="linenos">509</span></a>            <span class="n">max_batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_max_batch_size</span><span class="p">,</span>
</span><span id="ONNXRTBackend-510"><a href="#ONNXRTBackend-510"><span class="linenos">510</span></a>            <span class="n">supports_image_batch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="ONNXRTBackend-511"><a href="#ONNXRTBackend-511"><span class="linenos">511</span></a>            <span class="n">extra</span><span class="o">=</span><span class="p">{</span>
</span><span id="ONNXRTBackend-512"><a href="#ONNXRTBackend-512"><span class="linenos">512</span></a>                <span class="s2">&quot;providers&quot;</span><span class="p">:</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_providers</span><span class="p">),</span>
</span><span id="ONNXRTBackend-513"><a href="#ONNXRTBackend-513"><span class="linenos">513</span></a>                <span class="s2">&quot;image_size&quot;</span><span class="p">:</span> <span class="n">image_size_str</span><span class="p">,</span>
</span><span id="ONNXRTBackend-514"><a href="#ONNXRTBackend-514"><span class="linenos">514</span></a>                <span class="s2">&quot;vision_precision&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vision_precision</span><span class="p">,</span>
</span><span id="ONNXRTBackend-515"><a href="#ONNXRTBackend-515"><span class="linenos">515</span></a>                <span class="s2">&quot;text_precision&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_text_precision</span><span class="p">,</span>
</span><span id="ONNXRTBackend-516"><a href="#ONNXRTBackend-516"><span class="linenos">516</span></a>                <span class="s2">&quot;vision_input_dtype&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_vision_input_dtype</span><span class="p">),</span>
</span><span id="ONNXRTBackend-517"><a href="#ONNXRTBackend-517"><span class="linenos">517</span></a>                <span class="s2">&quot;text_input_dtype&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_text_input_dtype</span><span class="p">),</span>
</span><span id="ONNXRTBackend-518"><a href="#ONNXRTBackend-518"><span class="linenos">518</span></a>            <span class="p">},</span>
</span><span id="ONNXRTBackend-519"><a href="#ONNXRTBackend-519"><span class="linenos">519</span></a>        <span class="p">)</span>
</span><span id="ONNXRTBackend-520"><a href="#ONNXRTBackend-520"><span class="linenos">520</span></a>
</span><span id="ONNXRTBackend-521"><a href="#ONNXRTBackend-521"><span class="linenos">521</span></a>    <span class="nd">@staticmethod</span>
</span><span id="ONNXRTBackend-522"><a href="#ONNXRTBackend-522"><span class="linenos">522</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_default_providers</span><span class="p">(</span><span class="n">device_pref</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
</span><span id="ONNXRTBackend-523"><a href="#ONNXRTBackend-523"><span class="linenos">523</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Select default ONNX Runtime providers based on device preference.&quot;&quot;&quot;</span>
</span><span id="ONNXRTBackend-524"><a href="#ONNXRTBackend-524"><span class="linenos">524</span></a>        <span class="n">pref</span> <span class="o">=</span> <span class="p">(</span><span class="n">device_pref</span> <span class="ow">or</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
</span><span id="ONNXRTBackend-525"><a href="#ONNXRTBackend-525"><span class="linenos">525</span></a>
</span><span id="ONNXRTBackend-526"><a href="#ONNXRTBackend-526"><span class="linenos">526</span></a>        <span class="k">if</span> <span class="n">pref</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
</span><span id="ONNXRTBackend-527"><a href="#ONNXRTBackend-527"><span class="linenos">527</span></a>            <span class="k">return</span> <span class="p">[</span><span class="s2">&quot;CUDAExecutionProvider&quot;</span><span class="p">,</span> <span class="s2">&quot;CPUExecutionProvider&quot;</span><span class="p">]</span>
</span><span id="ONNXRTBackend-528"><a href="#ONNXRTBackend-528"><span class="linenos">528</span></a>        <span class="k">if</span> <span class="n">pref</span> <span class="o">==</span> <span class="s2">&quot;coreml&quot;</span><span class="p">:</span>
</span><span id="ONNXRTBackend-529"><a href="#ONNXRTBackend-529"><span class="linenos">529</span></a>            <span class="k">return</span> <span class="p">[</span><span class="s2">&quot;CoreMLExecutionProvider&quot;</span><span class="p">,</span> <span class="s2">&quot;CPUExecutionProvider&quot;</span><span class="p">]</span>
</span><span id="ONNXRTBackend-530"><a href="#ONNXRTBackend-530"><span class="linenos">530</span></a>        <span class="k">if</span> <span class="n">pref</span> <span class="o">==</span> <span class="s2">&quot;directml&quot;</span><span class="p">:</span>
</span><span id="ONNXRTBackend-531"><a href="#ONNXRTBackend-531"><span class="linenos">531</span></a>            <span class="k">return</span> <span class="p">[</span><span class="s2">&quot;DmlExecutionProvider&quot;</span><span class="p">,</span> <span class="s2">&quot;CPUExecutionProvider&quot;</span><span class="p">]</span>
</span><span id="ONNXRTBackend-532"><a href="#ONNXRTBackend-532"><span class="linenos">532</span></a>        <span class="k">if</span> <span class="n">pref</span> <span class="o">==</span> <span class="s2">&quot;openvino&quot;</span><span class="p">:</span>
</span><span id="ONNXRTBackend-533"><a href="#ONNXRTBackend-533"><span class="linenos">533</span></a>            <span class="k">return</span> <span class="p">[</span><span class="s2">&quot;OpenVINOExecutionProvider&quot;</span><span class="p">,</span> <span class="s2">&quot;CPUExecutionProvider&quot;</span><span class="p">]</span>
</span><span id="ONNXRTBackend-534"><a href="#ONNXRTBackend-534"><span class="linenos">534</span></a>
</span><span id="ONNXRTBackend-535"><a href="#ONNXRTBackend-535"><span class="linenos">535</span></a>        <span class="c1"># Default: CPU only</span>
</span><span id="ONNXRTBackend-536"><a href="#ONNXRTBackend-536"><span class="linenos">536</span></a>        <span class="k">return</span> <span class="p">[</span><span class="s2">&quot;CPUExecutionProvider&quot;</span><span class="p">]</span>
</span><span id="ONNXRTBackend-537"><a href="#ONNXRTBackend-537"><span class="linenos">537</span></a>
</span><span id="ONNXRTBackend-538"><a href="#ONNXRTBackend-538"><span class="linenos">538</span></a>    <span class="nd">@staticmethod</span>
</span><span id="ONNXRTBackend-539"><a href="#ONNXRTBackend-539"><span class="linenos">539</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_infer_device_from_providers</span><span class="p">(</span><span class="n">providers</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="ONNXRTBackend-540"><a href="#ONNXRTBackend-540"><span class="linenos">540</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Infer device string from provider list.&quot;&quot;&quot;</span>
</span><span id="ONNXRTBackend-541"><a href="#ONNXRTBackend-541"><span class="linenos">541</span></a>        <span class="n">provs</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">providers</span><span class="p">]</span>
</span><span id="ONNXRTBackend-542"><a href="#ONNXRTBackend-542"><span class="linenos">542</span></a>
</span><span id="ONNXRTBackend-543"><a href="#ONNXRTBackend-543"><span class="linenos">543</span></a>        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="ow">in</span> <span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">provs</span><span class="p">):</span>
</span><span id="ONNXRTBackend-544"><a href="#ONNXRTBackend-544"><span class="linenos">544</span></a>            <span class="k">return</span> <span class="s2">&quot;cuda&quot;</span>
</span><span id="ONNXRTBackend-545"><a href="#ONNXRTBackend-545"><span class="linenos">545</span></a>        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="s2">&quot;coreml&quot;</span> <span class="ow">in</span> <span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">provs</span><span class="p">):</span>
</span><span id="ONNXRTBackend-546"><a href="#ONNXRTBackend-546"><span class="linenos">546</span></a>            <span class="k">return</span> <span class="s2">&quot;coreml&quot;</span>
</span><span id="ONNXRTBackend-547"><a href="#ONNXRTBackend-547"><span class="linenos">547</span></a>        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="s2">&quot;dml&quot;</span> <span class="ow">in</span> <span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">provs</span><span class="p">):</span>
</span><span id="ONNXRTBackend-548"><a href="#ONNXRTBackend-548"><span class="linenos">548</span></a>            <span class="k">return</span> <span class="s2">&quot;directml&quot;</span>
</span><span id="ONNXRTBackend-549"><a href="#ONNXRTBackend-549"><span class="linenos">549</span></a>        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="s2">&quot;openvino&quot;</span> <span class="ow">in</span> <span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">provs</span><span class="p">):</span>
</span><span id="ONNXRTBackend-550"><a href="#ONNXRTBackend-550"><span class="linenos">550</span></a>            <span class="k">return</span> <span class="s2">&quot;openvino&quot;</span>
</span><span id="ONNXRTBackend-551"><a href="#ONNXRTBackend-551"><span class="linenos">551</span></a>
</span><span id="ONNXRTBackend-552"><a href="#ONNXRTBackend-552"><span class="linenos">552</span></a>        <span class="k">return</span> <span class="s2">&quot;cpu&quot;</span>
</span><span id="ONNXRTBackend-553"><a href="#ONNXRTBackend-553"><span class="linenos">553</span></a>
</span><span id="ONNXRTBackend-554"><a href="#ONNXRTBackend-554"><span class="linenos">554</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_ensure_initialized</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ONNXRTBackend-555"><a href="#ONNXRTBackend-555"><span class="linenos">555</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Ensure backend is initialized before inference.&quot;&quot;&quot;</span>
</span><span id="ONNXRTBackend-556"><a href="#ONNXRTBackend-556"><span class="linenos">556</span></a>        <span class="k">if</span> <span class="p">(</span>
</span><span id="ONNXRTBackend-557"><a href="#ONNXRTBackend-557"><span class="linenos">557</span></a>            <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span>
</span><span id="ONNXRTBackend-558"><a href="#ONNXRTBackend-558"><span class="linenos">558</span></a>            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_vision</span> <span class="ow">is</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend-559"><a href="#ONNXRTBackend-559"><span class="linenos">559</span></a>            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_text</span> <span class="ow">is</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend-560"><a href="#ONNXRTBackend-560"><span class="linenos">560</span></a>        <span class="p">):</span>
</span><span id="ONNXRTBackend-561"><a href="#ONNXRTBackend-561"><span class="linenos">561</span></a>            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
</span><span id="ONNXRTBackend-562"><a href="#ONNXRTBackend-562"><span class="linenos">562</span></a>                <span class="s2">&quot;ONNXRTBackend is not initialized. Call initialize() first.&quot;</span>
</span><span id="ONNXRTBackend-563"><a href="#ONNXRTBackend-563"><span class="linenos">563</span></a>            <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Abstract base for CLIP-like backends.</p>

<p>Implementations MUST:</p>

<ul>
<li>Perform model loading in initialize()</li>
<li>Produce unit-normalized float32 vectors for text/image encoding</li>
<li>Provide accurate BackendInfo via get_info()</li>
</ul>

<p>Implementations MAY:</p>

<ul>
<li>Override image_batch_to_vectors for true batched execution</li>
<li>Expose runtime-specific knobs via <code>extra</code> in BackendInfo</li>
</ul>
</div>


                            <div id="ONNXRTBackend.__init__" class="classattr">
                                        <input id="ONNXRTBackend.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">ONNXRTBackend</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">resources</span><span class="p">:</span> <span class="n"><a href="resources.html#ModelResources">lumen_clip.resources.ModelResources</a></span>,</span><span class="param">	<span class="n">providers</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">device_preference</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">max_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">prefer_fp16</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span></span>)</span>

                <label class="view-source-button" for="ONNXRTBackend.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ONNXRTBackend.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ONNXRTBackend.__init__-89"><a href="#ONNXRTBackend.__init__-89"><span class="linenos"> 89</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="ONNXRTBackend.__init__-90"><a href="#ONNXRTBackend.__init__-90"><span class="linenos"> 90</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="ONNXRTBackend.__init__-91"><a href="#ONNXRTBackend.__init__-91"><span class="linenos"> 91</span></a>        <span class="n">resources</span><span class="p">:</span> <span class="s2">&quot;ModelResources&quot;</span><span class="p">,</span>
</span><span id="ONNXRTBackend.__init__-92"><a href="#ONNXRTBackend.__init__-92"><span class="linenos"> 92</span></a>        <span class="n">providers</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="ONNXRTBackend.__init__-93"><a href="#ONNXRTBackend.__init__-93"><span class="linenos"> 93</span></a>        <span class="n">device_preference</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="ONNXRTBackend.__init__-94"><a href="#ONNXRTBackend.__init__-94"><span class="linenos"> 94</span></a>        <span class="n">max_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="ONNXRTBackend.__init__-95"><a href="#ONNXRTBackend.__init__-95"><span class="linenos"> 95</span></a>        <span class="n">prefer_fp16</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="ONNXRTBackend.__init__-96"><a href="#ONNXRTBackend.__init__-96"><span class="linenos"> 96</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ONNXRTBackend.__init__-97"><a href="#ONNXRTBackend.__init__-97"><span class="linenos"> 97</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="ONNXRTBackend.__init__-98"><a href="#ONNXRTBackend.__init__-98"><span class="linenos"> 98</span></a>            <span class="n">resources</span><span class="o">=</span><span class="n">resources</span><span class="p">,</span>
</span><span id="ONNXRTBackend.__init__-99"><a href="#ONNXRTBackend.__init__-99"><span class="linenos"> 99</span></a>            <span class="n">device_preference</span><span class="o">=</span><span class="n">device_preference</span><span class="p">,</span>
</span><span id="ONNXRTBackend.__init__-100"><a href="#ONNXRTBackend.__init__-100"><span class="linenos">100</span></a>            <span class="n">max_batch_size</span><span class="o">=</span><span class="n">max_batch_size</span><span class="p">,</span>
</span><span id="ONNXRTBackend.__init__-101"><a href="#ONNXRTBackend.__init__-101"><span class="linenos">101</span></a>        <span class="p">)</span>
</span><span id="ONNXRTBackend.__init__-102"><a href="#ONNXRTBackend.__init__-102"><span class="linenos">102</span></a>
</span><span id="ONNXRTBackend.__init__-103"><a href="#ONNXRTBackend.__init__-103"><span class="linenos">103</span></a>        <span class="c1"># Execution providers</span>
</span><span id="ONNXRTBackend.__init__-104"><a href="#ONNXRTBackend.__init__-104"><span class="linenos">104</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_providers</span> <span class="o">=</span> <span class="n">providers</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_default_providers</span><span class="p">(</span><span class="n">device_preference</span><span class="p">)</span>
</span><span id="ONNXRTBackend.__init__-105"><a href="#ONNXRTBackend.__init__-105"><span class="linenos">105</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_prefer_fp16</span> <span class="o">=</span> <span class="n">prefer_fp16</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_gpu_available</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_providers</span><span class="p">)</span>
</span><span id="ONNXRTBackend.__init__-106"><a href="#ONNXRTBackend.__init__-106"><span class="linenos">106</span></a>
</span><span id="ONNXRTBackend.__init__-107"><a href="#ONNXRTBackend.__init__-107"><span class="linenos">107</span></a>        <span class="c1"># Runtime objects</span>
</span><span id="ONNXRTBackend.__init__-108"><a href="#ONNXRTBackend.__init__-108"><span class="linenos">108</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_sess_vision</span><span class="p">:</span> <span class="n">ort</span><span class="o">.</span><span class="n">InferenceSession</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend.__init__-109"><a href="#ONNXRTBackend.__init__-109"><span class="linenos">109</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_sess_text</span><span class="p">:</span> <span class="n">ort</span><span class="o">.</span><span class="n">InferenceSession</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend.__init__-110"><a href="#ONNXRTBackend.__init__-110"><span class="linenos">110</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend.__init__-111"><a href="#ONNXRTBackend.__init__-111"><span class="linenos">111</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_image_preprocessor</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend.__init__-112"><a href="#ONNXRTBackend.__init__-112"><span class="linenos">112</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_load_time_seconds</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend.__init__-113"><a href="#ONNXRTBackend.__init__-113"><span class="linenos">113</span></a>
</span><span id="ONNXRTBackend.__init__-114"><a href="#ONNXRTBackend.__init__-114"><span class="linenos">114</span></a>        <span class="c1"># Precision tracking</span>
</span><span id="ONNXRTBackend.__init__-115"><a href="#ONNXRTBackend.__init__-115"><span class="linenos">115</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_vision_precision</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;unknown&quot;</span>
</span><span id="ONNXRTBackend.__init__-116"><a href="#ONNXRTBackend.__init__-116"><span class="linenos">116</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_text_precision</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;unknown&quot;</span>
</span><span id="ONNXRTBackend.__init__-117"><a href="#ONNXRTBackend.__init__-117"><span class="linenos">117</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_vision_input_dtype</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="ONNXRTBackend.__init__-118"><a href="#ONNXRTBackend.__init__-118"><span class="linenos">118</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_text_input_dtype</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Construct a backend with model resources.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>resources:</strong>  ModelResources object containing all model files and configs</li>
<li><strong>device_preference:</strong>  Hint for device selection (e.g., "cuda", "mps", "cpu").</li>
<li><strong>max_batch_size:</strong>  Hint for batching; implementation may clamp lower/higher.</li>
</ul>
</div>


                            </div>
                            <div id="ONNXRTBackend.initialize" class="classattr">
                                        <input id="ONNXRTBackend.initialize-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-override">@override</div>

        <span class="def">def</span>
        <span class="name">initialize</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

                <label class="view-source-button" for="ONNXRTBackend.initialize-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ONNXRTBackend.initialize"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ONNXRTBackend.initialize-120"><a href="#ONNXRTBackend.initialize-120"><span class="linenos">120</span></a>    <span class="nd">@override</span>
</span><span id="ONNXRTBackend.initialize-121"><a href="#ONNXRTBackend.initialize-121"><span class="linenos">121</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ONNXRTBackend.initialize-122"><a href="#ONNXRTBackend.initialize-122"><span class="linenos">122</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Load ONNX models and prepare preprocessing.&quot;&quot;&quot;</span>
</span><span id="ONNXRTBackend.initialize-123"><a href="#ONNXRTBackend.initialize-123"><span class="linenos">123</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span><span class="p">:</span>
</span><span id="ONNXRTBackend.initialize-124"><a href="#ONNXRTBackend.initialize-124"><span class="linenos">124</span></a>            <span class="k">return</span>
</span><span id="ONNXRTBackend.initialize-125"><a href="#ONNXRTBackend.initialize-125"><span class="linenos">125</span></a>
</span><span id="ONNXRTBackend.initialize-126"><a href="#ONNXRTBackend.initialize-126"><span class="linenos">126</span></a>        <span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
</span><span id="ONNXRTBackend.initialize-127"><a href="#ONNXRTBackend.initialize-127"><span class="linenos">127</span></a>
</span><span id="ONNXRTBackend.initialize-128"><a href="#ONNXRTBackend.initialize-128"><span class="linenos">128</span></a>        <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</span><span id="ONNXRTBackend.initialize-129"><a href="#ONNXRTBackend.initialize-129"><span class="linenos">129</span></a>
</span><span id="ONNXRTBackend.initialize-130"><a href="#ONNXRTBackend.initialize-130"><span class="linenos">130</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="ONNXRTBackend.initialize-131"><a href="#ONNXRTBackend.initialize-131"><span class="linenos">131</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Initializing ONNXRTBackend for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="ONNXRTBackend.initialize-132"><a href="#ONNXRTBackend.initialize-132"><span class="linenos">132</span></a>
</span><span id="ONNXRTBackend.initialize-133"><a href="#ONNXRTBackend.initialize-133"><span class="linenos">133</span></a>            <span class="n">sess_options</span> <span class="o">=</span> <span class="n">ort</span><span class="o">.</span><span class="n">SessionOptions</span><span class="p">()</span>
</span><span id="ONNXRTBackend.initialize-134"><a href="#ONNXRTBackend.initialize-134"><span class="linenos">134</span></a>            <span class="n">sess_options</span><span class="o">.</span><span class="n">graph_optimization_level</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="ONNXRTBackend.initialize-135"><a href="#ONNXRTBackend.initialize-135"><span class="linenos">135</span></a>                <span class="n">ort</span><span class="o">.</span><span class="n">GraphOptimizationLevel</span><span class="o">.</span><span class="n">ORT_ENABLE_ALL</span>
</span><span id="ONNXRTBackend.initialize-136"><a href="#ONNXRTBackend.initialize-136"><span class="linenos">136</span></a>            <span class="p">)</span>
</span><span id="ONNXRTBackend.initialize-137"><a href="#ONNXRTBackend.initialize-137"><span class="linenos">137</span></a>
</span><span id="ONNXRTBackend.initialize-138"><a href="#ONNXRTBackend.initialize-138"><span class="linenos">138</span></a>            <span class="c1"># 1. Load vision encoder with precision selection</span>
</span><span id="ONNXRTBackend.initialize-139"><a href="#ONNXRTBackend.initialize-139"><span class="linenos">139</span></a>            <span class="n">vision_path</span><span class="p">,</span> <span class="n">vision_precision</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_model_file</span><span class="p">(</span><span class="s2">&quot;vision&quot;</span><span class="p">)</span>
</span><span id="ONNXRTBackend.initialize-140"><a href="#ONNXRTBackend.initialize-140"><span class="linenos">140</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
</span><span id="ONNXRTBackend.initialize-141"><a href="#ONNXRTBackend.initialize-141"><span class="linenos">141</span></a>                <span class="sa">f</span><span class="s2">&quot;Loading vision encoder from </span><span class="si">{</span><span class="n">vision_path</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">vision_precision</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="ONNXRTBackend.initialize-142"><a href="#ONNXRTBackend.initialize-142"><span class="linenos">142</span></a>            <span class="p">)</span>
</span><span id="ONNXRTBackend.initialize-143"><a href="#ONNXRTBackend.initialize-143"><span class="linenos">143</span></a>
</span><span id="ONNXRTBackend.initialize-144"><a href="#ONNXRTBackend.initialize-144"><span class="linenos">144</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_sess_vision</span> <span class="o">=</span> <span class="n">ort</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span>
</span><span id="ONNXRTBackend.initialize-145"><a href="#ONNXRTBackend.initialize-145"><span class="linenos">145</span></a>                <span class="nb">str</span><span class="p">(</span><span class="n">vision_path</span><span class="p">),</span>
</span><span id="ONNXRTBackend.initialize-146"><a href="#ONNXRTBackend.initialize-146"><span class="linenos">146</span></a>                <span class="n">sess_options</span><span class="p">,</span>
</span><span id="ONNXRTBackend.initialize-147"><a href="#ONNXRTBackend.initialize-147"><span class="linenos">147</span></a>                <span class="n">providers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_providers</span><span class="p">,</span>
</span><span id="ONNXRTBackend.initialize-148"><a href="#ONNXRTBackend.initialize-148"><span class="linenos">148</span></a>            <span class="p">)</span>
</span><span id="ONNXRTBackend.initialize-149"><a href="#ONNXRTBackend.initialize-149"><span class="linenos">149</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_vision_precision</span> <span class="o">=</span> <span class="n">vision_precision</span>
</span><span id="ONNXRTBackend.initialize-150"><a href="#ONNXRTBackend.initialize-150"><span class="linenos">150</span></a>
</span><span id="ONNXRTBackend.initialize-151"><a href="#ONNXRTBackend.initialize-151"><span class="linenos">151</span></a>            <span class="c1"># Detect vision input dtype</span>
</span><span id="ONNXRTBackend.initialize-152"><a href="#ONNXRTBackend.initialize-152"><span class="linenos">152</span></a>            <span class="n">vision_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_vision</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ONNXRTBackend.initialize-153"><a href="#ONNXRTBackend.initialize-153"><span class="linenos">153</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_vision_input_dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_onnx_type_to_numpy</span><span class="p">(</span><span class="n">vision_input</span><span class="o">.</span><span class="n">type</span><span class="p">)</span>
</span><span id="ONNXRTBackend.initialize-154"><a href="#ONNXRTBackend.initialize-154"><span class="linenos">154</span></a>
</span><span id="ONNXRTBackend.initialize-155"><a href="#ONNXRTBackend.initialize-155"><span class="linenos">155</span></a>            <span class="c1"># 2. Load text encoder with precision selection</span>
</span><span id="ONNXRTBackend.initialize-156"><a href="#ONNXRTBackend.initialize-156"><span class="linenos">156</span></a>            <span class="n">text_path</span><span class="p">,</span> <span class="n">text_precision</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_model_file</span><span class="p">(</span><span class="s2">&quot;text&quot;</span><span class="p">)</span>
</span><span id="ONNXRTBackend.initialize-157"><a href="#ONNXRTBackend.initialize-157"><span class="linenos">157</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading text encoder from </span><span class="si">{</span><span class="n">text_path</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">text_precision</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
</span><span id="ONNXRTBackend.initialize-158"><a href="#ONNXRTBackend.initialize-158"><span class="linenos">158</span></a>
</span><span id="ONNXRTBackend.initialize-159"><a href="#ONNXRTBackend.initialize-159"><span class="linenos">159</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_sess_text</span> <span class="o">=</span> <span class="n">ort</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span>
</span><span id="ONNXRTBackend.initialize-160"><a href="#ONNXRTBackend.initialize-160"><span class="linenos">160</span></a>                <span class="nb">str</span><span class="p">(</span><span class="n">text_path</span><span class="p">),</span>
</span><span id="ONNXRTBackend.initialize-161"><a href="#ONNXRTBackend.initialize-161"><span class="linenos">161</span></a>                <span class="n">sess_options</span><span class="p">,</span>
</span><span id="ONNXRTBackend.initialize-162"><a href="#ONNXRTBackend.initialize-162"><span class="linenos">162</span></a>                <span class="n">providers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_providers</span><span class="p">,</span>
</span><span id="ONNXRTBackend.initialize-163"><a href="#ONNXRTBackend.initialize-163"><span class="linenos">163</span></a>            <span class="p">)</span>
</span><span id="ONNXRTBackend.initialize-164"><a href="#ONNXRTBackend.initialize-164"><span class="linenos">164</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_text_precision</span> <span class="o">=</span> <span class="n">text_precision</span>
</span><span id="ONNXRTBackend.initialize-165"><a href="#ONNXRTBackend.initialize-165"><span class="linenos">165</span></a>
</span><span id="ONNXRTBackend.initialize-166"><a href="#ONNXRTBackend.initialize-166"><span class="linenos">166</span></a>            <span class="c1"># Detect text input dtype</span>
</span><span id="ONNXRTBackend.initialize-167"><a href="#ONNXRTBackend.initialize-167"><span class="linenos">167</span></a>            <span class="n">text_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_text</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ONNXRTBackend.initialize-168"><a href="#ONNXRTBackend.initialize-168"><span class="linenos">168</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_text_input_dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_onnx_type_to_numpy</span><span class="p">(</span><span class="n">text_input</span><span class="o">.</span><span class="n">type</span><span class="p">)</span>
</span><span id="ONNXRTBackend.initialize-169"><a href="#ONNXRTBackend.initialize-169"><span class="linenos">169</span></a>
</span><span id="ONNXRTBackend.initialize-170"><a href="#ONNXRTBackend.initialize-170"><span class="linenos">170</span></a>            <span class="c1"># 3. Setup tokenizer</span>
</span><span id="ONNXRTBackend.initialize-171"><a href="#ONNXRTBackend.initialize-171"><span class="linenos">171</span></a>            <span class="c1"># Cast to the declared callable signature to satisfy static type checkers.</span>
</span><span id="ONNXRTBackend.initialize-172"><a href="#ONNXRTBackend.initialize-172"><span class="linenos">172</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span>
</span><span id="ONNXRTBackend.initialize-173"><a href="#ONNXRTBackend.initialize-173"><span class="linenos">173</span></a>                <span class="n">Callable</span><span class="p">[[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load_tokenizer</span><span class="p">()</span>
</span><span id="ONNXRTBackend.initialize-174"><a href="#ONNXRTBackend.initialize-174"><span class="linenos">174</span></a>            <span class="p">)</span>
</span><span id="ONNXRTBackend.initialize-175"><a href="#ONNXRTBackend.initialize-175"><span class="linenos">175</span></a>
</span><span id="ONNXRTBackend.initialize-176"><a href="#ONNXRTBackend.initialize-176"><span class="linenos">176</span></a>            <span class="c1"># 4. Setup image preprocessor</span>
</span><span id="ONNXRTBackend.initialize-177"><a href="#ONNXRTBackend.initialize-177"><span class="linenos">177</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_image_preprocessor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_image_preprocessor</span><span class="p">()</span>
</span><span id="ONNXRTBackend.initialize-178"><a href="#ONNXRTBackend.initialize-178"><span class="linenos">178</span></a>
</span><span id="ONNXRTBackend.initialize-179"><a href="#ONNXRTBackend.initialize-179"><span class="linenos">179</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_load_time_seconds</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span>
</span><span id="ONNXRTBackend.initialize-180"><a href="#ONNXRTBackend.initialize-180"><span class="linenos">180</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_initialized</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="ONNXRTBackend.initialize-181"><a href="#ONNXRTBackend.initialize-181"><span class="linenos">181</span></a>
</span><span id="ONNXRTBackend.initialize-182"><a href="#ONNXRTBackend.initialize-182"><span class="linenos">182</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
</span><span id="ONNXRTBackend.initialize-183"><a href="#ONNXRTBackend.initialize-183"><span class="linenos">183</span></a>                <span class="sa">f</span><span class="s2">&quot;✅ ONNXRTBackend initialized in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_load_time_seconds</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s&quot;</span>
</span><span id="ONNXRTBackend.initialize-184"><a href="#ONNXRTBackend.initialize-184"><span class="linenos">184</span></a>            <span class="p">)</span>
</span><span id="ONNXRTBackend.initialize-185"><a href="#ONNXRTBackend.initialize-185"><span class="linenos">185</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   Providers: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_providers</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="ONNXRTBackend.initialize-186"><a href="#ONNXRTBackend.initialize-186"><span class="linenos">186</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
</span><span id="ONNXRTBackend.initialize-187"><a href="#ONNXRTBackend.initialize-187"><span class="linenos">187</span></a>                <span class="sa">f</span><span class="s2">&quot;   Vision: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_vision_precision</span><span class="si">}</span><span class="s2"> (input: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_vision_input_dtype</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="ONNXRTBackend.initialize-188"><a href="#ONNXRTBackend.initialize-188"><span class="linenos">188</span></a>            <span class="p">)</span>
</span><span id="ONNXRTBackend.initialize-189"><a href="#ONNXRTBackend.initialize-189"><span class="linenos">189</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
</span><span id="ONNXRTBackend.initialize-190"><a href="#ONNXRTBackend.initialize-190"><span class="linenos">190</span></a>                <span class="sa">f</span><span class="s2">&quot;   Text: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_text_precision</span><span class="si">}</span><span class="s2"> (input: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_text_input_dtype</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="ONNXRTBackend.initialize-191"><a href="#ONNXRTBackend.initialize-191"><span class="linenos">191</span></a>            <span class="p">)</span>
</span><span id="ONNXRTBackend.initialize-192"><a href="#ONNXRTBackend.initialize-192"><span class="linenos">192</span></a>
</span><span id="ONNXRTBackend.initialize-193"><a href="#ONNXRTBackend.initialize-193"><span class="linenos">193</span></a>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="ONNXRTBackend.initialize-194"><a href="#ONNXRTBackend.initialize-194"><span class="linenos">194</span></a>            <span class="k">raise</span> <span class="n">ONNXRTModelLoadingError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ONNX model loading failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span></pre></div>


            <div class="docstring"><p>Load ONNX models and prepare preprocessing.</p>
</div>


                            </div>
                            <div id="ONNXRTBackend.text_to_vector" class="classattr">
                                        <input id="ONNXRTBackend.text_to_vector-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-override">@override</div>

        <span class="def">def</span>
        <span class="name">text_to_vector</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">text</span><span class="p">:</span> <span class="nb">str</span></span><span class="return-annotation">) -> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dtype</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">]]</span>:</span></span>

                <label class="view-source-button" for="ONNXRTBackend.text_to_vector-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ONNXRTBackend.text_to_vector"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ONNXRTBackend.text_to_vector-342"><a href="#ONNXRTBackend.text_to_vector-342"><span class="linenos">342</span></a>    <span class="nd">@override</span>
</span><span id="ONNXRTBackend.text_to_vector-343"><a href="#ONNXRTBackend.text_to_vector-343"><span class="linenos">343</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">text_to_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="ONNXRTBackend.text_to_vector-344"><a href="#ONNXRTBackend.text_to_vector-344"><span class="linenos">344</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Encode text into a unit-normalized float32 vector.&quot;&quot;&quot;</span>
</span><span id="ONNXRTBackend.text_to_vector-345"><a href="#ONNXRTBackend.text_to_vector-345"><span class="linenos">345</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_initialized</span><span class="p">()</span>
</span><span id="ONNXRTBackend.text_to_vector-346"><a href="#ONNXRTBackend.text_to_vector-346"><span class="linenos">346</span></a>
</span><span id="ONNXRTBackend.text_to_vector-347"><a href="#ONNXRTBackend.text_to_vector-347"><span class="linenos">347</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">text</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
</span><span id="ONNXRTBackend.text_to_vector-348"><a href="#ONNXRTBackend.text_to_vector-348"><span class="linenos">348</span></a>            <span class="k">raise</span> <span class="n">InvalidInputError</span><span class="p">(</span><span class="s2">&quot;text cannot be empty or whitespace only&quot;</span><span class="p">)</span>
</span><span id="ONNXRTBackend.text_to_vector-349"><a href="#ONNXRTBackend.text_to_vector-349"><span class="linenos">349</span></a>
</span><span id="ONNXRTBackend.text_to_vector-350"><a href="#ONNXRTBackend.text_to_vector-350"><span class="linenos">350</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="ONNXRTBackend.text_to_vector-351"><a href="#ONNXRTBackend.text_to_vector-351"><span class="linenos">351</span></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend.text_to_vector-352"><a href="#ONNXRTBackend.text_to_vector-352"><span class="linenos">352</span></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_text</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend.text_to_vector-353"><a href="#ONNXRTBackend.text_to_vector-353"><span class="linenos">353</span></a>
</span><span id="ONNXRTBackend.text_to_vector-354"><a href="#ONNXRTBackend.text_to_vector-354"><span class="linenos">354</span></a>            <span class="c1"># Tokenize (always int64)</span>
</span><span id="ONNXRTBackend.text_to_vector-355"><a href="#ONNXRTBackend.text_to_vector-355"><span class="linenos">355</span></a>            <span class="n">tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span><span class="p">([</span><span class="n">text</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_text_input_dtype</span><span class="p">)</span>
</span><span id="ONNXRTBackend.text_to_vector-356"><a href="#ONNXRTBackend.text_to_vector-356"><span class="linenos">356</span></a>
</span><span id="ONNXRTBackend.text_to_vector-357"><a href="#ONNXRTBackend.text_to_vector-357"><span class="linenos">357</span></a>            <span class="c1"># Run inference</span>
</span><span id="ONNXRTBackend.text_to_vector-358"><a href="#ONNXRTBackend.text_to_vector-358"><span class="linenos">358</span></a>            <span class="n">input_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_text</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
</span><span id="ONNXRTBackend.text_to_vector-359"><a href="#ONNXRTBackend.text_to_vector-359"><span class="linenos">359</span></a>            <span class="n">output_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_text</span><span class="o">.</span><span class="n">get_outputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
</span><span id="ONNXRTBackend.text_to_vector-360"><a href="#ONNXRTBackend.text_to_vector-360"><span class="linenos">360</span></a>
</span><span id="ONNXRTBackend.text_to_vector-361"><a href="#ONNXRTBackend.text_to_vector-361"><span class="linenos">361</span></a>            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_text</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">output_name</span><span class="p">],</span> <span class="p">{</span><span class="n">input_name</span><span class="p">:</span> <span class="n">tokens</span><span class="p">})</span>
</span><span id="ONNXRTBackend.text_to_vector-362"><a href="#ONNXRTBackend.text_to_vector-362"><span class="linenos">362</span></a>            <span class="n">embedding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="ONNXRTBackend.text_to_vector-363"><a href="#ONNXRTBackend.text_to_vector-363"><span class="linenos">363</span></a>
</span><span id="ONNXRTBackend.text_to_vector-364"><a href="#ONNXRTBackend.text_to_vector-364"><span class="linenos">364</span></a>            <span class="c1"># Normalize</span>
</span><span id="ONNXRTBackend.text_to_vector-365"><a href="#ONNXRTBackend.text_to_vector-365"><span class="linenos">365</span></a>            <span class="n">embedding</span> <span class="o">=</span> <span class="p">(</span><span class="n">embedding</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">embedding</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="ONNXRTBackend.text_to_vector-366"><a href="#ONNXRTBackend.text_to_vector-366"><span class="linenos">366</span></a>
</span><span id="ONNXRTBackend.text_to_vector-367"><a href="#ONNXRTBackend.text_to_vector-367"><span class="linenos">367</span></a>            <span class="k">return</span> <span class="n">embedding</span>
</span><span id="ONNXRTBackend.text_to_vector-368"><a href="#ONNXRTBackend.text_to_vector-368"><span class="linenos">368</span></a>
</span><span id="ONNXRTBackend.text_to_vector-369"><a href="#ONNXRTBackend.text_to_vector-369"><span class="linenos">369</span></a>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="ONNXRTBackend.text_to_vector-370"><a href="#ONNXRTBackend.text_to_vector-370"><span class="linenos">370</span></a>            <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Text encoding failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span></pre></div>


            <div class="docstring"><p>Encode text into a unit-normalized float32 vector.</p>
</div>


                            </div>
                            <div id="ONNXRTBackend.image_to_vector" class="classattr">
                                        <input id="ONNXRTBackend.image_to_vector-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-override">@override</div>

        <span class="def">def</span>
        <span class="name">image_to_vector</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">image_bytes</span><span class="p">:</span> <span class="nb">bytes</span></span><span class="return-annotation">) -> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dtype</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">]]</span>:</span></span>

                <label class="view-source-button" for="ONNXRTBackend.image_to_vector-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ONNXRTBackend.image_to_vector"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ONNXRTBackend.image_to_vector-372"><a href="#ONNXRTBackend.image_to_vector-372"><span class="linenos">372</span></a>    <span class="nd">@override</span>
</span><span id="ONNXRTBackend.image_to_vector-373"><a href="#ONNXRTBackend.image_to_vector-373"><span class="linenos">373</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">image_to_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_bytes</span><span class="p">:</span> <span class="nb">bytes</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="ONNXRTBackend.image_to_vector-374"><a href="#ONNXRTBackend.image_to_vector-374"><span class="linenos">374</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Encode image bytes into a unit-normalized float32 vector.&quot;&quot;&quot;</span>
</span><span id="ONNXRTBackend.image_to_vector-375"><a href="#ONNXRTBackend.image_to_vector-375"><span class="linenos">375</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_initialized</span><span class="p">()</span>
</span><span id="ONNXRTBackend.image_to_vector-376"><a href="#ONNXRTBackend.image_to_vector-376"><span class="linenos">376</span></a>
</span><span id="ONNXRTBackend.image_to_vector-377"><a href="#ONNXRTBackend.image_to_vector-377"><span class="linenos">377</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">image_bytes</span><span class="p">:</span>
</span><span id="ONNXRTBackend.image_to_vector-378"><a href="#ONNXRTBackend.image_to_vector-378"><span class="linenos">378</span></a>            <span class="k">raise</span> <span class="n">InvalidInputError</span><span class="p">(</span><span class="s2">&quot;image_bytes cannot be empty&quot;</span><span class="p">)</span>
</span><span id="ONNXRTBackend.image_to_vector-379"><a href="#ONNXRTBackend.image_to_vector-379"><span class="linenos">379</span></a>
</span><span id="ONNXRTBackend.image_to_vector-380"><a href="#ONNXRTBackend.image_to_vector-380"><span class="linenos">380</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="ONNXRTBackend.image_to_vector-381"><a href="#ONNXRTBackend.image_to_vector-381"><span class="linenos">381</span></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_image_preprocessor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend.image_to_vector-382"><a href="#ONNXRTBackend.image_to_vector-382"><span class="linenos">382</span></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_vision</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend.image_to_vector-383"><a href="#ONNXRTBackend.image_to_vector-383"><span class="linenos">383</span></a>
</span><span id="ONNXRTBackend.image_to_vector-384"><a href="#ONNXRTBackend.image_to_vector-384"><span class="linenos">384</span></a>            <span class="c1"># Decode and preprocess image</span>
</span><span id="ONNXRTBackend.image_to_vector-385"><a href="#ONNXRTBackend.image_to_vector-385"><span class="linenos">385</span></a>            <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">image_bytes</span><span class="p">))</span>
</span><span id="ONNXRTBackend.image_to_vector-386"><a href="#ONNXRTBackend.image_to_vector-386"><span class="linenos">386</span></a>            <span class="n">img_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_image_preprocessor</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</span><span id="ONNXRTBackend.image_to_vector-387"><a href="#ONNXRTBackend.image_to_vector-387"><span class="linenos">387</span></a>
</span><span id="ONNXRTBackend.image_to_vector-388"><a href="#ONNXRTBackend.image_to_vector-388"><span class="linenos">388</span></a>            <span class="c1"># Run inference</span>
</span><span id="ONNXRTBackend.image_to_vector-389"><a href="#ONNXRTBackend.image_to_vector-389"><span class="linenos">389</span></a>            <span class="n">input_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_vision</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
</span><span id="ONNXRTBackend.image_to_vector-390"><a href="#ONNXRTBackend.image_to_vector-390"><span class="linenos">390</span></a>            <span class="n">output_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_vision</span><span class="o">.</span><span class="n">get_outputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
</span><span id="ONNXRTBackend.image_to_vector-391"><a href="#ONNXRTBackend.image_to_vector-391"><span class="linenos">391</span></a>
</span><span id="ONNXRTBackend.image_to_vector-392"><a href="#ONNXRTBackend.image_to_vector-392"><span class="linenos">392</span></a>            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_vision</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">output_name</span><span class="p">],</span> <span class="p">{</span><span class="n">input_name</span><span class="p">:</span> <span class="n">img_tensor</span><span class="p">})</span>
</span><span id="ONNXRTBackend.image_to_vector-393"><a href="#ONNXRTBackend.image_to_vector-393"><span class="linenos">393</span></a>            <span class="n">embedding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="ONNXRTBackend.image_to_vector-394"><a href="#ONNXRTBackend.image_to_vector-394"><span class="linenos">394</span></a>
</span><span id="ONNXRTBackend.image_to_vector-395"><a href="#ONNXRTBackend.image_to_vector-395"><span class="linenos">395</span></a>            <span class="c1"># Normalize</span>
</span><span id="ONNXRTBackend.image_to_vector-396"><a href="#ONNXRTBackend.image_to_vector-396"><span class="linenos">396</span></a>            <span class="n">embedding</span> <span class="o">=</span> <span class="p">(</span><span class="n">embedding</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">embedding</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="ONNXRTBackend.image_to_vector-397"><a href="#ONNXRTBackend.image_to_vector-397"><span class="linenos">397</span></a>
</span><span id="ONNXRTBackend.image_to_vector-398"><a href="#ONNXRTBackend.image_to_vector-398"><span class="linenos">398</span></a>            <span class="k">return</span> <span class="n">embedding</span>
</span><span id="ONNXRTBackend.image_to_vector-399"><a href="#ONNXRTBackend.image_to_vector-399"><span class="linenos">399</span></a>
</span><span id="ONNXRTBackend.image_to_vector-400"><a href="#ONNXRTBackend.image_to_vector-400"><span class="linenos">400</span></a>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="ONNXRTBackend.image_to_vector-401"><a href="#ONNXRTBackend.image_to_vector-401"><span class="linenos">401</span></a>            <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Image encoding failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span></pre></div>


            <div class="docstring"><p>Encode image bytes into a unit-normalized float32 vector.</p>
</div>


                            </div>
                            <div id="ONNXRTBackend.image_batch_to_vectors" class="classattr">
                                        <input id="ONNXRTBackend.image_batch_to_vectors-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-override">@override</div>

        <span class="def">def</span>
        <span class="name">image_batch_to_vectors</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">images</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">bytes</span><span class="p">]</span></span><span class="return-annotation">) -> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dtype</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">]]</span>:</span></span>

                <label class="view-source-button" for="ONNXRTBackend.image_batch_to_vectors-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ONNXRTBackend.image_batch_to_vectors"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ONNXRTBackend.image_batch_to_vectors-403"><a href="#ONNXRTBackend.image_batch_to_vectors-403"><span class="linenos">403</span></a>    <span class="nd">@override</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-404"><a href="#ONNXRTBackend.image_batch_to_vectors-404"><span class="linenos">404</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">image_batch_to_vectors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">bytes</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-405"><a href="#ONNXRTBackend.image_batch_to_vectors-405"><span class="linenos">405</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Encode a batch of images using batched ONNX inference.&quot;&quot;&quot;</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-406"><a href="#ONNXRTBackend.image_batch_to_vectors-406"><span class="linenos">406</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">images</span><span class="p">:</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-407"><a href="#ONNXRTBackend.image_batch_to_vectors-407"><span class="linenos">407</span></a>            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-408"><a href="#ONNXRTBackend.image_batch_to_vectors-408"><span class="linenos">408</span></a>
</span><span id="ONNXRTBackend.image_batch_to_vectors-409"><a href="#ONNXRTBackend.image_batch_to_vectors-409"><span class="linenos">409</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_initialized</span><span class="p">()</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-410"><a href="#ONNXRTBackend.image_batch_to_vectors-410"><span class="linenos">410</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_image_preprocessor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-411"><a href="#ONNXRTBackend.image_batch_to_vectors-411"><span class="linenos">411</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_vision</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-412"><a href="#ONNXRTBackend.image_batch_to_vectors-412"><span class="linenos">412</span></a>
</span><span id="ONNXRTBackend.image_batch_to_vectors-413"><a href="#ONNXRTBackend.image_batch_to_vectors-413"><span class="linenos">413</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-414"><a href="#ONNXRTBackend.image_batch_to_vectors-414"><span class="linenos">414</span></a>            <span class="c1"># Preprocess all images</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-415"><a href="#ONNXRTBackend.image_batch_to_vectors-415"><span class="linenos">415</span></a>            <span class="n">img_tensors</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-416"><a href="#ONNXRTBackend.image_batch_to_vectors-416"><span class="linenos">416</span></a>            <span class="k">for</span> <span class="n">img_bytes</span> <span class="ow">in</span> <span class="n">images</span><span class="p">:</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-417"><a href="#ONNXRTBackend.image_batch_to_vectors-417"><span class="linenos">417</span></a>                <span class="k">if</span> <span class="ow">not</span> <span class="n">img_bytes</span><span class="p">:</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-418"><a href="#ONNXRTBackend.image_batch_to_vectors-418"><span class="linenos">418</span></a>                    <span class="k">raise</span> <span class="n">InvalidInputError</span><span class="p">(</span><span class="s2">&quot;image bytes cannot be empty&quot;</span><span class="p">)</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-419"><a href="#ONNXRTBackend.image_batch_to_vectors-419"><span class="linenos">419</span></a>                <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">img_bytes</span><span class="p">))</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-420"><a href="#ONNXRTBackend.image_batch_to_vectors-420"><span class="linenos">420</span></a>                <span class="n">img_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_image_preprocessor</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-421"><a href="#ONNXRTBackend.image_batch_to_vectors-421"><span class="linenos">421</span></a>                <span class="n">img_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">img_tensor</span><span class="p">)</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-422"><a href="#ONNXRTBackend.image_batch_to_vectors-422"><span class="linenos">422</span></a>
</span><span id="ONNXRTBackend.image_batch_to_vectors-423"><a href="#ONNXRTBackend.image_batch_to_vectors-423"><span class="linenos">423</span></a>            <span class="c1"># Stack into batch</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-424"><a href="#ONNXRTBackend.image_batch_to_vectors-424"><span class="linenos">424</span></a>            <span class="n">batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">img_tensors</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-425"><a href="#ONNXRTBackend.image_batch_to_vectors-425"><span class="linenos">425</span></a>
</span><span id="ONNXRTBackend.image_batch_to_vectors-426"><a href="#ONNXRTBackend.image_batch_to_vectors-426"><span class="linenos">426</span></a>            <span class="c1"># Run batched inference</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-427"><a href="#ONNXRTBackend.image_batch_to_vectors-427"><span class="linenos">427</span></a>            <span class="n">input_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_vision</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-428"><a href="#ONNXRTBackend.image_batch_to_vectors-428"><span class="linenos">428</span></a>            <span class="n">output_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_vision</span><span class="o">.</span><span class="n">get_outputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-429"><a href="#ONNXRTBackend.image_batch_to_vectors-429"><span class="linenos">429</span></a>
</span><span id="ONNXRTBackend.image_batch_to_vectors-430"><a href="#ONNXRTBackend.image_batch_to_vectors-430"><span class="linenos">430</span></a>            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_vision</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">output_name</span><span class="p">],</span> <span class="p">{</span><span class="n">input_name</span><span class="p">:</span> <span class="n">batch</span><span class="p">})</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-431"><a href="#ONNXRTBackend.image_batch_to_vectors-431"><span class="linenos">431</span></a>            <span class="n">embeddings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-432"><a href="#ONNXRTBackend.image_batch_to_vectors-432"><span class="linenos">432</span></a>
</span><span id="ONNXRTBackend.image_batch_to_vectors-433"><a href="#ONNXRTBackend.image_batch_to_vectors-433"><span class="linenos">433</span></a>            <span class="c1"># Normalize each vector</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-434"><a href="#ONNXRTBackend.image_batch_to_vectors-434"><span class="linenos">434</span></a>            <span class="n">norms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-435"><a href="#ONNXRTBackend.image_batch_to_vectors-435"><span class="linenos">435</span></a>            <span class="n">embeddings</span> <span class="o">=</span> <span class="n">embeddings</span> <span class="o">/</span> <span class="n">norms</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-436"><a href="#ONNXRTBackend.image_batch_to_vectors-436"><span class="linenos">436</span></a>
</span><span id="ONNXRTBackend.image_batch_to_vectors-437"><a href="#ONNXRTBackend.image_batch_to_vectors-437"><span class="linenos">437</span></a>            <span class="k">return</span> <span class="n">embeddings</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-438"><a href="#ONNXRTBackend.image_batch_to_vectors-438"><span class="linenos">438</span></a>
</span><span id="ONNXRTBackend.image_batch_to_vectors-439"><a href="#ONNXRTBackend.image_batch_to_vectors-439"><span class="linenos">439</span></a>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="ONNXRTBackend.image_batch_to_vectors-440"><a href="#ONNXRTBackend.image_batch_to_vectors-440"><span class="linenos">440</span></a>            <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Batch image encoding failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span></pre></div>


            <div class="docstring"><p>Encode a batch of images using batched ONNX inference.</p>
</div>


                            </div>
                            <div id="ONNXRTBackend.text_batch_to_vectors" class="classattr">
                                        <input id="ONNXRTBackend.text_batch_to_vectors-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-override">@override</div>

        <span class="def">def</span>
        <span class="name">text_batch_to_vectors</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">texts</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span></span><span class="return-annotation">) -> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dtype</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">]]</span>:</span></span>

                <label class="view-source-button" for="ONNXRTBackend.text_batch_to_vectors-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ONNXRTBackend.text_batch_to_vectors"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ONNXRTBackend.text_batch_to_vectors-442"><a href="#ONNXRTBackend.text_batch_to_vectors-442"><span class="linenos">442</span></a>    <span class="nd">@override</span>
</span><span id="ONNXRTBackend.text_batch_to_vectors-443"><a href="#ONNXRTBackend.text_batch_to_vectors-443"><span class="linenos">443</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">text_batch_to_vectors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">texts</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="ONNXRTBackend.text_batch_to_vectors-444"><a href="#ONNXRTBackend.text_batch_to_vectors-444"><span class="linenos">444</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Encode a batch of texts using batched ONNX inference.&quot;&quot;&quot;</span>
</span><span id="ONNXRTBackend.text_batch_to_vectors-445"><a href="#ONNXRTBackend.text_batch_to_vectors-445"><span class="linenos">445</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">texts</span><span class="p">:</span>
</span><span id="ONNXRTBackend.text_batch_to_vectors-446"><a href="#ONNXRTBackend.text_batch_to_vectors-446"><span class="linenos">446</span></a>            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="ONNXRTBackend.text_batch_to_vectors-447"><a href="#ONNXRTBackend.text_batch_to_vectors-447"><span class="linenos">447</span></a>
</span><span id="ONNXRTBackend.text_batch_to_vectors-448"><a href="#ONNXRTBackend.text_batch_to_vectors-448"><span class="linenos">448</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_ensure_initialized</span><span class="p">()</span>
</span><span id="ONNXRTBackend.text_batch_to_vectors-449"><a href="#ONNXRTBackend.text_batch_to_vectors-449"><span class="linenos">449</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend.text_batch_to_vectors-450"><a href="#ONNXRTBackend.text_batch_to_vectors-450"><span class="linenos">450</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_text</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend.text_batch_to_vectors-451"><a href="#ONNXRTBackend.text_batch_to_vectors-451"><span class="linenos">451</span></a>
</span><span id="ONNXRTBackend.text_batch_to_vectors-452"><a href="#ONNXRTBackend.text_batch_to_vectors-452"><span class="linenos">452</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="ONNXRTBackend.text_batch_to_vectors-453"><a href="#ONNXRTBackend.text_batch_to_vectors-453"><span class="linenos">453</span></a>            <span class="c1"># Validate inputs</span>
</span><span id="ONNXRTBackend.text_batch_to_vectors-454"><a href="#ONNXRTBackend.text_batch_to_vectors-454"><span class="linenos">454</span></a>            <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">:</span>
</span><span id="ONNXRTBackend.text_batch_to_vectors-455"><a href="#ONNXRTBackend.text_batch_to_vectors-455"><span class="linenos">455</span></a>                <span class="k">if</span> <span class="ow">not</span> <span class="n">text</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
</span><span id="ONNXRTBackend.text_batch_to_vectors-456"><a href="#ONNXRTBackend.text_batch_to_vectors-456"><span class="linenos">456</span></a>                    <span class="k">raise</span> <span class="n">InvalidInputError</span><span class="p">(</span><span class="s2">&quot;text cannot be empty or whitespace only&quot;</span><span class="p">)</span>
</span><span id="ONNXRTBackend.text_batch_to_vectors-457"><a href="#ONNXRTBackend.text_batch_to_vectors-457"><span class="linenos">457</span></a>
</span><span id="ONNXRTBackend.text_batch_to_vectors-458"><a href="#ONNXRTBackend.text_batch_to_vectors-458"><span class="linenos">458</span></a>            <span class="c1"># Tokenize all texts (always int64)</span>
</span><span id="ONNXRTBackend.text_batch_to_vectors-459"><a href="#ONNXRTBackend.text_batch_to_vectors-459"><span class="linenos">459</span></a>            <span class="n">tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenizer</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">texts</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_text_input_dtype</span><span class="p">)</span>
</span><span id="ONNXRTBackend.text_batch_to_vectors-460"><a href="#ONNXRTBackend.text_batch_to_vectors-460"><span class="linenos">460</span></a>
</span><span id="ONNXRTBackend.text_batch_to_vectors-461"><a href="#ONNXRTBackend.text_batch_to_vectors-461"><span class="linenos">461</span></a>            <span class="c1"># Run batched inference</span>
</span><span id="ONNXRTBackend.text_batch_to_vectors-462"><a href="#ONNXRTBackend.text_batch_to_vectors-462"><span class="linenos">462</span></a>            <span class="n">input_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_text</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
</span><span id="ONNXRTBackend.text_batch_to_vectors-463"><a href="#ONNXRTBackend.text_batch_to_vectors-463"><span class="linenos">463</span></a>            <span class="n">output_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_text</span><span class="o">.</span><span class="n">get_outputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
</span><span id="ONNXRTBackend.text_batch_to_vectors-464"><a href="#ONNXRTBackend.text_batch_to_vectors-464"><span class="linenos">464</span></a>
</span><span id="ONNXRTBackend.text_batch_to_vectors-465"><a href="#ONNXRTBackend.text_batch_to_vectors-465"><span class="linenos">465</span></a>            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess_text</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">output_name</span><span class="p">],</span> <span class="p">{</span><span class="n">input_name</span><span class="p">:</span> <span class="n">tokens</span><span class="p">})</span>
</span><span id="ONNXRTBackend.text_batch_to_vectors-466"><a href="#ONNXRTBackend.text_batch_to_vectors-466"><span class="linenos">466</span></a>            <span class="n">embeddings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="ONNXRTBackend.text_batch_to_vectors-467"><a href="#ONNXRTBackend.text_batch_to_vectors-467"><span class="linenos">467</span></a>
</span><span id="ONNXRTBackend.text_batch_to_vectors-468"><a href="#ONNXRTBackend.text_batch_to_vectors-468"><span class="linenos">468</span></a>            <span class="c1"># Normalize each vector</span>
</span><span id="ONNXRTBackend.text_batch_to_vectors-469"><a href="#ONNXRTBackend.text_batch_to_vectors-469"><span class="linenos">469</span></a>            <span class="n">norms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="ONNXRTBackend.text_batch_to_vectors-470"><a href="#ONNXRTBackend.text_batch_to_vectors-470"><span class="linenos">470</span></a>            <span class="n">embeddings</span> <span class="o">=</span> <span class="n">embeddings</span> <span class="o">/</span> <span class="n">norms</span>
</span><span id="ONNXRTBackend.text_batch_to_vectors-471"><a href="#ONNXRTBackend.text_batch_to_vectors-471"><span class="linenos">471</span></a>
</span><span id="ONNXRTBackend.text_batch_to_vectors-472"><a href="#ONNXRTBackend.text_batch_to_vectors-472"><span class="linenos">472</span></a>            <span class="k">return</span> <span class="n">embeddings</span>
</span><span id="ONNXRTBackend.text_batch_to_vectors-473"><a href="#ONNXRTBackend.text_batch_to_vectors-473"><span class="linenos">473</span></a>
</span><span id="ONNXRTBackend.text_batch_to_vectors-474"><a href="#ONNXRTBackend.text_batch_to_vectors-474"><span class="linenos">474</span></a>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="ONNXRTBackend.text_batch_to_vectors-475"><a href="#ONNXRTBackend.text_batch_to_vectors-475"><span class="linenos">475</span></a>            <span class="k">raise</span> <span class="n">InferenceError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Batch text encoding failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
</span></pre></div>


            <div class="docstring"><p>Encode a batch of texts using batched ONNX inference.</p>
</div>


                            </div>
                            <div id="ONNXRTBackend.get_info" class="classattr">
                                        <input id="ONNXRTBackend.get_info-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-override">@override</div>

        <span class="def">def</span>
        <span class="name">get_info</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">) -> <span class="n"><a href="#BackendInfo">BackendInfo</a></span>:</span></span>

                <label class="view-source-button" for="ONNXRTBackend.get_info-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ONNXRTBackend.get_info"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ONNXRTBackend.get_info-477"><a href="#ONNXRTBackend.get_info-477"><span class="linenos">477</span></a>    <span class="nd">@override</span>
</span><span id="ONNXRTBackend.get_info-478"><a href="#ONNXRTBackend.get_info-478"><span class="linenos">478</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_info</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BackendInfo</span><span class="p">:</span>
</span><span id="ONNXRTBackend.get_info-479"><a href="#ONNXRTBackend.get_info-479"><span class="linenos">479</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Report ONNX Runtime metadata and configuration.&quot;&quot;&quot;</span>
</span><span id="ONNXRTBackend.get_info-480"><a href="#ONNXRTBackend.get_info-480"><span class="linenos">480</span></a>        <span class="n">version</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">ort</span><span class="p">,</span> <span class="s2">&quot;__version__&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span><span id="ONNXRTBackend.get_info-481"><a href="#ONNXRTBackend.get_info-481"><span class="linenos">481</span></a>        <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_infer_device_from_providers</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_providers</span><span class="p">)</span>
</span><span id="ONNXRTBackend.get_info-482"><a href="#ONNXRTBackend.get_info-482"><span class="linenos">482</span></a>
</span><span id="ONNXRTBackend.get_info-483"><a href="#ONNXRTBackend.get_info-483"><span class="linenos">483</span></a>        <span class="c1"># Get embedding dimension from resources</span>
</span><span id="ONNXRTBackend.get_info-484"><a href="#ONNXRTBackend.get_info-484"><span class="linenos">484</span></a>        <span class="n">embed_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">get_embedding_dim</span><span class="p">()</span>
</span><span id="ONNXRTBackend.get_info-485"><a href="#ONNXRTBackend.get_info-485"><span class="linenos">485</span></a>
</span><span id="ONNXRTBackend.get_info-486"><a href="#ONNXRTBackend.get_info-486"><span class="linenos">486</span></a>        <span class="c1"># Get image size from resources</span>
</span><span id="ONNXRTBackend.get_info-487"><a href="#ONNXRTBackend.get_info-487"><span class="linenos">487</span></a>        <span class="n">image_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">get_image_size</span><span class="p">()</span>
</span><span id="ONNXRTBackend.get_info-488"><a href="#ONNXRTBackend.get_info-488"><span class="linenos">488</span></a>        <span class="n">image_size_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">image_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">x</span><span class="si">{</span><span class="n">image_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">if</span> <span class="n">image_size</span> <span class="k">else</span> <span class="kc">None</span>
</span><span id="ONNXRTBackend.get_info-489"><a href="#ONNXRTBackend.get_info-489"><span class="linenos">489</span></a>
</span><span id="ONNXRTBackend.get_info-490"><a href="#ONNXRTBackend.get_info-490"><span class="linenos">490</span></a>        <span class="c1"># Determine precision list</span>
</span><span id="ONNXRTBackend.get_info-491"><a href="#ONNXRTBackend.get_info-491"><span class="linenos">491</span></a>        <span class="n">precisions</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_vision_precision</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_text_precision</span><span class="p">]))</span>
</span><span id="ONNXRTBackend.get_info-492"><a href="#ONNXRTBackend.get_info-492"><span class="linenos">492</span></a>        <span class="k">if</span> <span class="s2">&quot;unknown&quot;</span> <span class="ow">in</span> <span class="n">precisions</span><span class="p">:</span>
</span><span id="ONNXRTBackend.get_info-493"><a href="#ONNXRTBackend.get_info-493"><span class="linenos">493</span></a>            <span class="n">precisions</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s2">&quot;unknown&quot;</span><span class="p">)</span>
</span><span id="ONNXRTBackend.get_info-494"><a href="#ONNXRTBackend.get_info-494"><span class="linenos">494</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">precisions</span><span class="p">:</span>
</span><span id="ONNXRTBackend.get_info-495"><a href="#ONNXRTBackend.get_info-495"><span class="linenos">495</span></a>            <span class="n">precisions</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;fp32&quot;</span><span class="p">]</span>
</span><span id="ONNXRTBackend.get_info-496"><a href="#ONNXRTBackend.get_info-496"><span class="linenos">496</span></a>
</span><span id="ONNXRTBackend.get_info-497"><a href="#ONNXRTBackend.get_info-497"><span class="linenos">497</span></a>        <span class="k">return</span> <span class="n">BackendInfo</span><span class="p">(</span>
</span><span id="ONNXRTBackend.get_info-498"><a href="#ONNXRTBackend.get_info-498"><span class="linenos">498</span></a>            <span class="n">runtime</span><span class="o">=</span><span class="s2">&quot;onnx&quot;</span><span class="p">,</span>
</span><span id="ONNXRTBackend.get_info-499"><a href="#ONNXRTBackend.get_info-499"><span class="linenos">499</span></a>            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
</span><span id="ONNXRTBackend.get_info-500"><a href="#ONNXRTBackend.get_info-500"><span class="linenos">500</span></a>            <span class="n">model_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span>
</span><span id="ONNXRTBackend.get_info-501"><a href="#ONNXRTBackend.get_info-501"><span class="linenos">501</span></a>            <span class="n">model_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
</span><span id="ONNXRTBackend.get_info-502"><a href="#ONNXRTBackend.get_info-502"><span class="linenos">502</span></a>                <span class="s2">&quot;model_name&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">resources</span><span class="o">.</span><span class="n">model_name</span>
</span><span id="ONNXRTBackend.get_info-503"><a href="#ONNXRTBackend.get_info-503"><span class="linenos">503</span></a>            <span class="p">),</span>
</span><span id="ONNXRTBackend.get_info-504"><a href="#ONNXRTBackend.get_info-504"><span class="linenos">504</span></a>            <span class="n">pretrained</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># Local weights</span>
</span><span id="ONNXRTBackend.get_info-505"><a href="#ONNXRTBackend.get_info-505"><span class="linenos">505</span></a>            <span class="n">version</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">version</span><span class="p">)</span> <span class="k">if</span> <span class="n">version</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="ONNXRTBackend.get_info-506"><a href="#ONNXRTBackend.get_info-506"><span class="linenos">506</span></a>            <span class="n">image_embedding_dim</span><span class="o">=</span><span class="n">embed_dim</span><span class="p">,</span>
</span><span id="ONNXRTBackend.get_info-507"><a href="#ONNXRTBackend.get_info-507"><span class="linenos">507</span></a>            <span class="n">text_embedding_dim</span><span class="o">=</span><span class="n">embed_dim</span><span class="p">,</span>
</span><span id="ONNXRTBackend.get_info-508"><a href="#ONNXRTBackend.get_info-508"><span class="linenos">508</span></a>            <span class="n">precisions</span><span class="o">=</span><span class="n">precisions</span><span class="p">,</span>
</span><span id="ONNXRTBackend.get_info-509"><a href="#ONNXRTBackend.get_info-509"><span class="linenos">509</span></a>            <span class="n">max_batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_max_batch_size</span><span class="p">,</span>
</span><span id="ONNXRTBackend.get_info-510"><a href="#ONNXRTBackend.get_info-510"><span class="linenos">510</span></a>            <span class="n">supports_image_batch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="ONNXRTBackend.get_info-511"><a href="#ONNXRTBackend.get_info-511"><span class="linenos">511</span></a>            <span class="n">extra</span><span class="o">=</span><span class="p">{</span>
</span><span id="ONNXRTBackend.get_info-512"><a href="#ONNXRTBackend.get_info-512"><span class="linenos">512</span></a>                <span class="s2">&quot;providers&quot;</span><span class="p">:</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_providers</span><span class="p">),</span>
</span><span id="ONNXRTBackend.get_info-513"><a href="#ONNXRTBackend.get_info-513"><span class="linenos">513</span></a>                <span class="s2">&quot;image_size&quot;</span><span class="p">:</span> <span class="n">image_size_str</span><span class="p">,</span>
</span><span id="ONNXRTBackend.get_info-514"><a href="#ONNXRTBackend.get_info-514"><span class="linenos">514</span></a>                <span class="s2">&quot;vision_precision&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vision_precision</span><span class="p">,</span>
</span><span id="ONNXRTBackend.get_info-515"><a href="#ONNXRTBackend.get_info-515"><span class="linenos">515</span></a>                <span class="s2">&quot;text_precision&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_text_precision</span><span class="p">,</span>
</span><span id="ONNXRTBackend.get_info-516"><a href="#ONNXRTBackend.get_info-516"><span class="linenos">516</span></a>                <span class="s2">&quot;vision_input_dtype&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_vision_input_dtype</span><span class="p">),</span>
</span><span id="ONNXRTBackend.get_info-517"><a href="#ONNXRTBackend.get_info-517"><span class="linenos">517</span></a>                <span class="s2">&quot;text_input_dtype&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_text_input_dtype</span><span class="p">),</span>
</span><span id="ONNXRTBackend.get_info-518"><a href="#ONNXRTBackend.get_info-518"><span class="linenos">518</span></a>            <span class="p">},</span>
</span><span id="ONNXRTBackend.get_info-519"><a href="#ONNXRTBackend.get_info-519"><span class="linenos">519</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Report ONNX Runtime metadata and configuration.</p>
</div>


                            </div>
                </section>
                <section id="RKNNBackend">
                            <input id="RKNNBackend-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">RKNNBackend</span><wbr>(<span class="base"><a href="#BaseClipBackend">lumen_clip.backends.BaseClipBackend</a></span>):

                <label class="view-source-button" for="RKNNBackend-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#RKNNBackend"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="RKNNBackend-33"><a href="#RKNNBackend-33"><span class="linenos">33</span></a><span class="k">class</span><span class="w"> </span><span class="nc">RKNNBackend</span><span class="p">(</span><span class="n">BaseClipBackend</span><span class="p">):</span>
</span><span id="RKNNBackend-34"><a href="#RKNNBackend-34"><span class="linenos">34</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="RKNNBackend-35"><a href="#RKNNBackend-35"><span class="linenos">35</span></a><span class="sd">    Linux-only RKNN backend shim.</span>
</span><span id="RKNNBackend-36"><a href="#RKNNBackend-36"><span class="linenos">36</span></a>
</span><span id="RKNNBackend-37"><a href="#RKNNBackend-37"><span class="linenos">37</span></a><span class="sd">    This class exists to satisfy type checkers by providing the full</span>
</span><span id="RKNNBackend-38"><a href="#RKNNBackend-38"><span class="linenos">38</span></a><span class="sd">    BaseClipBackend interface. All methods raise ImportError to indicate</span>
</span><span id="RKNNBackend-39"><a href="#RKNNBackend-39"><span class="linenos">39</span></a><span class="sd">    the RKNN backend is unavailable in the current environment/build.</span>
</span><span id="RKNNBackend-40"><a href="#RKNNBackend-40"><span class="linenos">40</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="RKNNBackend-41"><a href="#RKNNBackend-41"><span class="linenos">41</span></a>
</span><span id="RKNNBackend-42"><a href="#RKNNBackend-42"><span class="linenos">42</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="RKNNBackend-43"><a href="#RKNNBackend-43"><span class="linenos">43</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="RKNNBackend-44"><a href="#RKNNBackend-44"><span class="linenos">44</span></a>        <span class="n">resources</span><span class="p">:</span> <span class="s2">&quot;ModelResources&quot;</span><span class="p">,</span>
</span><span id="RKNNBackend-45"><a href="#RKNNBackend-45"><span class="linenos">45</span></a>        <span class="n">device_preference</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="RKNNBackend-46"><a href="#RKNNBackend-46"><span class="linenos">46</span></a>        <span class="n">max_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="RKNNBackend-47"><a href="#RKNNBackend-47"><span class="linenos">47</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="RKNNBackend-48"><a href="#RKNNBackend-48"><span class="linenos">48</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="RKNNBackend-49"><a href="#RKNNBackend-49"><span class="linenos">49</span></a>            <span class="n">resources</span><span class="p">,</span>
</span><span id="RKNNBackend-50"><a href="#RKNNBackend-50"><span class="linenos">50</span></a>            <span class="n">device_preference</span><span class="p">,</span>
</span><span id="RKNNBackend-51"><a href="#RKNNBackend-51"><span class="linenos">51</span></a>            <span class="n">max_batch_size</span><span class="p">,</span>
</span><span id="RKNNBackend-52"><a href="#RKNNBackend-52"><span class="linenos">52</span></a>        <span class="p">)</span>
</span><span id="RKNNBackend-53"><a href="#RKNNBackend-53"><span class="linenos">53</span></a>        <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
</span><span id="RKNNBackend-54"><a href="#RKNNBackend-54"><span class="linenos">54</span></a>            <span class="s2">&quot;RKNNBackend is a Linux-only optional backend and is not available in this build.</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="RKNNBackend-55"><a href="#RKNNBackend-55"><span class="linenos">55</span></a>            <span class="s2">&quot;- rknn-toolkit2 provides wheels only for Linux (manylinux) targets.</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="RKNNBackend-56"><a href="#RKNNBackend-56"><span class="linenos">56</span></a>            <span class="s2">&quot;- Use the CUDA/ROCm Docker images which install the Linux-only &#39;rknn&#39; extra, e.g.:</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="RKNNBackend-57"><a href="#RKNNBackend-57"><span class="linenos">57</span></a>            <span class="s2">&quot;    docker build -f Dockerfiles/cuda/Dockerfile -t lumen-clip:cuda .</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="RKNNBackend-58"><a href="#RKNNBackend-58"><span class="linenos">58</span></a>            <span class="s2">&quot;    docker build -f Dockerfiles/rocm/Dockerfile -t lumen-clip:rocm .</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="RKNNBackend-59"><a href="#RKNNBackend-59"><span class="linenos">59</span></a>            <span class="s2">&quot;- At runtime, set BIOCLIP_BACKEND=rknn or CLIP_BACKEND=rknn to select the RKNN backend.&quot;</span>
</span><span id="RKNNBackend-60"><a href="#RKNNBackend-60"><span class="linenos">60</span></a>        <span class="p">)</span>
</span><span id="RKNNBackend-61"><a href="#RKNNBackend-61"><span class="linenos">61</span></a>
</span><span id="RKNNBackend-62"><a href="#RKNNBackend-62"><span class="linenos">62</span></a>    <span class="nd">@override</span>
</span><span id="RKNNBackend-63"><a href="#RKNNBackend-63"><span class="linenos">63</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="RKNNBackend-64"><a href="#RKNNBackend-64"><span class="linenos">64</span></a>        <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
</span><span id="RKNNBackend-65"><a href="#RKNNBackend-65"><span class="linenos">65</span></a>            <span class="s2">&quot;RKNNBackend.initialize is unavailable: RKNN is Linux-only. &quot;</span>
</span><span id="RKNNBackend-66"><a href="#RKNNBackend-66"><span class="linenos">66</span></a>            <span class="s2">&quot;Use a Linux build with the &#39;rknn&#39; extra to enable this backend.&quot;</span>
</span><span id="RKNNBackend-67"><a href="#RKNNBackend-67"><span class="linenos">67</span></a>        <span class="p">)</span>
</span><span id="RKNNBackend-68"><a href="#RKNNBackend-68"><span class="linenos">68</span></a>
</span><span id="RKNNBackend-69"><a href="#RKNNBackend-69"><span class="linenos">69</span></a>    <span class="nd">@override</span>
</span><span id="RKNNBackend-70"><a href="#RKNNBackend-70"><span class="linenos">70</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">text_to_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="RKNNBackend-71"><a href="#RKNNBackend-71"><span class="linenos">71</span></a>        <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
</span><span id="RKNNBackend-72"><a href="#RKNNBackend-72"><span class="linenos">72</span></a>            <span class="s2">&quot;RKNNBackend.text_to_vector is unavailable: RKNN is Linux-only. &quot;</span>
</span><span id="RKNNBackend-73"><a href="#RKNNBackend-73"><span class="linenos">73</span></a>            <span class="s2">&quot;Use a Linux build with the &#39;rknn&#39; extra to enable this backend.&quot;</span>
</span><span id="RKNNBackend-74"><a href="#RKNNBackend-74"><span class="linenos">74</span></a>        <span class="p">)</span>
</span><span id="RKNNBackend-75"><a href="#RKNNBackend-75"><span class="linenos">75</span></a>
</span><span id="RKNNBackend-76"><a href="#RKNNBackend-76"><span class="linenos">76</span></a>    <span class="nd">@override</span>
</span><span id="RKNNBackend-77"><a href="#RKNNBackend-77"><span class="linenos">77</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">image_to_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_bytes</span><span class="p">:</span> <span class="nb">bytes</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="RKNNBackend-78"><a href="#RKNNBackend-78"><span class="linenos">78</span></a>        <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
</span><span id="RKNNBackend-79"><a href="#RKNNBackend-79"><span class="linenos">79</span></a>            <span class="s2">&quot;RKNNBackend.image_to_vector is unavailable: RKNN is Linux-only. &quot;</span>
</span><span id="RKNNBackend-80"><a href="#RKNNBackend-80"><span class="linenos">80</span></a>            <span class="s2">&quot;Use a Linux build with the &#39;rknn&#39; extra to enable this backend.&quot;</span>
</span><span id="RKNNBackend-81"><a href="#RKNNBackend-81"><span class="linenos">81</span></a>        <span class="p">)</span>
</span><span id="RKNNBackend-82"><a href="#RKNNBackend-82"><span class="linenos">82</span></a>
</span><span id="RKNNBackend-83"><a href="#RKNNBackend-83"><span class="linenos">83</span></a>    <span class="nd">@override</span>
</span><span id="RKNNBackend-84"><a href="#RKNNBackend-84"><span class="linenos">84</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_info</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BackendInfo</span><span class="p">:</span>
</span><span id="RKNNBackend-85"><a href="#RKNNBackend-85"><span class="linenos">85</span></a>        <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
</span><span id="RKNNBackend-86"><a href="#RKNNBackend-86"><span class="linenos">86</span></a>            <span class="s2">&quot;RKNNBackend.get_info is unavailable: RKNN is Linux-only. &quot;</span>
</span><span id="RKNNBackend-87"><a href="#RKNNBackend-87"><span class="linenos">87</span></a>            <span class="s2">&quot;Use a Linux build with the &#39;rknn&#39; extra to enable this backend.&quot;</span>
</span><span id="RKNNBackend-88"><a href="#RKNNBackend-88"><span class="linenos">88</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Linux-only RKNN backend shim.</p>

<p>This class exists to satisfy type checkers by providing the full
BaseClipBackend interface. All methods raise ImportError to indicate
the RKNN backend is unavailable in the current environment/build.</p>
</div>


                            <div id="RKNNBackend.__init__" class="classattr">
                                        <input id="RKNNBackend.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">RKNNBackend</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">resources</span><span class="p">:</span> <span class="n"><a href="resources.html#ModelResources">lumen_clip.resources.ModelResources</a></span>,</span><span class="param">	<span class="n">device_preference</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">max_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="RKNNBackend.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#RKNNBackend.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="RKNNBackend.__init__-42"><a href="#RKNNBackend.__init__-42"><span class="linenos">42</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="RKNNBackend.__init__-43"><a href="#RKNNBackend.__init__-43"><span class="linenos">43</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="RKNNBackend.__init__-44"><a href="#RKNNBackend.__init__-44"><span class="linenos">44</span></a>        <span class="n">resources</span><span class="p">:</span> <span class="s2">&quot;ModelResources&quot;</span><span class="p">,</span>
</span><span id="RKNNBackend.__init__-45"><a href="#RKNNBackend.__init__-45"><span class="linenos">45</span></a>        <span class="n">device_preference</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="RKNNBackend.__init__-46"><a href="#RKNNBackend.__init__-46"><span class="linenos">46</span></a>        <span class="n">max_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="RKNNBackend.__init__-47"><a href="#RKNNBackend.__init__-47"><span class="linenos">47</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="RKNNBackend.__init__-48"><a href="#RKNNBackend.__init__-48"><span class="linenos">48</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="RKNNBackend.__init__-49"><a href="#RKNNBackend.__init__-49"><span class="linenos">49</span></a>            <span class="n">resources</span><span class="p">,</span>
</span><span id="RKNNBackend.__init__-50"><a href="#RKNNBackend.__init__-50"><span class="linenos">50</span></a>            <span class="n">device_preference</span><span class="p">,</span>
</span><span id="RKNNBackend.__init__-51"><a href="#RKNNBackend.__init__-51"><span class="linenos">51</span></a>            <span class="n">max_batch_size</span><span class="p">,</span>
</span><span id="RKNNBackend.__init__-52"><a href="#RKNNBackend.__init__-52"><span class="linenos">52</span></a>        <span class="p">)</span>
</span><span id="RKNNBackend.__init__-53"><a href="#RKNNBackend.__init__-53"><span class="linenos">53</span></a>        <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
</span><span id="RKNNBackend.__init__-54"><a href="#RKNNBackend.__init__-54"><span class="linenos">54</span></a>            <span class="s2">&quot;RKNNBackend is a Linux-only optional backend and is not available in this build.</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="RKNNBackend.__init__-55"><a href="#RKNNBackend.__init__-55"><span class="linenos">55</span></a>            <span class="s2">&quot;- rknn-toolkit2 provides wheels only for Linux (manylinux) targets.</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="RKNNBackend.__init__-56"><a href="#RKNNBackend.__init__-56"><span class="linenos">56</span></a>            <span class="s2">&quot;- Use the CUDA/ROCm Docker images which install the Linux-only &#39;rknn&#39; extra, e.g.:</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="RKNNBackend.__init__-57"><a href="#RKNNBackend.__init__-57"><span class="linenos">57</span></a>            <span class="s2">&quot;    docker build -f Dockerfiles/cuda/Dockerfile -t lumen-clip:cuda .</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="RKNNBackend.__init__-58"><a href="#RKNNBackend.__init__-58"><span class="linenos">58</span></a>            <span class="s2">&quot;    docker build -f Dockerfiles/rocm/Dockerfile -t lumen-clip:rocm .</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="RKNNBackend.__init__-59"><a href="#RKNNBackend.__init__-59"><span class="linenos">59</span></a>            <span class="s2">&quot;- At runtime, set BIOCLIP_BACKEND=rknn or CLIP_BACKEND=rknn to select the RKNN backend.&quot;</span>
</span><span id="RKNNBackend.__init__-60"><a href="#RKNNBackend.__init__-60"><span class="linenos">60</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Construct a backend with model resources.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>resources:</strong>  ModelResources object containing all model files and configs</li>
<li><strong>device_preference:</strong>  Hint for device selection (e.g., "cuda", "mps", "cpu").</li>
<li><strong>max_batch_size:</strong>  Hint for batching; implementation may clamp lower/higher.</li>
</ul>
</div>


                            </div>
                            <div id="RKNNBackend.initialize" class="classattr">
                                        <input id="RKNNBackend.initialize-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-override">@override</div>

        <span class="def">def</span>
        <span class="name">initialize</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

                <label class="view-source-button" for="RKNNBackend.initialize-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#RKNNBackend.initialize"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="RKNNBackend.initialize-62"><a href="#RKNNBackend.initialize-62"><span class="linenos">62</span></a>    <span class="nd">@override</span>
</span><span id="RKNNBackend.initialize-63"><a href="#RKNNBackend.initialize-63"><span class="linenos">63</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="RKNNBackend.initialize-64"><a href="#RKNNBackend.initialize-64"><span class="linenos">64</span></a>        <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
</span><span id="RKNNBackend.initialize-65"><a href="#RKNNBackend.initialize-65"><span class="linenos">65</span></a>            <span class="s2">&quot;RKNNBackend.initialize is unavailable: RKNN is Linux-only. &quot;</span>
</span><span id="RKNNBackend.initialize-66"><a href="#RKNNBackend.initialize-66"><span class="linenos">66</span></a>            <span class="s2">&quot;Use a Linux build with the &#39;rknn&#39; extra to enable this backend.&quot;</span>
</span><span id="RKNNBackend.initialize-67"><a href="#RKNNBackend.initialize-67"><span class="linenos">67</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Load weights and prepare runtime resources. Must be idempotent.</p>
</div>


                            </div>
                            <div id="RKNNBackend.text_to_vector" class="classattr">
                                        <input id="RKNNBackend.text_to_vector-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-override">@override</div>

        <span class="def">def</span>
        <span class="name">text_to_vector</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">text</span><span class="p">:</span> <span class="nb">str</span></span><span class="return-annotation">) -> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dtype</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">]]</span>:</span></span>

                <label class="view-source-button" for="RKNNBackend.text_to_vector-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#RKNNBackend.text_to_vector"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="RKNNBackend.text_to_vector-69"><a href="#RKNNBackend.text_to_vector-69"><span class="linenos">69</span></a>    <span class="nd">@override</span>
</span><span id="RKNNBackend.text_to_vector-70"><a href="#RKNNBackend.text_to_vector-70"><span class="linenos">70</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">text_to_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="RKNNBackend.text_to_vector-71"><a href="#RKNNBackend.text_to_vector-71"><span class="linenos">71</span></a>        <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
</span><span id="RKNNBackend.text_to_vector-72"><a href="#RKNNBackend.text_to_vector-72"><span class="linenos">72</span></a>            <span class="s2">&quot;RKNNBackend.text_to_vector is unavailable: RKNN is Linux-only. &quot;</span>
</span><span id="RKNNBackend.text_to_vector-73"><a href="#RKNNBackend.text_to_vector-73"><span class="linenos">73</span></a>            <span class="s2">&quot;Use a Linux build with the &#39;rknn&#39; extra to enable this backend.&quot;</span>
</span><span id="RKNNBackend.text_to_vector-74"><a href="#RKNNBackend.text_to_vector-74"><span class="linenos">74</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Encode a text string to a unit-normalized embedding vector.</p>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>np.ndarray with shape (D,) and dtype float32, L2-normalized to 1.0</p>
</blockquote>
</div>


                            </div>
                            <div id="RKNNBackend.image_to_vector" class="classattr">
                                        <input id="RKNNBackend.image_to_vector-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-override">@override</div>

        <span class="def">def</span>
        <span class="name">image_to_vector</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">image_bytes</span><span class="p">:</span> <span class="nb">bytes</span></span><span class="return-annotation">) -> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">typing</span><span class="o">.</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">numpy</span><span class="o">.</span><span class="n">dtype</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">]]</span>:</span></span>

                <label class="view-source-button" for="RKNNBackend.image_to_vector-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#RKNNBackend.image_to_vector"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="RKNNBackend.image_to_vector-76"><a href="#RKNNBackend.image_to_vector-76"><span class="linenos">76</span></a>    <span class="nd">@override</span>
</span><span id="RKNNBackend.image_to_vector-77"><a href="#RKNNBackend.image_to_vector-77"><span class="linenos">77</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">image_to_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_bytes</span><span class="p">:</span> <span class="nb">bytes</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">]:</span>
</span><span id="RKNNBackend.image_to_vector-78"><a href="#RKNNBackend.image_to_vector-78"><span class="linenos">78</span></a>        <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
</span><span id="RKNNBackend.image_to_vector-79"><a href="#RKNNBackend.image_to_vector-79"><span class="linenos">79</span></a>            <span class="s2">&quot;RKNNBackend.image_to_vector is unavailable: RKNN is Linux-only. &quot;</span>
</span><span id="RKNNBackend.image_to_vector-80"><a href="#RKNNBackend.image_to_vector-80"><span class="linenos">80</span></a>            <span class="s2">&quot;Use a Linux build with the &#39;rknn&#39; extra to enable this backend.&quot;</span>
</span><span id="RKNNBackend.image_to_vector-81"><a href="#RKNNBackend.image_to_vector-81"><span class="linenos">81</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Encode image bytes to a unit-normalized embedding vector.</p>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>np.ndarray with shape (D,) and dtype float32, L2-normalized to 1.0</p>
</blockquote>
</div>


                            </div>
                            <div id="RKNNBackend.get_info" class="classattr">
                                        <input id="RKNNBackend.get_info-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-override">@override</div>

        <span class="def">def</span>
        <span class="name">get_info</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">) -> <span class="n"><a href="#BackendInfo">BackendInfo</a></span>:</span></span>

                <label class="view-source-button" for="RKNNBackend.get_info-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#RKNNBackend.get_info"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="RKNNBackend.get_info-83"><a href="#RKNNBackend.get_info-83"><span class="linenos">83</span></a>    <span class="nd">@override</span>
</span><span id="RKNNBackend.get_info-84"><a href="#RKNNBackend.get_info-84"><span class="linenos">84</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_info</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BackendInfo</span><span class="p">:</span>
</span><span id="RKNNBackend.get_info-85"><a href="#RKNNBackend.get_info-85"><span class="linenos">85</span></a>        <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
</span><span id="RKNNBackend.get_info-86"><a href="#RKNNBackend.get_info-86"><span class="linenos">86</span></a>            <span class="s2">&quot;RKNNBackend.get_info is unavailable: RKNN is Linux-only. &quot;</span>
</span><span id="RKNNBackend.get_info-87"><a href="#RKNNBackend.get_info-87"><span class="linenos">87</span></a>            <span class="s2">&quot;Use a Linux build with the &#39;rknn&#39; extra to enable this backend.&quot;</span>
</span><span id="RKNNBackend.get_info-88"><a href="#RKNNBackend.get_info-88"><span class="linenos">88</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Return a BackendInfo describing runtime, device, model identifiers,
embedding dimensions, precision supports, batchability, etc.</p>
</div>


                            </div>
                </section>
    </main>
<script>
    function escapeHTML(html) {
        return document.createElement('div').appendChild(document.createTextNode(html)).parentNode.innerHTML;
    }

    const originalContent = document.querySelector("main.pdoc");
    let currentContent = originalContent;

    function setContent(innerHTML) {
        let elem;
        if (innerHTML) {
            elem = document.createElement("main");
            elem.classList.add("pdoc");
            elem.innerHTML = innerHTML;
        } else {
            elem = originalContent;
        }
        if (currentContent !== elem) {
            currentContent.replaceWith(elem);
            currentContent = elem;
        }
    }

    function getSearchTerm() {
        return (new URL(window.location)).searchParams.get("search");
    }

    const searchBox = document.querySelector(".pdoc input[type=search]");
    searchBox.addEventListener("input", function () {
        let url = new URL(window.location);
        if (searchBox.value.trim()) {
            url.hash = "";
            url.searchParams.set("search", searchBox.value);
        } else {
            url.searchParams.delete("search");
        }
        history.replaceState("", "", url.toString());
        onInput();
    });
    window.addEventListener("popstate", onInput);


    let search, searchErr;

    async function initialize() {
        try {
            search = await new Promise((resolve, reject) => {
                const script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.onload = () => resolve(window.pdocSearch);
                script.onerror = (e) => reject(e);
                script.src = "../search.js";
                document.getElementsByTagName("head")[0].appendChild(script);
            });
        } catch (e) {
            console.error("Cannot fetch pdoc search index");
            searchErr = "Cannot fetch search index.";
        }
        onInput();

        document.querySelector("nav.pdoc").addEventListener("click", e => {
            if (e.target.hash) {
                searchBox.value = "";
                searchBox.dispatchEvent(new Event("input"));
            }
        });
    }

    function onInput() {
        setContent((() => {
            const term = getSearchTerm();
            if (!term) {
                return null
            }
            if (searchErr) {
                return `<h3>Error: ${searchErr}</h3>`
            }
            if (!search) {
                return "<h3>Searching...</h3>"
            }

            window.scrollTo({top: 0, left: 0, behavior: 'auto'});

            const results = search(term);

            let html;
            if (results.length === 0) {
                html = `No search results for '${escapeHTML(term)}'.`
            } else {
                html = `<h4>${results.length} search result${results.length > 1 ? "s" : ""} for '${escapeHTML(term)}'.</h4>`;
            }
            for (let result of results.slice(0, 10)) {
                let doc = result.doc;
                let url = `../${doc.modulename.replaceAll(".", "/")}.html`;
                if (doc.qualname) {
                    url += `#${doc.qualname}`;
                }

                let heading;
                switch (result.doc.kind) {
                    case "function":
                        if (doc.fullname.endsWith(".__init__")) {
                            heading = `<span class="name">${doc.fullname.replace(/\.__init__$/, "")}</span>${doc.signature}`;
                        } else {
                            heading = `<span class="def">${doc.funcdef}</span> <span class="name">${doc.fullname}</span>${doc.signature}`;
                        }
                        break;
                    case "class":
                        heading = `<span class="def">class</span> <span class="name">${doc.fullname}</span>`;
                        if (doc.bases)
                            heading += `<wbr>(<span class="base">${doc.bases}</span>)`;
                        heading += `:`;
                        break;
                    case "variable":
                        heading = `<span class="name">${doc.fullname}</span>`;
                        if (doc.annotation)
                            heading += `<span class="annotation">${doc.annotation}</span>`;
                        if (doc.default_value)
                            heading += `<span class="default_value"> = ${doc.default_value}</span>`;
                        break;
                    default:
                        heading = `<span class="name">${doc.fullname}</span>`;
                        break;
                }
                html += `
                        <section class="search-result">
                        <a href="${url}" class="attr ${doc.kind}">${heading}</a>
                        <div class="docstring">${doc.doc}</div>
                        </section>
                    `;

            }
            return html;
        })());
    }

    if (getSearchTerm()) {
        initialize();
        searchBox.value = getSearchTerm();
        onInput();
    } else {
        searchBox.addEventListener("focus", initialize, {once: true});
    }

    searchBox.addEventListener("keydown", e => {
        if (["ArrowDown", "ArrowUp", "Enter"].includes(e.key)) {
            let focused = currentContent.querySelector(".search-result.focused");
            if (!focused) {
                currentContent.querySelector(".search-result").classList.add("focused");
            } else if (
                e.key === "ArrowDown"
                && focused.nextElementSibling
                && focused.nextElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.nextElementSibling.classList.add("focused");
                focused.nextElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "ArrowUp"
                && focused.previousElementSibling
                && focused.previousElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.previousElementSibling.classList.add("focused");
                focused.previousElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "Enter"
            ) {
                focused.querySelector("a").click();
            }
        }
    });
</script></body>
</html>